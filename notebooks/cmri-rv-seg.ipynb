{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Model for RV Segmentation\n",
    "\n",
    "## Training U-Net CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os, re, glob\n",
    "import numpy as np\n",
    "import matplotlib as mplt\n",
    "%matplotlib inline\n",
    "\n",
    "from src import data,unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 243 total training images.\n",
      "There are 243 total inner masks.\n",
      "There are 243 total outer masks.\n"
     ]
    }
   ],
   "source": [
    "from keras import utils\n",
    "\n",
    "train_dir = \"/home/ubuntu/training/TrainingSet\"\n",
    "\n",
    "\n",
    "images=[]\n",
    "inner_masks=[]\n",
    "outer_masks = []\n",
    "\n",
    "patient_directories = sorted(glob.glob(os.path.join(train_dir, \"patient*\")))\n",
    "\n",
    "for patient_dir in patient_directories:\n",
    "    imgdata = data.ImageData(patient_dir)\n",
    "    images += imgdata.labeled_images\n",
    "    inner_masks += imgdata.endo_masks.values()\n",
    "    outer_masks += imgdata.epi_masks.values()\n",
    "\n",
    "images = np.asarray(images)[:,:,:,None].astype('float64')\n",
    "i_masks = np.asarray(inner_masks)\n",
    "o_masks = np.asarray(outer_masks)\n",
    "\n",
    "dims = i_masks.shape\n",
    "classes = len(set(i_masks[0].flatten()))\n",
    "new_shape = dims + (classes,)\n",
    "i_masks = utils.to_categorical(i_masks).reshape(new_shape)\n",
    "o_masks = utils.to_categorical(o_masks).reshape(new_shape)\n",
    "\n",
    "print(\"There are %d total training images.\" % len(images))\n",
    "print(\"There are %d total inner masks.\" % len(inner_masks))\n",
    "print(\"There are %d total outer masks.\" % len(outer_masks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 216, 256, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 216, 256, 32)  320         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 216, 256, 32)  0           conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 216, 256, 32)  9248        activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 216, 256, 32)  0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 108, 128, 32)  0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 108, 128, 64)  18496       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 108, 128, 64)  0           conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 108, 128, 64)  36928       activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 108, 128, 64)  0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 54, 64, 64)    0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 54, 64, 128)   73856       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 54, 64, 128)   0           conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 54, 64, 128)   147584      activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 54, 64, 128)   0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 27, 32, 128)   0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 27, 32, 256)   295168      max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 27, 32, 256)   0           conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 27, 32, 256)   590080      activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 27, 32, 256)   0           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTransp (None, 54, 64, 128)   131200      activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 54, 64, 256)   0           conv2d_transpose_1[0][0]         \n",
      "                                                                   conv2d_transpose_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 54, 64, 128)   295040      concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 54, 64, 128)   0           conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 54, 64, 128)   147584      activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 54, 64, 128)   0           conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTransp (None, 108, 128, 64)  32832       activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 108, 128, 128) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                   conv2d_transpose_2[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 108, 128, 64)  73792       concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 108, 128, 64)  0           conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 108, 128, 64)  36928       activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 108, 128, 64)  0           conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTransp (None, 216, 256, 32)  8224        activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 216, 256, 64)  0           conv2d_transpose_3[0][0]         \n",
      "                                                                   conv2d_transpose_3[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 216, 256, 32)  18464       concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 216, 256, 32)  0           conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 216, 256, 32)  9248        activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 216, 256, 32)  0           conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 216, 256, 2)   66          activation_14[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 1,925,058\n",
      "Trainable params: 1,925,058\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "height,width,_ = images[0].shape\n",
    "dropout = 0.0\n",
    "\n",
    "unet_conv = unet.UNet()\n",
    "\n",
    "model = unet_conv.get_unet(height=height,width=width,channels=1,features=32,steps=3,padding='same')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "        flat_y_true = K.flatten(y_true)\n",
    "        flat_y_preds = K.flatten(y_pred)\n",
    "        intersection = K.sum(flat_y_true*flat_y_preds)\n",
    "        return (2. * intersection + 1.) / (K.sum(flat_y_true)+K.sum(flat_y_preds))\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-5),loss='categorical_crossentropy',metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/preprocessing/image.py:653: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (194, 216, 256, 2) (2 channels).\n",
      "/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/preprocessing/image.py:787: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (194, 216, 256, 2) (2 channels).\n"
     ]
    }
   ],
   "source": [
    "#TODO: 1. split data into training and validation set\n",
    "#      2. Augment the data\n",
    "#      3. Train model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "seed = 0\n",
    "\n",
    "validation_split=0.2\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 20\n",
    "\n",
    "\n",
    "split_index = int((1 - validation_split) * len(images))\n",
    "\n",
    "train_steps = ceil(split_index / batch_size)\n",
    "val_steps = ceil((len(images)-split_index )/batch_size)\n",
    "\n",
    "train_images = images[:split_index]\n",
    "train_inner_masks = i_masks[:split_index]\n",
    "\n",
    "validation_images = images[split_index:]\n",
    "validation_inner_masks = i_masks[split_index:]\n",
    "\n",
    "\n",
    "data_gen_args = dict(rotation_range=180,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     shear_range=0.1,\n",
    "                     zoom_range=0.01,\n",
    "                     fill_mode='nearest')\n",
    "\n",
    "train_images_datagen = ImageDataGenerator(**data_gen_args)\n",
    "train_masks_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "\n",
    "seed = 1\n",
    "#height,width,channels = train_images[0].shape\n",
    "#print(train_images[0].shape)\n",
    "#print(train_inner_masks[0].shape)\n",
    "train_images_datagen.fit(train_images,augment=True,seed=seed)\n",
    "train_masks_datagen.fit(train_inner_masks,augment=True,seed=seed)\n",
    "\n",
    "train_images_generator = train_images_datagen.flow(train_images, y=None, seed=seed)\n",
    "train_masks_generator = train_images_datagen.flow(train_inner_masks, y=None, seed=seed)\n",
    "\n",
    "\n",
    "train_generator = zip(train_images_generator, train_masks_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 9/10 [==========================>...] - ETA: 2s - loss: 0.7059 - dice_coef: 0.4940Epoch 00000: val_loss improved from inf to 0.69389, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 26s - loss: 0.7049 - dice_coef: 0.4945 - val_loss: 0.6939 - val_dice_coef: 0.4998\n",
      "Epoch 2/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.6887 - dice_coef: 0.5024Epoch 00001: val_loss improved from 0.69389 to 0.68153, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.6880 - dice_coef: 0.5028 - val_loss: 0.6815 - val_dice_coef: 0.5060\n",
      "Epoch 3/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.6719 - dice_coef: 0.5112Epoch 00002: val_loss improved from 0.68153 to 0.65780, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 14s - loss: 0.6702 - dice_coef: 0.5120 - val_loss: 0.6578 - val_dice_coef: 0.5187\n",
      "Epoch 4/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.6328 - dice_coef: 0.5331Epoch 00003: val_loss improved from 0.65780 to 0.59466, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.6287 - dice_coef: 0.5356 - val_loss: 0.5947 - val_dice_coef: 0.5558\n",
      "Epoch 5/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.5380 - dice_coef: 0.5957Epoch 00004: val_loss improved from 0.59466 to 0.46538, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 14s - loss: 0.5316 - dice_coef: 0.6007 - val_loss: 0.4654 - val_dice_coef: 0.6501\n",
      "Epoch 6/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.4087 - dice_coef: 0.7161Epoch 00005: val_loss improved from 0.46538 to 0.35150, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.4026 - dice_coef: 0.7237 - val_loss: 0.3515 - val_dice_coef: 0.7812\n",
      "Epoch 7/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.3540 - dice_coef: 0.8185Epoch 00006: val_loss improved from 0.35150 to 0.33302, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.3628 - dice_coef: 0.8195 - val_loss: 0.3330 - val_dice_coef: 0.8228\n",
      "Epoch 8/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.3621 - dice_coef: 0.8154Epoch 00007: val_loss improved from 0.33302 to 0.33053, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.3586 - dice_coef: 0.8148 - val_loss: 0.3305 - val_dice_coef: 0.7874\n",
      "Epoch 9/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.3304 - dice_coef: 0.7968Epoch 00008: val_loss improved from 0.33053 to 0.31470, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.3298 - dice_coef: 0.7985 - val_loss: 0.3147 - val_dice_coef: 0.8030\n",
      "Epoch 10/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.3352 - dice_coef: 0.8127Epoch 00009: val_loss improved from 0.31470 to 0.30072, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.3320 - dice_coef: 0.8141 - val_loss: 0.3007 - val_dice_coef: 0.8157\n",
      "Epoch 11/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.3190 - dice_coef: 0.8217Epoch 00010: val_loss improved from 0.30072 to 0.28811, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.3159 - dice_coef: 0.8226 - val_loss: 0.2881 - val_dice_coef: 0.8229\n",
      "Epoch 12/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.2942 - dice_coef: 0.8340Epoch 00011: val_loss improved from 0.28811 to 0.27419, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.2999 - dice_coef: 0.8324 - val_loss: 0.2742 - val_dice_coef: 0.8336\n",
      "Epoch 13/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.2735 - dice_coef: 0.8441Epoch 00012: val_loss improved from 0.27419 to 0.26017, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.2742 - dice_coef: 0.8443 - val_loss: 0.2602 - val_dice_coef: 0.8478\n",
      "Epoch 14/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.2830 - dice_coef: 0.8415Epoch 00013: val_loss improved from 0.26017 to 0.25350, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.2897 - dice_coef: 0.8365 - val_loss: 0.2535 - val_dice_coef: 0.8394\n",
      "Epoch 15/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.2719 - dice_coef: 0.8475Epoch 00014: val_loss improved from 0.25350 to 0.24000, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.2707 - dice_coef: 0.8479 - val_loss: 0.2400 - val_dice_coef: 0.8532\n",
      "Epoch 16/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.2563 - dice_coef: 0.8515Epoch 00015: val_loss improved from 0.24000 to 0.22938, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.2551 - dice_coef: 0.8526 - val_loss: 0.2294 - val_dice_coef: 0.8634\n",
      "Epoch 17/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.2562 - dice_coef: 0.8598Epoch 00016: val_loss improved from 0.22938 to 0.22684, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.2539 - dice_coef: 0.8590 - val_loss: 0.2268 - val_dice_coef: 0.8526\n",
      "Epoch 18/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.2525 - dice_coef: 0.8477Epoch 00017: val_loss improved from 0.22684 to 0.21314, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.2496 - dice_coef: 0.8506 - val_loss: 0.2131 - val_dice_coef: 0.8783\n",
      "Epoch 19/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.2462 - dice_coef: 0.8630Epoch 00018: val_loss improved from 0.21314 to 0.20950, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.2434 - dice_coef: 0.8646 - val_loss: 0.2095 - val_dice_coef: 0.8697\n",
      "Epoch 20/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.2340 - dice_coef: 0.8634Epoch 00019: val_loss improved from 0.20950 to 0.20395, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.2326 - dice_coef: 0.8634 - val_loss: 0.2039 - val_dice_coef: 0.8717\n",
      "Epoch 21/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.2285 - dice_coef: 0.8686Epoch 00020: val_loss improved from 0.20395 to 0.19720, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.2307 - dice_coef: 0.8684 - val_loss: 0.1972 - val_dice_coef: 0.8789\n",
      "Epoch 22/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.2109 - dice_coef: 0.8714Epoch 00021: val_loss improved from 0.19720 to 0.19102, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.2159 - dice_coef: 0.8717 - val_loss: 0.1910 - val_dice_coef: 0.8979\n",
      "Epoch 23/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.2154 - dice_coef: 0.8814Epoch 00022: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.2158 - dice_coef: 0.8814 - val_loss: 0.1916 - val_dice_coef: 0.8777\n",
      "Epoch 24/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.2229 - dice_coef: 0.8671Epoch 00023: val_loss improved from 0.19102 to 0.18410, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.2206 - dice_coef: 0.8694 - val_loss: 0.1841 - val_dice_coef: 0.8937\n",
      "Epoch 25/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1986 - dice_coef: 0.8891Epoch 00024: val_loss improved from 0.18410 to 0.18212, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.2001 - dice_coef: 0.8881 - val_loss: 0.1821 - val_dice_coef: 0.8898\n",
      "Epoch 26/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.2101 - dice_coef: 0.8749Epoch 00025: val_loss improved from 0.18212 to 0.17832, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.2115 - dice_coef: 0.8752 - val_loss: 0.1783 - val_dice_coef: 0.8947\n",
      "Epoch 27/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1921 - dice_coef: 0.8937Epoch 00026: val_loss improved from 0.17832 to 0.17530, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.1911 - dice_coef: 0.8930 - val_loss: 0.1753 - val_dice_coef: 0.8950\n",
      "Epoch 28/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1885 - dice_coef: 0.8916Epoch 00027: val_loss improved from 0.17530 to 0.17242, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.1993 - dice_coef: 0.8870 - val_loss: 0.1724 - val_dice_coef: 0.8952\n",
      "Epoch 29/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1891 - dice_coef: 0.8876Epoch 00028: val_loss improved from 0.17242 to 0.16809, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.1890 - dice_coef: 0.8894 - val_loss: 0.1681 - val_dice_coef: 0.9088\n",
      "Epoch 30/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1924 - dice_coef: 0.8887Epoch 00029: val_loss improved from 0.16809 to 0.16723, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.1894 - dice_coef: 0.8891 - val_loss: 0.1672 - val_dice_coef: 0.8983\n",
      "Epoch 31/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1906 - dice_coef: 0.8965Epoch 00030: val_loss did not improve\n",
      "10/10 [==============================] - 14s - loss: 0.1879 - dice_coef: 0.8953 - val_loss: 0.1742 - val_dice_coef: 0.8830\n",
      "Epoch 32/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.2102 - dice_coef: 0.8810Epoch 00031: val_loss improved from 0.16723 to 0.16430, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.2041 - dice_coef: 0.8823 - val_loss: 0.1643 - val_dice_coef: 0.9009\n",
      "Epoch 33/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1807 - dice_coef: 0.8979Epoch 00032: val_loss did not improve\n",
      "10/10 [==============================] - 14s - loss: 0.1828 - dice_coef: 0.8969 - val_loss: 0.1668 - val_dice_coef: 0.8919\n",
      "Epoch 34/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1795 - dice_coef: 0.8922Epoch 00033: val_loss improved from 0.16430 to 0.15976, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.1802 - dice_coef: 0.8933 - val_loss: 0.1598 - val_dice_coef: 0.9115\n",
      "Epoch 35/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1930 - dice_coef: 0.8842Epoch 00034: val_loss improved from 0.15976 to 0.15743, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.1830 - dice_coef: 0.8886 - val_loss: 0.1574 - val_dice_coef: 0.9136\n",
      "Epoch 36/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1917 - dice_coef: 0.8945Epoch 00035: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1905 - dice_coef: 0.8927 - val_loss: 0.1666 - val_dice_coef: 0.8877\n",
      "Epoch 37/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1890 - dice_coef: 0.8932Epoch 00036: val_loss improved from 0.15743 to 0.15514, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.1869 - dice_coef: 0.8933 - val_loss: 0.1551 - val_dice_coef: 0.9070\n",
      "Epoch 38/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1675 - dice_coef: 0.9020Epoch 00037: val_loss improved from 0.15514 to 0.15282, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.1688 - dice_coef: 0.9013 - val_loss: 0.1528 - val_dice_coef: 0.9115\n",
      "Epoch 39/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1900 - dice_coef: 0.8917Epoch 00038: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1873 - dice_coef: 0.8920 - val_loss: 0.1546 - val_dice_coef: 0.9040\n",
      "Epoch 40/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1931 - dice_coef: 0.8913Epoch 00039: val_loss did not improve\n",
      "10/10 [==============================] - 14s - loss: 0.1907 - dice_coef: 0.8932 - val_loss: 0.1535 - val_dice_coef: 0.9036\n",
      "Epoch 41/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1707 - dice_coef: 0.9004Epoch 00040: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1729 - dice_coef: 0.8999 - val_loss: 0.1544 - val_dice_coef: 0.9016\n",
      "Epoch 42/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1757 - dice_coef: 0.8975Epoch 00041: val_loss did not improve\n",
      "10/10 [==============================] - 15s - loss: 0.1729 - dice_coef: 0.8987 - val_loss: 0.1530 - val_dice_coef: 0.9035\n",
      "Epoch 43/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1653 - dice_coef: 0.9016Epoch 00042: val_loss improved from 0.15282 to 0.14972, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.1667 - dice_coef: 0.9024 - val_loss: 0.1497 - val_dice_coef: 0.9123\n",
      "Epoch 44/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1802 - dice_coef: 0.8873Epoch 00043: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1782 - dice_coef: 0.8899 - val_loss: 0.1513 - val_dice_coef: 0.9225\n",
      "Epoch 45/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1715 - dice_coef: 0.9001Epoch 00044: val_loss improved from 0.14972 to 0.14908, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.1679 - dice_coef: 0.9014 - val_loss: 0.1491 - val_dice_coef: 0.9164\n",
      "Epoch 46/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1950 - dice_coef: 0.8917Epoch 00045: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1927 - dice_coef: 0.8904 - val_loss: 0.1541 - val_dice_coef: 0.8979\n",
      "Epoch 47/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1659 - dice_coef: 0.9059Epoch 00046: val_loss did not improve\n",
      "10/10 [==============================] - 14s - loss: 0.1669 - dice_coef: 0.9032 - val_loss: 0.1621 - val_dice_coef: 0.8871\n",
      "Epoch 48/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1722 - dice_coef: 0.8997Epoch 00047: val_loss improved from 0.14908 to 0.14820, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.1683 - dice_coef: 0.9019 - val_loss: 0.1482 - val_dice_coef: 0.9163\n",
      "Epoch 49/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1634 - dice_coef: 0.9049Epoch 00048: val_loss improved from 0.14820 to 0.14779, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.1590 - dice_coef: 0.9061 - val_loss: 0.1478 - val_dice_coef: 0.9199\n",
      "Epoch 50/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1580 - dice_coef: 0.9129Epoch 00049: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1602 - dice_coef: 0.9111 - val_loss: 0.1495 - val_dice_coef: 0.9054\n",
      "Epoch 51/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1647 - dice_coef: 0.9039Epoch 00050: val_loss improved from 0.14779 to 0.14619, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.1643 - dice_coef: 0.9044 - val_loss: 0.1462 - val_dice_coef: 0.9122\n",
      "Epoch 52/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1712 - dice_coef: 0.9021Epoch 00051: val_loss improved from 0.14619 to 0.14508, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.1708 - dice_coef: 0.9025 - val_loss: 0.1451 - val_dice_coef: 0.9167\n",
      "Epoch 53/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1581 - dice_coef: 0.9073Epoch 00052: val_loss improved from 0.14508 to 0.14436, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.1581 - dice_coef: 0.9075 - val_loss: 0.1444 - val_dice_coef: 0.9194\n",
      "Epoch 54/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1705 - dice_coef: 0.8974Epoch 00053: val_loss did not improve\n",
      "10/10 [==============================] - 15s - loss: 0.1708 - dice_coef: 0.8985 - val_loss: 0.1456 - val_dice_coef: 0.9280\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1614 - dice_coef: 0.9053Epoch 00054: val_loss improved from 0.14436 to 0.14350, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.1627 - dice_coef: 0.9064 - val_loss: 0.1435 - val_dice_coef: 0.9229\n",
      "Epoch 56/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1843 - dice_coef: 0.8922Epoch 00055: val_loss improved from 0.14350 to 0.14167, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.1773 - dice_coef: 0.8934 - val_loss: 0.1417 - val_dice_coef: 0.9144\n",
      "Epoch 57/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1578 - dice_coef: 0.9141Epoch 00056: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1605 - dice_coef: 0.9123 - val_loss: 0.1444 - val_dice_coef: 0.9075\n",
      "Epoch 58/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1667 - dice_coef: 0.9056Epoch 00057: val_loss improved from 0.14167 to 0.14146, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.1637 - dice_coef: 0.9063 - val_loss: 0.1415 - val_dice_coef: 0.9149\n",
      "Epoch 59/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1628 - dice_coef: 0.9057Epoch 00058: val_loss improved from 0.14146 to 0.14060, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.1607 - dice_coef: 0.9068 - val_loss: 0.1406 - val_dice_coef: 0.9191\n",
      "Epoch 60/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1527 - dice_coef: 0.9116Epoch 00059: val_loss improved from 0.14060 to 0.14023, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.1563 - dice_coef: 0.9111 - val_loss: 0.1402 - val_dice_coef: 0.9189\n",
      "Epoch 61/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1520 - dice_coef: 0.9091Epoch 00060: val_loss did not improve\n",
      "10/10 [==============================] - 15s - loss: 0.1552 - dice_coef: 0.9091 - val_loss: 0.1405 - val_dice_coef: 0.9251\n",
      "Epoch 62/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1549 - dice_coef: 0.9108Epoch 00061: val_loss improved from 0.14023 to 0.13984, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.1534 - dice_coef: 0.9108 - val_loss: 0.1398 - val_dice_coef: 0.9158\n",
      "Epoch 63/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1590 - dice_coef: 0.9066Epoch 00062: val_loss improved from 0.13984 to 0.13953, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.1541 - dice_coef: 0.9085 - val_loss: 0.1395 - val_dice_coef: 0.9212\n",
      "Epoch 64/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1520 - dice_coef: 0.9137Epoch 00063: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1521 - dice_coef: 0.9131 - val_loss: 0.1404 - val_dice_coef: 0.9157\n",
      "Epoch 65/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1788 - dice_coef: 0.8990Epoch 00064: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1751 - dice_coef: 0.8989 - val_loss: 0.1421 - val_dice_coef: 0.9120\n",
      "Epoch 66/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1573 - dice_coef: 0.9129Epoch 00065: val_loss did not improve\n",
      "10/10 [==============================] - 15s - loss: 0.1586 - dice_coef: 0.9123 - val_loss: 0.1419 - val_dice_coef: 0.9130\n",
      "Epoch 67/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1464 - dice_coef: 0.9177Epoch 00066: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1468 - dice_coef: 0.9167 - val_loss: 0.1413 - val_dice_coef: 0.9124\n",
      "Epoch 68/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1429 - dice_coef: 0.9158Epoch 00067: val_loss improved from 0.13953 to 0.13868, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.1442 - dice_coef: 0.9159 - val_loss: 0.1387 - val_dice_coef: 0.9240\n",
      "Epoch 69/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1412 - dice_coef: 0.9182Epoch 00068: val_loss improved from 0.13868 to 0.13755, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.1429 - dice_coef: 0.9186 - val_loss: 0.1376 - val_dice_coef: 0.9261\n",
      "Epoch 70/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1481 - dice_coef: 0.9166Epoch 00069: val_loss improved from 0.13755 to 0.13637, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.1486 - dice_coef: 0.9165 - val_loss: 0.1364 - val_dice_coef: 0.9192\n",
      "Epoch 71/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1535 - dice_coef: 0.9095Epoch 00070: val_loss improved from 0.13637 to 0.13602, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.1505 - dice_coef: 0.9118 - val_loss: 0.1360 - val_dice_coef: 0.9230\n",
      "Epoch 72/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1456 - dice_coef: 0.9160Epoch 00071: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1464 - dice_coef: 0.9157 - val_loss: 0.1362 - val_dice_coef: 0.9203\n",
      "Epoch 73/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1438 - dice_coef: 0.9167Epoch 00072: val_loss did not improve\n",
      "10/10 [==============================] - 14s - loss: 0.1430 - dice_coef: 0.9159 - val_loss: 0.1361 - val_dice_coef: 0.9176\n",
      "Epoch 74/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1708 - dice_coef: 0.9021Epoch 00073: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1669 - dice_coef: 0.9022 - val_loss: 0.1370 - val_dice_coef: 0.9123\n",
      "Epoch 75/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1554 - dice_coef: 0.9089Epoch 00074: val_loss improved from 0.13602 to 0.13571, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.1547 - dice_coef: 0.9090 - val_loss: 0.1357 - val_dice_coef: 0.9198\n",
      "Epoch 76/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1408 - dice_coef: 0.9218Epoch 00075: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1418 - dice_coef: 0.9203 - val_loss: 0.1359 - val_dice_coef: 0.9172\n",
      "Epoch 77/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1498 - dice_coef: 0.9144Epoch 00076: val_loss did not improve\n",
      "10/10 [==============================] - 15s - loss: 0.1557 - dice_coef: 0.9118 - val_loss: 0.1380 - val_dice_coef: 0.9102\n",
      "Epoch 78/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1458 - dice_coef: 0.9150Epoch 00077: val_loss improved from 0.13571 to 0.13420, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.1440 - dice_coef: 0.9171 - val_loss: 0.1342 - val_dice_coef: 0.9257\n",
      "Epoch 79/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1466 - dice_coef: 0.9116Epoch 00078: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1478 - dice_coef: 0.9132 - val_loss: 0.1351 - val_dice_coef: 0.9277\n",
      "Epoch 80/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1646 - dice_coef: 0.9091Epoch 00079: val_loss did not improve\n",
      "10/10 [==============================] - 14s - loss: 0.1631 - dice_coef: 0.9079 - val_loss: 0.1439 - val_dice_coef: 0.9006\n",
      "Epoch 81/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1498 - dice_coef: 0.9142Epoch 00080: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1504 - dice_coef: 0.9139 - val_loss: 0.1386 - val_dice_coef: 0.9085\n",
      "Epoch 82/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1403 - dice_coef: 0.9133Epoch 00081: val_loss did not improve\n",
      "10/10 [==============================] - 14s - loss: 0.1409 - dice_coef: 0.9148 - val_loss: 0.1382 - val_dice_coef: 0.9338\n",
      "Epoch 83/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1536 - dice_coef: 0.9102Epoch 00082: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1529 - dice_coef: 0.9098 - val_loss: 0.1364 - val_dice_coef: 0.9131\n",
      "Epoch 84/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1501 - dice_coef: 0.9164Epoch 00083: val_loss did not improve\n",
      "10/10 [==============================] - 15s - loss: 0.1479 - dice_coef: 0.9157 - val_loss: 0.1356 - val_dice_coef: 0.9169\n",
      "Epoch 85/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1548 - dice_coef: 0.9133Epoch 00084: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1526 - dice_coef: 0.9146 - val_loss: 0.1342 - val_dice_coef: 0.9243\n",
      "Epoch 86/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1496 - dice_coef: 0.9105Epoch 00085: val_loss improved from 0.13420 to 0.13327, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.1481 - dice_coef: 0.9118 - val_loss: 0.1333 - val_dice_coef: 0.9271\n",
      "Epoch 87/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1512 - dice_coef: 0.9137Epoch 00086: val_loss did not improve\n",
      "10/10 [==============================] - 14s - loss: 0.1520 - dice_coef: 0.9128 - val_loss: 0.1347 - val_dice_coef: 0.9148\n",
      "Epoch 88/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1466 - dice_coef: 0.9152Epoch 00087: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1477 - dice_coef: 0.9151 - val_loss: 0.1338 - val_dice_coef: 0.9175\n",
      "Epoch 89/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1522 - dice_coef: 0.9066Epoch 00088: val_loss did not improve\n",
      "10/10 [==============================] - 14s - loss: 0.1510 - dice_coef: 0.9096 - val_loss: 0.1355 - val_dice_coef: 0.9300\n",
      "Epoch 90/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1610 - dice_coef: 0.9122Epoch 00089: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1580 - dice_coef: 0.9127 - val_loss: 0.1338 - val_dice_coef: 0.9212\n",
      "Epoch 91/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1400 - dice_coef: 0.9234Epoch 00090: val_loss did not improve\n",
      "10/10 [==============================] - 15s - loss: 0.1422 - dice_coef: 0.9194 - val_loss: 0.1399 - val_dice_coef: 0.9055\n",
      "Epoch 92/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1391 - dice_coef: 0.9201Epoch 00091: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1396 - dice_coef: 0.9194 - val_loss: 0.1357 - val_dice_coef: 0.9126\n",
      "Epoch 93/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1425 - dice_coef: 0.9176Epoch 00092: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1430 - dice_coef: 0.9180 - val_loss: 0.1333 - val_dice_coef: 0.9183\n",
      "Epoch 94/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1350 - dice_coef: 0.9189Epoch 00093: val_loss improved from 0.13327 to 0.13281, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 15s - loss: 0.1388 - dice_coef: 0.9190 - val_loss: 0.1328 - val_dice_coef: 0.9276\n",
      "Epoch 95/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1353 - dice_coef: 0.9221Epoch 00094: val_loss improved from 0.13281 to 0.13237, saving model to saved_models/weights.hdf5\n",
      "10/10 [==============================] - 16s - loss: 0.1379 - dice_coef: 0.9216 - val_loss: 0.1324 - val_dice_coef: 0.9237\n",
      "Epoch 96/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1415 - dice_coef: 0.9180Epoch 00095: val_loss did not improve\n",
      "10/10 [==============================] - 14s - loss: 0.1442 - dice_coef: 0.9167 - val_loss: 0.1343 - val_dice_coef: 0.9148\n",
      "Epoch 97/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1341 - dice_coef: 0.9213Epoch 00096: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1326 - dice_coef: 0.9215 - val_loss: 0.1333 - val_dice_coef: 0.9172\n",
      "Epoch 98/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1469 - dice_coef: 0.9145Epoch 00097: val_loss did not improve\n",
      "10/10 [==============================] - 15s - loss: 0.1414 - dice_coef: 0.9177 - val_loss: 0.1338 - val_dice_coef: 0.9158\n",
      "Epoch 99/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1778 - dice_coef: 0.9070Epoch 00098: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1756 - dice_coef: 0.9031 - val_loss: 0.1780 - val_dice_coef: 0.8634\n",
      "Epoch 100/100\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.1668 - dice_coef: 0.8955Epoch 00099: val_loss did not improve\n",
      "10/10 [==============================] - 16s - loss: 0.1663 - dice_coef: 0.8984 - val_loss: 0.1350 - val_dice_coef: 0.9273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3e8d16a550>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit_generator(train_generator,steps_per_epoch=train_steps,epochs=epochs,verbose=1,callbacks=[checkpointer],\n",
    "                   validation_data=(validation_images,validation_inner_masks),validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.hdf5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Results of Endocardium Model\n",
    "\n",
    "## Training\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
