{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training U-Net model\n",
    "## 500 Epochs, No Dropout, Adam Optimizer, Learning Rate 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os, re, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from src import data,unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 243 total training images.\n",
      "There are 243 total inner masks.\n",
      "There are 243 total outer masks.\n"
     ]
    }
   ],
   "source": [
    "from keras import utils\n",
    "train_dir = \"/home/ubuntu/trainingdata/TrainingSet\"\n",
    "weight_file = 'saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5'\n",
    "save_imgs_dir = 'images/train500NoDrpAdam5'\n",
    "\n",
    "images = []\n",
    "inner_masks = []\n",
    "outer_masks = []\n",
    "\n",
    "patient_directories = sorted(glob.glob(os.path.join(train_dir, \"patient*\")))\n",
    "\n",
    "for patient_dir in patient_directories:\n",
    "    imgdata = data.ImageData(patient_dir)\n",
    "    images += imgdata.labeled_images\n",
    "    inner_masks += imgdata.endo_masks\n",
    "    outer_masks += imgdata.epi_masks\n",
    "\n",
    "images = np.asarray(images)[:,:,:,None].astype('float64')\n",
    "i_masks = np.asarray(inner_masks)\n",
    "o_masks = np.asarray(outer_masks)\n",
    "\n",
    "dims = i_masks.shape\n",
    "classes = len(set(i_masks[0].flatten()))\n",
    "new_shape = dims + (classes,)\n",
    "i_masks = utils.to_categorical(i_masks).reshape(new_shape)\n",
    "o_masks = utils.to_categorical(o_masks).reshape(new_shape)\n",
    "\n",
    "def normalize(x, epsilon=1e-7, axis=(1,2)):\n",
    "    x -= np.mean(x, axis=axis, keepdims=True)\n",
    "    x /= np.std(x, axis=axis, keepdims=True) + epsilon\n",
    "    \n",
    "normalize(images,axis=(1,2))\n",
    "\n",
    "print(\"There are %d total training images.\" % len(images))\n",
    "print(\"There are %d total inner masks.\" % len(inner_masks))\n",
    "print(\"There are %d total outer masks.\" % len(outer_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 216, 256, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 216, 256, 32)  320         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 216, 256, 32)  0           conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 216, 256, 32)  0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 216, 256, 32)  9248        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 216, 256, 32)  0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 216, 256, 32)  0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 108, 128, 32)  0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 108, 128, 64)  18496       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 108, 128, 64)  0           conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 108, 128, 64)  0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 108, 128, 64)  36928       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 108, 128, 64)  0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 108, 128, 64)  0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 54, 64, 64)    0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 54, 64, 128)   73856       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 54, 64, 128)   0           conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 54, 64, 128)   0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 54, 64, 128)   147584      dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 54, 64, 128)   0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 54, 64, 128)   0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 27, 32, 128)   0           dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 27, 32, 256)   295168      max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 27, 32, 256)   0           conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 27, 32, 256)   0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 27, 32, 256)   590080      dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 27, 32, 256)   0           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 27, 32, 256)   0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTransp (None, 54, 64, 128)   131200      dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 54, 64, 256)   0           conv2d_transpose_1[0][0]         \n",
      "                                                                   conv2d_transpose_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 54, 64, 128)   295040      concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 54, 64, 128)   0           conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 54, 64, 128)   0           activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 54, 64, 128)   147584      dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 54, 64, 128)   0           conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 54, 64, 128)   0           activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTransp (None, 108, 128, 64)  32832       dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 108, 128, 128) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                   conv2d_transpose_2[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 108, 128, 64)  73792       concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 108, 128, 64)  0           conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 108, 128, 64)  0           activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 108, 128, 64)  36928       dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 108, 128, 64)  0           conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 108, 128, 64)  0           activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTransp (None, 216, 256, 32)  8224        dropout_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 216, 256, 64)  0           conv2d_transpose_3[0][0]         \n",
      "                                                                   conv2d_transpose_3[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 216, 256, 32)  18464       concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 216, 256, 32)  0           conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 216, 256, 32)  0           activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 216, 256, 32)  9248        dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 216, 256, 32)  0           conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 216, 256, 32)  0           activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 216, 256, 2)   66          dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 216, 256, 2)   0           conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 216, 256, 2)   0           lambda_1[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 1,925,058\n",
      "Trainable params: 1,925,058\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "height,width,_ = images[0].shape\n",
    "dropout = 0.0\n",
    "unet_conv = unet.UNet()\n",
    "\n",
    "model = unet_conv.get_unet(height=height, width=width, channels=1,features=32,steps=3,dropout=dropout,padding='same')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    flat_y_true = K.flatten(y_true)\n",
    "    flat_y_pred = K.flatten(y_pred)\n",
    "    intersection = K.sum(flat_y_true * flat_y_pred)\n",
    "    return (2. * intersection + 1.) / (K.sum(flat_y_true) + K.sum(flat_y_pred) + 1.)\n",
    "\n",
    "def dice_coef_np(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    return (2. * intersection + 1.) / (np.sum(y_true) + np.sum(y_pred) + 1.)\n",
    "\n",
    "\n",
    "def pixelwise_crossentropy(y_true, y_pred, weights=[0.5,0.5], epsilon=1e-8):\n",
    "    ndim = K.ndim(y_pred)\n",
    "    ncategory = K.int_shape(y_pred)[-1]\n",
    "    # scale predictions so class probabilities of each pixel sum to 1\n",
    "    y_pred /= K.sum(y_pred, axis=(ndim-1), keepdims=True)\n",
    "    y_pred = K.clip(y_pred, epsilon, 1-epsilon)\n",
    "    w = K.constant(weights) * (ncategory / sum(weights))\n",
    "    # first, average over all axis except classes\n",
    "    cross_entropies = -K.mean(y_true * K.log(y_pred), axis=tuple(range(ndim-1)))\n",
    "    return K.sum(w * cross_entropies)\n",
    "\n",
    "\n",
    "def show_plots(history):    \n",
    "    plt.plot(history.history['dice_coef'])\n",
    "    plt.plot(history.history['val_dice_coef'])\n",
    "    plt.title('model dice')\n",
    "    plt.ylabel('dice')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.savefig(os.path.join(save_imgs_dir,\"acc-loss-plot.png\"))\n",
    "model.compile(optimizer=Adam(lr=1e-5),loss=[pixelwise_crossentropy],metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/preprocessing/image.py:653: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (194, 216, 256, 2) (2 channels).\n",
      "/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/preprocessing/image.py:787: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (194, 216, 256, 2) (2 channels).\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "seed = 78\n",
    "\n",
    "validation_split=0.2\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "split_index = int((1 - validation_split) * len(images))\n",
    "\n",
    "train_steps = ceil(split_index / batch_size)\n",
    "val_steps = ceil((len(images)-split_index )/batch_size)\n",
    "\n",
    "train_images = images[:split_index]\n",
    "train_inner_masks = i_masks[:split_index]\n",
    "\n",
    "validation_images = images[split_index:]\n",
    "validation_inner_masks = i_masks[split_index:]\n",
    "\n",
    "\n",
    "data_gen_args = dict(rotation_range=180,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     shear_range=0.1,\n",
    "                     zoom_range=0.05,\n",
    "                     fill_mode='nearest')\n",
    "\n",
    "train_images_datagen = ImageDataGenerator(**data_gen_args)\n",
    "train_masks_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "\n",
    "#seed = 1\n",
    "#height,width,channels = train_images[0].shape\n",
    "#print(train_images[0].shape)\n",
    "#print(train_inner_masks[0].shape)\n",
    "train_images_datagen.fit(train_images,augment=True,seed=seed)\n",
    "train_masks_datagen.fit(train_inner_masks,augment=True,seed=seed)\n",
    "\n",
    "train_images_generator = train_images_datagen.flow(train_images, y=None, seed=seed)\n",
    "train_masks_generator = train_images_datagen.flow(train_inner_masks, y=None, seed=seed)\n",
    "\n",
    "\n",
    "train_generator = zip(train_images_generator, train_masks_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6/7 [========================>.....] - ETA: 3s - loss: 0.6926 - dice_coef: 0.5000Epoch 00000: val_loss improved from inf to 0.69281, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 22s - loss: 0.6926 - dice_coef: 0.5001 - val_loss: 0.6928 - val_dice_coef: 0.5002\n",
      "Epoch 2/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6923 - dice_coef: 0.5002Epoch 00001: val_loss improved from 0.69281 to 0.69239, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.6923 - dice_coef: 0.5003 - val_loss: 0.6924 - val_dice_coef: 0.5004\n",
      "Epoch 3/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6922 - dice_coef: 0.5005Epoch 00002: val_loss improved from 0.69239 to 0.69187, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.6922 - dice_coef: 0.5005 - val_loss: 0.6919 - val_dice_coef: 0.5006\n",
      "Epoch 4/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6921 - dice_coef: 0.5007Epoch 00003: val_loss improved from 0.69187 to 0.69120, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.6920 - dice_coef: 0.5008 - val_loss: 0.6912 - val_dice_coef: 0.5010\n",
      "Epoch 5/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6914 - dice_coef: 0.5011Epoch 00004: val_loss improved from 0.69120 to 0.69019, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.6912 - dice_coef: 0.5012 - val_loss: 0.6902 - val_dice_coef: 0.5015\n",
      "Epoch 6/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6898 - dice_coef: 0.5017Epoch 00005: val_loss improved from 0.69019 to 0.68854, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.6897 - dice_coef: 0.5018 - val_loss: 0.6885 - val_dice_coef: 0.5023\n",
      "Epoch 7/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6876 - dice_coef: 0.5027Epoch 00006: val_loss improved from 0.68854 to 0.68565, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.6875 - dice_coef: 0.5028 - val_loss: 0.6856 - val_dice_coef: 0.5038\n",
      "Epoch 8/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6841 - dice_coef: 0.5046Epoch 00007: val_loss improved from 0.68565 to 0.68030, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.6838 - dice_coef: 0.5047 - val_loss: 0.6803 - val_dice_coef: 0.5065\n",
      "Epoch 9/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6774 - dice_coef: 0.5080Epoch 00008: val_loss improved from 0.68030 to 0.67012, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.6766 - dice_coef: 0.5084 - val_loss: 0.6701 - val_dice_coef: 0.5117\n",
      "Epoch 10/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6643 - dice_coef: 0.5148Epoch 00009: val_loss improved from 0.67012 to 0.65056, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.6630 - dice_coef: 0.5154 - val_loss: 0.6506 - val_dice_coef: 0.5220\n",
      "Epoch 11/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6395 - dice_coef: 0.5281Epoch 00010: val_loss improved from 0.65056 to 0.61348, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.6375 - dice_coef: 0.5291 - val_loss: 0.6135 - val_dice_coef: 0.5424\n",
      "Epoch 12/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.5941 - dice_coef: 0.5538Epoch 00011: val_loss improved from 0.61348 to 0.54681, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.5905 - dice_coef: 0.5560 - val_loss: 0.5468 - val_dice_coef: 0.5820\n",
      "Epoch 13/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.5134 - dice_coef: 0.6044Epoch 00012: val_loss improved from 0.54681 to 0.43930, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.5064 - dice_coef: 0.6094 - val_loss: 0.4393 - val_dice_coef: 0.6550\n",
      "Epoch 14/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.3995 - dice_coef: 0.6888Epoch 00013: val_loss improved from 0.43930 to 0.31042, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.3934 - dice_coef: 0.6947 - val_loss: 0.3104 - val_dice_coef: 0.7630\n",
      "Epoch 15/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.2877 - dice_coef: 0.7961Epoch 00014: val_loss improved from 0.31042 to 0.23059, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.2839 - dice_coef: 0.8035 - val_loss: 0.2306 - val_dice_coef: 0.8617\n",
      "Epoch 16/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.2457 - dice_coef: 0.8721Epoch 00015: val_loss improved from 0.23059 to 0.21652, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.2404 - dice_coef: 0.8765 - val_loss: 0.2165 - val_dice_coef: 0.9041\n",
      "Epoch 17/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.2414 - dice_coef: 0.8985Epoch 00016: val_loss improved from 0.21652 to 0.20693, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.2427 - dice_coef: 0.8976 - val_loss: 0.2069 - val_dice_coef: 0.9090\n",
      "Epoch 18/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.2279 - dice_coef: 0.8961Epoch 00017: val_loss improved from 0.20693 to 0.19674, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.2462 - dice_coef: 0.8906 - val_loss: 0.1967 - val_dice_coef: 0.8968\n",
      "Epoch 19/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.2172 - dice_coef: 0.8831Epoch 00018: val_loss improved from 0.19674 to 0.19499, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.2127 - dice_coef: 0.8844 - val_loss: 0.1950 - val_dice_coef: 0.8829\n",
      "Epoch 20/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.2141 - dice_coef: 0.8751Epoch 00019: val_loss improved from 0.19499 to 0.19044, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.2032 - dice_coef: 0.8800 - val_loss: 0.1904 - val_dice_coef: 0.8847\n",
      "Epoch 21/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.2074 - dice_coef: 0.8822Epoch 00020: val_loss improved from 0.19044 to 0.18382, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.2130 - dice_coef: 0.8799 - val_loss: 0.1838 - val_dice_coef: 0.8947\n",
      "Epoch 22/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.2031 - dice_coef: 0.8905Epoch 00021: val_loss improved from 0.18382 to 0.17996, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.2063 - dice_coef: 0.8900 - val_loss: 0.1800 - val_dice_coef: 0.8995\n",
      "Epoch 23/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.2022 - dice_coef: 0.8924Epoch 00022: val_loss improved from 0.17996 to 0.17762, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.2057 - dice_coef: 0.8923 - val_loss: 0.1776 - val_dice_coef: 0.8995\n",
      "Epoch 24/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1983 - dice_coef: 0.8922Epoch 00023: val_loss improved from 0.17762 to 0.17636, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.2022 - dice_coef: 0.8908 - val_loss: 0.1764 - val_dice_coef: 0.8969\n",
      "Epoch 25/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1978 - dice_coef: 0.8900Epoch 00024: val_loss improved from 0.17636 to 0.17499, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1964 - dice_coef: 0.8906 - val_loss: 0.1750 - val_dice_coef: 0.8961\n",
      "Epoch 26/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1948 - dice_coef: 0.8913Epoch 00025: val_loss improved from 0.17499 to 0.17292, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.2015 - dice_coef: 0.8904 - val_loss: 0.1729 - val_dice_coef: 0.8984\n",
      "Epoch 27/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1955 - dice_coef: 0.8919Epoch 00026: val_loss improved from 0.17292 to 0.17155, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1884 - dice_coef: 0.8946 - val_loss: 0.1715 - val_dice_coef: 0.8988\n",
      "Epoch 28/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1924 - dice_coef: 0.8947Epoch 00027: val_loss improved from 0.17155 to 0.16964, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1836 - dice_coef: 0.8963 - val_loss: 0.1696 - val_dice_coef: 0.9020\n",
      "Epoch 29/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1922 - dice_coef: 0.8983Epoch 00028: val_loss improved from 0.16964 to 0.16797, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1864 - dice_coef: 0.9008 - val_loss: 0.1680 - val_dice_coef: 0.9057\n",
      "Epoch 30/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1911 - dice_coef: 0.9000Epoch 00029: val_loss improved from 0.16797 to 0.16758, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.2016 - dice_coef: 0.8947 - val_loss: 0.1676 - val_dice_coef: 0.9037\n",
      "Epoch 31/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1893 - dice_coef: 0.8970Epoch 00030: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1890 - dice_coef: 0.8971 - val_loss: 0.1686 - val_dice_coef: 0.8981\n",
      "Epoch 32/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1886 - dice_coef: 0.8931Epoch 00031: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1777 - dice_coef: 0.8964 - val_loss: 0.1682 - val_dice_coef: 0.8975\n",
      "Epoch 33/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1890 - dice_coef: 0.8949Epoch 00032: val_loss improved from 0.16758 to 0.16583, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1826 - dice_coef: 0.8971 - val_loss: 0.1658 - val_dice_coef: 0.9032\n",
      "Epoch 34/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1879 - dice_coef: 0.8998Epoch 00033: val_loss improved from 0.16583 to 0.16480, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1837 - dice_coef: 0.9019 - val_loss: 0.1648 - val_dice_coef: 0.9057\n",
      "Epoch 35/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1870 - dice_coef: 0.9002Epoch 00034: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1962 - dice_coef: 0.8974 - val_loss: 0.1652 - val_dice_coef: 0.9018\n",
      "Epoch 36/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1846 - dice_coef: 0.8962Epoch 00035: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1903 - dice_coef: 0.8947 - val_loss: 0.1669 - val_dice_coef: 0.8960\n",
      "Epoch 37/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1850 - dice_coef: 0.8923Epoch 00036: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1848 - dice_coef: 0.8921 - val_loss: 0.1665 - val_dice_coef: 0.8957\n",
      "Epoch 38/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1853 - dice_coef: 0.8932Epoch 00037: val_loss improved from 0.16480 to 0.16411, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1822 - dice_coef: 0.8957 - val_loss: 0.1641 - val_dice_coef: 0.9003\n",
      "Epoch 39/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1841 - dice_coef: 0.8979Epoch 00038: val_loss improved from 0.16411 to 0.16254, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1813 - dice_coef: 0.8981 - val_loss: 0.1625 - val_dice_coef: 0.9041\n",
      "Epoch 40/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1841 - dice_coef: 0.9011Epoch 00039: val_loss improved from 0.16254 to 0.16194, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1782 - dice_coef: 0.9043 - val_loss: 0.1619 - val_dice_coef: 0.9049\n",
      "Epoch 41/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1828 - dice_coef: 0.9009Epoch 00040: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1800 - dice_coef: 0.9012 - val_loss: 0.1621 - val_dice_coef: 0.9027\n",
      "Epoch 42/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1847 - dice_coef: 0.8979Epoch 00041: val_loss improved from 0.16194 to 0.16167, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1737 - dice_coef: 0.9021 - val_loss: 0.1617 - val_dice_coef: 0.9027\n",
      "Epoch 43/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1833 - dice_coef: 0.8996Epoch 00042: val_loss improved from 0.16167 to 0.16063, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1780 - dice_coef: 0.9030 - val_loss: 0.1606 - val_dice_coef: 0.9050\n",
      "Epoch 44/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1828 - dice_coef: 0.8997Epoch 00043: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1815 - dice_coef: 0.9004 - val_loss: 0.1611 - val_dice_coef: 0.9023\n",
      "Epoch 45/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1802 - dice_coef: 0.8990Epoch 00044: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1858 - dice_coef: 0.8973 - val_loss: 0.1615 - val_dice_coef: 0.9001\n",
      "Epoch 46/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1804 - dice_coef: 0.8963Epoch 00045: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1856 - dice_coef: 0.8936 - val_loss: 0.1618 - val_dice_coef: 0.8987\n",
      "Epoch 47/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1807 - dice_coef: 0.8954Epoch 00046: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1852 - dice_coef: 0.8945 - val_loss: 0.1607 - val_dice_coef: 0.9004\n",
      "Epoch 48/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1802 - dice_coef: 0.8972Epoch 00047: val_loss improved from 0.16063 to 0.15992, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1836 - dice_coef: 0.8959 - val_loss: 0.1599 - val_dice_coef: 0.9015\n",
      "Epoch 49/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1788 - dice_coef: 0.8990Epoch 00048: val_loss improved from 0.15992 to 0.15910, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1793 - dice_coef: 0.8993 - val_loss: 0.1591 - val_dice_coef: 0.9027\n",
      "Epoch 50/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1779 - dice_coef: 0.8992Epoch 00049: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1862 - dice_coef: 0.8942 - val_loss: 0.1592 - val_dice_coef: 0.9017\n",
      "Epoch 51/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1769 - dice_coef: 0.9003Epoch 00050: val_loss improved from 0.15910 to 0.15832, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1786 - dice_coef: 0.9006 - val_loss: 0.1583 - val_dice_coef: 0.9032\n",
      "Epoch 52/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1772 - dice_coef: 0.8996Epoch 00051: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1783 - dice_coef: 0.9005 - val_loss: 0.1585 - val_dice_coef: 0.9018\n",
      "Epoch 53/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1782 - dice_coef: 0.8968Epoch 00052: val_loss improved from 0.15832 to 0.15826, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1694 - dice_coef: 0.9005 - val_loss: 0.1583 - val_dice_coef: 0.9015\n",
      "Epoch 54/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1768 - dice_coef: 0.9014Epoch 00053: val_loss improved from 0.15826 to 0.15586, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1689 - dice_coef: 0.9040 - val_loss: 0.1559 - val_dice_coef: 0.9079\n",
      "Epoch 55/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1761 - dice_coef: 0.9058Epoch 00054: val_loss improved from 0.15586 to 0.15554, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1828 - dice_coef: 0.9031 - val_loss: 0.1555 - val_dice_coef: 0.9078\n",
      "Epoch 56/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1738 - dice_coef: 0.9021Epoch 00055: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1841 - dice_coef: 0.8976 - val_loss: 0.1584 - val_dice_coef: 0.8991\n",
      "Epoch 57/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1745 - dice_coef: 0.8950Epoch 00056: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1764 - dice_coef: 0.8930 - val_loss: 0.1583 - val_dice_coef: 0.8986\n",
      "Epoch 58/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1741 - dice_coef: 0.8997Epoch 00057: val_loss improved from 0.15554 to 0.15430, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1767 - dice_coef: 0.8986 - val_loss: 0.1543 - val_dice_coef: 0.9082\n",
      "Epoch 59/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1724 - dice_coef: 0.9068Epoch 00058: val_loss improved from 0.15430 to 0.15363, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1657 - dice_coef: 0.9098 - val_loss: 0.1536 - val_dice_coef: 0.9090\n",
      "Epoch 60/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1726 - dice_coef: 0.9045Epoch 00059: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1697 - dice_coef: 0.9039 - val_loss: 0.1538 - val_dice_coef: 0.9068\n",
      "Epoch 61/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1699 - dice_coef: 0.9059Epoch 00060: val_loss improved from 0.15363 to 0.15308, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1728 - dice_coef: 0.9050 - val_loss: 0.1531 - val_dice_coef: 0.9080\n",
      "Epoch 62/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1690 - dice_coef: 0.9043Epoch 00061: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1759 - dice_coef: 0.9024 - val_loss: 0.1539 - val_dice_coef: 0.9044\n",
      "Epoch 63/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1701 - dice_coef: 0.9000Epoch 00062: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1668 - dice_coef: 0.9017 - val_loss: 0.1537 - val_dice_coef: 0.9038\n",
      "Epoch 64/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1684 - dice_coef: 0.9028Epoch 00063: val_loss improved from 0.15308 to 0.15093, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1618 - dice_coef: 0.9043 - val_loss: 0.1509 - val_dice_coef: 0.9105\n",
      "Epoch 65/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1689 - dice_coef: 0.9096Epoch 00064: val_loss improved from 0.15093 to 0.14971, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1706 - dice_coef: 0.9100 - val_loss: 0.1497 - val_dice_coef: 0.9148\n",
      "Epoch 66/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1671 - dice_coef: 0.9082Epoch 00065: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1642 - dice_coef: 0.9082 - val_loss: 0.1510 - val_dice_coef: 0.9069\n",
      "Epoch 67/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1677 - dice_coef: 0.9032Epoch 00066: val_loss improved from 0.14971 to 0.14966, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1630 - dice_coef: 0.9058 - val_loss: 0.1497 - val_dice_coef: 0.9094\n",
      "Epoch 68/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1660 - dice_coef: 0.9066Epoch 00067: val_loss improved from 0.14966 to 0.14837, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1673 - dice_coef: 0.9043 - val_loss: 0.1484 - val_dice_coef: 0.9121\n",
      "Epoch 69/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1650 - dice_coef: 0.9091Epoch 00068: val_loss improved from 0.14837 to 0.14738, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1627 - dice_coef: 0.9097 - val_loss: 0.1474 - val_dice_coef: 0.9137\n",
      "Epoch 70/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1626 - dice_coef: 0.9099Epoch 00069: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1678 - dice_coef: 0.9079 - val_loss: 0.1475 - val_dice_coef: 0.9105\n",
      "Epoch 71/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1626 - dice_coef: 0.9045Epoch 00070: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1698 - dice_coef: 0.9017 - val_loss: 0.1478 - val_dice_coef: 0.9076\n",
      "Epoch 72/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1596 - dice_coef: 0.9065Epoch 00071: val_loss improved from 0.14738 to 0.14603, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1669 - dice_coef: 0.9047 - val_loss: 0.1460 - val_dice_coef: 0.9108\n",
      "Epoch 73/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1606 - dice_coef: 0.9059Epoch 00072: val_loss improved from 0.14603 to 0.14494, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1571 - dice_coef: 0.9065 - val_loss: 0.1449 - val_dice_coef: 0.9122\n",
      "Epoch 74/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1584 - dice_coef: 0.9122Epoch 00073: val_loss improved from 0.14494 to 0.14289, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1557 - dice_coef: 0.9131 - val_loss: 0.1429 - val_dice_coef: 0.9190\n",
      "Epoch 75/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1579 - dice_coef: 0.9139Epoch 00074: val_loss improved from 0.14289 to 0.14272, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1567 - dice_coef: 0.9139 - val_loss: 0.1427 - val_dice_coef: 0.9146\n",
      "Epoch 76/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1557 - dice_coef: 0.9096Epoch 00075: val_loss improved from 0.14272 to 0.14205, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1543 - dice_coef: 0.9105 - val_loss: 0.1420 - val_dice_coef: 0.9143\n",
      "Epoch 77/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1553 - dice_coef: 0.9110Epoch 00076: val_loss improved from 0.14205 to 0.14028, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1508 - dice_coef: 0.9127 - val_loss: 0.1403 - val_dice_coef: 0.9188\n",
      "Epoch 78/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1519 - dice_coef: 0.9164Epoch 00077: val_loss improved from 0.14028 to 0.13919, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1482 - dice_coef: 0.9179 - val_loss: 0.1392 - val_dice_coef: 0.9197\n",
      "Epoch 79/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1502 - dice_coef: 0.9144Epoch 00078: val_loss improved from 0.13919 to 0.13873, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1520 - dice_coef: 0.9134 - val_loss: 0.1387 - val_dice_coef: 0.9170\n",
      "Epoch 80/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1500 - dice_coef: 0.9126Epoch 00079: val_loss improved from 0.13873 to 0.13705, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1463 - dice_coef: 0.9144 - val_loss: 0.1370 - val_dice_coef: 0.9208\n",
      "Epoch 81/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1473 - dice_coef: 0.9166Epoch 00080: val_loss improved from 0.13705 to 0.13592, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1497 - dice_coef: 0.9144 - val_loss: 0.1359 - val_dice_coef: 0.9218\n",
      "Epoch 82/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1452 - dice_coef: 0.9170Epoch 00081: val_loss improved from 0.13592 to 0.13503, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1420 - dice_coef: 0.9190 - val_loss: 0.1350 - val_dice_coef: 0.9214\n",
      "Epoch 83/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1447 - dice_coef: 0.9177Epoch 00082: val_loss improved from 0.13503 to 0.13413, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1461 - dice_coef: 0.9173 - val_loss: 0.1341 - val_dice_coef: 0.9228\n",
      "Epoch 84/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1432 - dice_coef: 0.9138Epoch 00083: val_loss improved from 0.13413 to 0.13301, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1386 - dice_coef: 0.9167 - val_loss: 0.1330 - val_dice_coef: 0.9253\n",
      "Epoch 85/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1424 - dice_coef: 0.9230Epoch 00084: val_loss improved from 0.13301 to 0.13229, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1360 - dice_coef: 0.9258 - val_loss: 0.1323 - val_dice_coef: 0.9259\n",
      "Epoch 86/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1391 - dice_coef: 0.9180Epoch 00085: val_loss improved from 0.13229 to 0.13165, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1343 - dice_coef: 0.9197 - val_loss: 0.1317 - val_dice_coef: 0.9249\n",
      "Epoch 87/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1392 - dice_coef: 0.9222Epoch 00086: val_loss improved from 0.13165 to 0.13102, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1351 - dice_coef: 0.9244 - val_loss: 0.1310 - val_dice_coef: 0.9271\n",
      "Epoch 88/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1373 - dice_coef: 0.9193Epoch 00087: val_loss improved from 0.13102 to 0.13038, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1386 - dice_coef: 0.9189 - val_loss: 0.1304 - val_dice_coef: 0.9253\n",
      "Epoch 89/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1351 - dice_coef: 0.9212Epoch 00088: val_loss improved from 0.13038 to 0.12993, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1393 - dice_coef: 0.9191 - val_loss: 0.1299 - val_dice_coef: 0.9271\n",
      "Epoch 90/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1359 - dice_coef: 0.9188Epoch 00089: val_loss improved from 0.12993 to 0.12988, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1322 - dice_coef: 0.9209 - val_loss: 0.1299 - val_dice_coef: 0.9304\n",
      "Epoch 91/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1332 - dice_coef: 0.9257Epoch 00090: val_loss improved from 0.12988 to 0.12925, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1313 - dice_coef: 0.9266 - val_loss: 0.1292 - val_dice_coef: 0.9270\n",
      "Epoch 92/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1324 - dice_coef: 0.9197Epoch 00091: val_loss improved from 0.12925 to 0.12911, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1393 - dice_coef: 0.9160 - val_loss: 0.1291 - val_dice_coef: 0.9290\n",
      "Epoch 93/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1322 - dice_coef: 0.9227Epoch 00092: val_loss improved from 0.12911 to 0.12880, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1353 - dice_coef: 0.9205 - val_loss: 0.1288 - val_dice_coef: 0.9274\n",
      "Epoch 94/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1310 - dice_coef: 0.9214Epoch 00093: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1318 - dice_coef: 0.9220 - val_loss: 0.1290 - val_dice_coef: 0.9303\n",
      "Epoch 95/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1318 - dice_coef: 0.9223Epoch 00094: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1249 - dice_coef: 0.9251 - val_loss: 0.1293 - val_dice_coef: 0.9319\n",
      "Epoch 96/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1307 - dice_coef: 0.9279Epoch 00095: val_loss improved from 0.12880 to 0.12864, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1286 - dice_coef: 0.9290 - val_loss: 0.1286 - val_dice_coef: 0.9252\n",
      "Epoch 97/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1311 - dice_coef: 0.9188Epoch 00096: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1260 - dice_coef: 0.9212 - val_loss: 0.1305 - val_dice_coef: 0.9352\n",
      "Epoch 98/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1308 - dice_coef: 0.9302Epoch 00097: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1338 - dice_coef: 0.9278 - val_loss: 0.1292 - val_dice_coef: 0.9206\n",
      "Epoch 99/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1321 - dice_coef: 0.9136Epoch 00098: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1348 - dice_coef: 0.9140 - val_loss: 0.1295 - val_dice_coef: 0.9337\n",
      "Epoch 100/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1306 - dice_coef: 0.9289Epoch 00099: val_loss improved from 0.12864 to 0.12764, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1293 - dice_coef: 0.9297 - val_loss: 0.1276 - val_dice_coef: 0.9264\n",
      "Epoch 101/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1280 - dice_coef: 0.9203Epoch 00100: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1260 - dice_coef: 0.9211 - val_loss: 0.1283 - val_dice_coef: 0.9321\n",
      "Epoch 102/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1279 - dice_coef: 0.9292Epoch 00101: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1260 - dice_coef: 0.9292 - val_loss: 0.1278 - val_dice_coef: 0.9302\n",
      "Epoch 103/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1276 - dice_coef: 0.9226Epoch 00102: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1259 - dice_coef: 0.9235 - val_loss: 0.1281 - val_dice_coef: 0.9315\n",
      "Epoch 104/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1260 - dice_coef: 0.9268Epoch 00103: val_loss improved from 0.12764 to 0.12752, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1229 - dice_coef: 0.9301 - val_loss: 0.1275 - val_dice_coef: 0.9283\n",
      "Epoch 105/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1262 - dice_coef: 0.9226Epoch 00104: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1231 - dice_coef: 0.9256 - val_loss: 0.1284 - val_dice_coef: 0.9316\n",
      "Epoch 106/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1274 - dice_coef: 0.9260Epoch 00105: val_loss improved from 0.12752 to 0.12748, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1224 - dice_coef: 0.9297 - val_loss: 0.1275 - val_dice_coef: 0.9280\n",
      "Epoch 107/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1257 - dice_coef: 0.9231Epoch 00106: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1247 - dice_coef: 0.9238 - val_loss: 0.1276 - val_dice_coef: 0.9302\n",
      "Epoch 108/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1249 - dice_coef: 0.9267Epoch 00107: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1252 - dice_coef: 0.9265 - val_loss: 0.1276 - val_dice_coef: 0.9291\n",
      "Epoch 109/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1258 - dice_coef: 0.9236Epoch 00108: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1230 - dice_coef: 0.9258 - val_loss: 0.1290 - val_dice_coef: 0.9326\n",
      "Epoch 110/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1243 - dice_coef: 0.9275Epoch 00109: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1265 - dice_coef: 0.9258 - val_loss: 0.1284 - val_dice_coef: 0.9299\n",
      "Epoch 111/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1246 - dice_coef: 0.9265Epoch 00110: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1229 - dice_coef: 0.9282 - val_loss: 0.1287 - val_dice_coef: 0.9305\n",
      "Epoch 112/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1243 - dice_coef: 0.9247Epoch 00111: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1290 - dice_coef: 0.9228 - val_loss: 0.1279 - val_dice_coef: 0.9289\n",
      "Epoch 113/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1242 - dice_coef: 0.9237Epoch 00112: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1227 - dice_coef: 0.9261 - val_loss: 0.1285 - val_dice_coef: 0.9318\n",
      "Epoch 114/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1240 - dice_coef: 0.9280Epoch 00113: val_loss improved from 0.12748 to 0.12740, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1283 - dice_coef: 0.9252 - val_loss: 0.1274 - val_dice_coef: 0.9282\n",
      "Epoch 115/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1239 - dice_coef: 0.9238Epoch 00114: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1260 - dice_coef: 0.9228 - val_loss: 0.1275 - val_dice_coef: 0.9306\n",
      "Epoch 116/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1233 - dice_coef: 0.9261Epoch 00115: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1234 - dice_coef: 0.9254 - val_loss: 0.1282 - val_dice_coef: 0.9326\n",
      "Epoch 117/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1224 - dice_coef: 0.9298Epoch 00116: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1205 - dice_coef: 0.9287 - val_loss: 0.1281 - val_dice_coef: 0.9321\n",
      "Epoch 118/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1242 - dice_coef: 0.9279Epoch 00117: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1212 - dice_coef: 0.9293 - val_loss: 0.1279 - val_dice_coef: 0.9333\n",
      "Epoch 119/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1216 - dice_coef: 0.9299Epoch 00118: val_loss improved from 0.12740 to 0.12645, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1294 - dice_coef: 0.9242 - val_loss: 0.1265 - val_dice_coef: 0.9282\n",
      "Epoch 120/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1231 - dice_coef: 0.9220Epoch 00119: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1191 - dice_coef: 0.9242 - val_loss: 0.1282 - val_dice_coef: 0.9350\n",
      "Epoch 121/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1239 - dice_coef: 0.9304Epoch 00120: val_loss improved from 0.12645 to 0.12615, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1231 - dice_coef: 0.9302 - val_loss: 0.1261 - val_dice_coef: 0.9294\n",
      "Epoch 122/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1219 - dice_coef: 0.9266Epoch 00121: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1201 - dice_coef: 0.9281 - val_loss: 0.1271 - val_dice_coef: 0.9332\n",
      "Epoch 123/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1216 - dice_coef: 0.9267Epoch 00122: val_loss improved from 0.12615 to 0.12607, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1189 - dice_coef: 0.9281 - val_loss: 0.1261 - val_dice_coef: 0.9316\n",
      "Epoch 124/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1217 - dice_coef: 0.9280Epoch 00123: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1173 - dice_coef: 0.9295 - val_loss: 0.1264 - val_dice_coef: 0.9329\n",
      "Epoch 125/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1210 - dice_coef: 0.9305Epoch 00124: val_loss improved from 0.12607 to 0.12580, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1221 - dice_coef: 0.9292 - val_loss: 0.1258 - val_dice_coef: 0.9278\n",
      "Epoch 126/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1223 - dice_coef: 0.9227Epoch 00125: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1247 - dice_coef: 0.9229 - val_loss: 0.1264 - val_dice_coef: 0.9325\n",
      "Epoch 127/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1212 - dice_coef: 0.9273Epoch 00126: val_loss improved from 0.12580 to 0.12548, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1170 - dice_coef: 0.9315 - val_loss: 0.1255 - val_dice_coef: 0.9302\n",
      "Epoch 128/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1195 - dice_coef: 0.9263Epoch 00127: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1181 - dice_coef: 0.9272 - val_loss: 0.1260 - val_dice_coef: 0.9339\n",
      "Epoch 129/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1192 - dice_coef: 0.9309Epoch 00128: val_loss improved from 0.12548 to 0.12508, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1196 - dice_coef: 0.9313 - val_loss: 0.1251 - val_dice_coef: 0.9247\n",
      "Epoch 130/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1230 - dice_coef: 0.9194Epoch 00129: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1242 - dice_coef: 0.9212 - val_loss: 0.1251 - val_dice_coef: 0.9328\n",
      "Epoch 131/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1205 - dice_coef: 0.9287Epoch 00130: val_loss improved from 0.12508 to 0.12409, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1193 - dice_coef: 0.9282 - val_loss: 0.1241 - val_dice_coef: 0.9301\n",
      "Epoch 132/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1201 - dice_coef: 0.9291Epoch 00131: val_loss improved from 0.12409 to 0.12382, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1209 - dice_coef: 0.9286 - val_loss: 0.1238 - val_dice_coef: 0.9296\n",
      "Epoch 133/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1205 - dice_coef: 0.9256Epoch 00132: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1194 - dice_coef: 0.9263 - val_loss: 0.1242 - val_dice_coef: 0.9324\n",
      "Epoch 134/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1182 - dice_coef: 0.9296Epoch 00133: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1234 - dice_coef: 0.9267 - val_loss: 0.1241 - val_dice_coef: 0.9307\n",
      "Epoch 135/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1198 - dice_coef: 0.9252Epoch 00134: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1146 - dice_coef: 0.9276 - val_loss: 0.1255 - val_dice_coef: 0.9356\n",
      "Epoch 136/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1198 - dice_coef: 0.9323Epoch 00135: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1209 - dice_coef: 0.9309 - val_loss: 0.1241 - val_dice_coef: 0.9313\n",
      "Epoch 137/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1201 - dice_coef: 0.9260Epoch 00136: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1166 - dice_coef: 0.9294 - val_loss: 0.1241 - val_dice_coef: 0.9314\n",
      "Epoch 138/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1184 - dice_coef: 0.9273Epoch 00137: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1139 - dice_coef: 0.9302 - val_loss: 0.1245 - val_dice_coef: 0.9338\n",
      "Epoch 139/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1170 - dice_coef: 0.9316Epoch 00138: val_loss improved from 0.12382 to 0.12371, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1241 - dice_coef: 0.9259 - val_loss: 0.1237 - val_dice_coef: 0.9299\n",
      "Epoch 140/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1181 - dice_coef: 0.9273Epoch 00139: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1148 - dice_coef: 0.9297 - val_loss: 0.1245 - val_dice_coef: 0.9340\n",
      "Epoch 141/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1176 - dice_coef: 0.9295Epoch 00140: val_loss improved from 0.12371 to 0.12367, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1214 - dice_coef: 0.9262 - val_loss: 0.1237 - val_dice_coef: 0.9311\n",
      "Epoch 142/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1186 - dice_coef: 0.9280Epoch 00141: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1142 - dice_coef: 0.9306 - val_loss: 0.1250 - val_dice_coef: 0.9354\n",
      "Epoch 143/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1179 - dice_coef: 0.9306Epoch 00142: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1152 - dice_coef: 0.9313 - val_loss: 0.1241 - val_dice_coef: 0.9336\n",
      "Epoch 144/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1171 - dice_coef: 0.9309Epoch 00143: val_loss improved from 0.12367 to 0.12365, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1202 - dice_coef: 0.9275 - val_loss: 0.1236 - val_dice_coef: 0.9326\n",
      "Epoch 145/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1171 - dice_coef: 0.9284Epoch 00144: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1127 - dice_coef: 0.9314 - val_loss: 0.1237 - val_dice_coef: 0.9341\n",
      "Epoch 146/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1170 - dice_coef: 0.9313Epoch 00145: val_loss improved from 0.12365 to 0.12345, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1199 - dice_coef: 0.9295 - val_loss: 0.1234 - val_dice_coef: 0.9308\n",
      "Epoch 147/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1177 - dice_coef: 0.9269Epoch 00146: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1156 - dice_coef: 0.9304 - val_loss: 0.1242 - val_dice_coef: 0.9345\n",
      "Epoch 148/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1168 - dice_coef: 0.9279Epoch 00147: val_loss improved from 0.12345 to 0.12259, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1217 - dice_coef: 0.9262 - val_loss: 0.1226 - val_dice_coef: 0.9307\n",
      "Epoch 149/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1168 - dice_coef: 0.9267Epoch 00148: val_loss improved from 0.12259 to 0.12247, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1171 - dice_coef: 0.9284 - val_loss: 0.1225 - val_dice_coef: 0.9319\n",
      "Epoch 150/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1167 - dice_coef: 0.9276Epoch 00149: val_loss improved from 0.12247 to 0.12219, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1216 - dice_coef: 0.9238 - val_loss: 0.1222 - val_dice_coef: 0.9322\n",
      "Epoch 151/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1162 - dice_coef: 0.9294Epoch 00150: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1138 - dice_coef: 0.9294 - val_loss: 0.1239 - val_dice_coef: 0.9369\n",
      "Epoch 152/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1175 - dice_coef: 0.9353Epoch 00151: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1247 - dice_coef: 0.9292 - val_loss: 0.1230 - val_dice_coef: 0.9290\n",
      "Epoch 153/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1164 - dice_coef: 0.9259Epoch 00152: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1131 - dice_coef: 0.9286 - val_loss: 0.1237 - val_dice_coef: 0.9365\n",
      "Epoch 154/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1158 - dice_coef: 0.9317Epoch 00153: val_loss improved from 0.12219 to 0.12199, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1189 - dice_coef: 0.9287 - val_loss: 0.1220 - val_dice_coef: 0.9306\n",
      "Epoch 155/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1165 - dice_coef: 0.9278Epoch 00154: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1128 - dice_coef: 0.9300 - val_loss: 0.1229 - val_dice_coef: 0.9353\n",
      "Epoch 156/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1155 - dice_coef: 0.9325Epoch 00155: val_loss improved from 0.12199 to 0.12170, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1164 - dice_coef: 0.9323 - val_loss: 0.1217 - val_dice_coef: 0.9309\n",
      "Epoch 157/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1153 - dice_coef: 0.9266Epoch 00156: val_loss improved from 0.12170 to 0.12140, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1198 - dice_coef: 0.9249 - val_loss: 0.1214 - val_dice_coef: 0.9337\n",
      "Epoch 158/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1142 - dice_coef: 0.9304Epoch 00157: val_loss improved from 0.12140 to 0.12102, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1145 - dice_coef: 0.9326 - val_loss: 0.1210 - val_dice_coef: 0.9310\n",
      "Epoch 159/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1161 - dice_coef: 0.9267Epoch 00158: val_loss improved from 0.12102 to 0.12076, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1195 - dice_coef: 0.9248 - val_loss: 0.1208 - val_dice_coef: 0.9349\n",
      "Epoch 160/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1156 - dice_coef: 0.9301Epoch 00159: val_loss improved from 0.12076 to 0.12029, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1144 - dice_coef: 0.9300 - val_loss: 0.1203 - val_dice_coef: 0.9342\n",
      "Epoch 161/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1141 - dice_coef: 0.9315Epoch 00160: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1148 - dice_coef: 0.9293 - val_loss: 0.1207 - val_dice_coef: 0.9353\n",
      "Epoch 162/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1156 - dice_coef: 0.9306Epoch 00161: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1168 - dice_coef: 0.9302 - val_loss: 0.1205 - val_dice_coef: 0.9334\n",
      "Epoch 163/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1143 - dice_coef: 0.9299Epoch 00162: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1199 - dice_coef: 0.9255 - val_loss: 0.1206 - val_dice_coef: 0.9333\n",
      "Epoch 164/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1149 - dice_coef: 0.9291Epoch 00163: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1117 - dice_coef: 0.9305 - val_loss: 0.1216 - val_dice_coef: 0.9372\n",
      "Epoch 165/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1152 - dice_coef: 0.9344Epoch 00164: val_loss improved from 0.12029 to 0.11994, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1154 - dice_coef: 0.9335 - val_loss: 0.1199 - val_dice_coef: 0.9307\n",
      "Epoch 166/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1147 - dice_coef: 0.9261Epoch 00165: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1191 - dice_coef: 0.9228 - val_loss: 0.1209 - val_dice_coef: 0.9376\n",
      "Epoch 167/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1142 - dice_coef: 0.9325Epoch 00166: val_loss improved from 0.11994 to 0.11945, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1117 - dice_coef: 0.9328 - val_loss: 0.1194 - val_dice_coef: 0.9335\n",
      "Epoch 168/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1159 - dice_coef: 0.9309Epoch 00167: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1142 - dice_coef: 0.9328 - val_loss: 0.1199 - val_dice_coef: 0.9337\n",
      "Epoch 169/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1139 - dice_coef: 0.9271Epoch 00168: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1190 - dice_coef: 0.9236 - val_loss: 0.1206 - val_dice_coef: 0.9371\n",
      "Epoch 170/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1128 - dice_coef: 0.9334Epoch 00169: val_loss improved from 0.11945 to 0.11917, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1171 - dice_coef: 0.9313 - val_loss: 0.1192 - val_dice_coef: 0.9325\n",
      "Epoch 171/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1140 - dice_coef: 0.9283Epoch 00170: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1122 - dice_coef: 0.9292 - val_loss: 0.1193 - val_dice_coef: 0.9355\n",
      "Epoch 172/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1140 - dice_coef: 0.9312Epoch 00171: val_loss improved from 0.11917 to 0.11874, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1164 - dice_coef: 0.9285 - val_loss: 0.1187 - val_dice_coef: 0.9354\n",
      "Epoch 173/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1120 - dice_coef: 0.9330Epoch 00172: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1173 - dice_coef: 0.9282 - val_loss: 0.1192 - val_dice_coef: 0.9360\n",
      "Epoch 174/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1128 - dice_coef: 0.9316Epoch 00173: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1131 - dice_coef: 0.9309 - val_loss: 0.1188 - val_dice_coef: 0.9344\n",
      "Epoch 175/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1131 - dice_coef: 0.9318Epoch 00174: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1179 - dice_coef: 0.9283 - val_loss: 0.1188 - val_dice_coef: 0.9356\n",
      "Epoch 176/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1132 - dice_coef: 0.9299Epoch 00175: val_loss improved from 0.11874 to 0.11833, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1130 - dice_coef: 0.9311 - val_loss: 0.1183 - val_dice_coef: 0.9346\n",
      "Epoch 177/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1129 - dice_coef: 0.9300Epoch 00176: val_loss improved from 0.11833 to 0.11768, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1128 - dice_coef: 0.9298 - val_loss: 0.1177 - val_dice_coef: 0.9350\n",
      "Epoch 178/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1116 - dice_coef: 0.9317Epoch 00177: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1183 - dice_coef: 0.9270 - val_loss: 0.1178 - val_dice_coef: 0.9354\n",
      "Epoch 179/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1115 - dice_coef: 0.9328Epoch 00178: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1168 - dice_coef: 0.9288 - val_loss: 0.1181 - val_dice_coef: 0.9342\n",
      "Epoch 180/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1130 - dice_coef: 0.9297Epoch 00179: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1143 - dice_coef: 0.9338 - val_loss: 0.1182 - val_dice_coef: 0.9337\n",
      "Epoch 181/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1125 - dice_coef: 0.9280Epoch 00180: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1063 - dice_coef: 0.9336 - val_loss: 0.1177 - val_dice_coef: 0.9374\n",
      "Epoch 182/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1130 - dice_coef: 0.9310Epoch 00181: val_loss improved from 0.11768 to 0.11690, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1082 - dice_coef: 0.9336 - val_loss: 0.1169 - val_dice_coef: 0.9359\n",
      "Epoch 183/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1130 - dice_coef: 0.9312Epoch 00182: val_loss improved from 0.11690 to 0.11668, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1083 - dice_coef: 0.9344 - val_loss: 0.1167 - val_dice_coef: 0.9356\n",
      "Epoch 184/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1122 - dice_coef: 0.9314Epoch 00183: val_loss improved from 0.11668 to 0.11653, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1130 - dice_coef: 0.9326 - val_loss: 0.1165 - val_dice_coef: 0.9318\n",
      "Epoch 185/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1123 - dice_coef: 0.9276Epoch 00184: val_loss improved from 0.11653 to 0.11639, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1136 - dice_coef: 0.9273 - val_loss: 0.1164 - val_dice_coef: 0.9374\n",
      "Epoch 186/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1116 - dice_coef: 0.9323Epoch 00185: val_loss improved from 0.11639 to 0.11564, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1081 - dice_coef: 0.9346 - val_loss: 0.1156 - val_dice_coef: 0.9358\n",
      "Epoch 187/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1104 - dice_coef: 0.9322Epoch 00186: val_loss improved from 0.11564 to 0.11563, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1128 - dice_coef: 0.9308 - val_loss: 0.1156 - val_dice_coef: 0.9337\n",
      "Epoch 188/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1118 - dice_coef: 0.9292Epoch 00187: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1052 - dice_coef: 0.9330 - val_loss: 0.1177 - val_dice_coef: 0.9401\n",
      "Epoch 189/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1123 - dice_coef: 0.9351Epoch 00188: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1108 - dice_coef: 0.9354 - val_loss: 0.1170 - val_dice_coef: 0.9298\n",
      "Epoch 190/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1124 - dice_coef: 0.9284Epoch 00189: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1142 - dice_coef: 0.9282 - val_loss: 0.1182 - val_dice_coef: 0.9397\n",
      "Epoch 191/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1112 - dice_coef: 0.9327Epoch 00190: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1109 - dice_coef: 0.9331 - val_loss: 0.1164 - val_dice_coef: 0.9322\n",
      "Epoch 192/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1120 - dice_coef: 0.9295Epoch 00191: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1056 - dice_coef: 0.9336 - val_loss: 0.1208 - val_dice_coef: 0.9429\n",
      "Epoch 193/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1145 - dice_coef: 0.9358Epoch 00192: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1191 - dice_coef: 0.9307 - val_loss: 0.1176 - val_dice_coef: 0.9271\n",
      "Epoch 194/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1128 - dice_coef: 0.9267Epoch 00193: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1073 - dice_coef: 0.9315 - val_loss: 0.1189 - val_dice_coef: 0.9420\n",
      "Epoch 195/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1121 - dice_coef: 0.9332Epoch 00194: val_loss improved from 0.11563 to 0.11555, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1103 - dice_coef: 0.9329 - val_loss: 0.1155 - val_dice_coef: 0.9322\n",
      "Epoch 196/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1106 - dice_coef: 0.9323Epoch 00195: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1087 - dice_coef: 0.9330 - val_loss: 0.1177 - val_dice_coef: 0.9405\n",
      "Epoch 197/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1106 - dice_coef: 0.9332Epoch 00196: val_loss improved from 0.11555 to 0.11536, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1117 - dice_coef: 0.9320 - val_loss: 0.1154 - val_dice_coef: 0.9347\n",
      "Epoch 198/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1110 - dice_coef: 0.9309Epoch 00197: val_loss improved from 0.11536 to 0.11529, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1090 - dice_coef: 0.9336 - val_loss: 0.1153 - val_dice_coef: 0.9373\n",
      "Epoch 199/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1108 - dice_coef: 0.9307Epoch 00198: val_loss improved from 0.11529 to 0.11529, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1115 - dice_coef: 0.9302 - val_loss: 0.1153 - val_dice_coef: 0.9377\n",
      "Epoch 200/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1094 - dice_coef: 0.9338Epoch 00199: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1117 - dice_coef: 0.9314 - val_loss: 0.1153 - val_dice_coef: 0.9382\n",
      "Epoch 201/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1094 - dice_coef: 0.9341Epoch 00200: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1093 - dice_coef: 0.9330 - val_loss: 0.1154 - val_dice_coef: 0.9374\n",
      "Epoch 202/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1096 - dice_coef: 0.9327Epoch 00201: val_loss improved from 0.11529 to 0.11443, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1046 - dice_coef: 0.9353 - val_loss: 0.1144 - val_dice_coef: 0.9383\n",
      "Epoch 203/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1096 - dice_coef: 0.9340Epoch 00202: val_loss improved from 0.11443 to 0.11385, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1096 - dice_coef: 0.9349 - val_loss: 0.1138 - val_dice_coef: 0.9334\n",
      "Epoch 204/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1100 - dice_coef: 0.9276Epoch 00203: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1161 - dice_coef: 0.9234 - val_loss: 0.1158 - val_dice_coef: 0.9413\n",
      "Epoch 205/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1109 - dice_coef: 0.9349Epoch 00204: val_loss improved from 0.11385 to 0.11365, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1056 - dice_coef: 0.9385 - val_loss: 0.1136 - val_dice_coef: 0.9324\n",
      "Epoch 206/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1092 - dice_coef: 0.9293Epoch 00205: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1165 - dice_coef: 0.9250 - val_loss: 0.1153 - val_dice_coef: 0.9412\n",
      "Epoch 207/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1089 - dice_coef: 0.9333Epoch 00206: val_loss improved from 0.11365 to 0.11298, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1106 - dice_coef: 0.9316 - val_loss: 0.1130 - val_dice_coef: 0.9334\n",
      "Epoch 208/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1092 - dice_coef: 0.9327Epoch 00207: val_loss improved from 0.11298 to 0.11284, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1149 - dice_coef: 0.9292 - val_loss: 0.1128 - val_dice_coef: 0.9369\n",
      "Epoch 209/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1096 - dice_coef: 0.9285Epoch 00208: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1076 - dice_coef: 0.9308 - val_loss: 0.1136 - val_dice_coef: 0.9387\n",
      "Epoch 210/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1093 - dice_coef: 0.9345Epoch 00209: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1103 - dice_coef: 0.9360 - val_loss: 0.1135 - val_dice_coef: 0.9345\n",
      "Epoch 211/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1091 - dice_coef: 0.9299Epoch 00210: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1104 - dice_coef: 0.9286 - val_loss: 0.1165 - val_dice_coef: 0.9421\n",
      "Epoch 212/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1097 - dice_coef: 0.9349Epoch 00211: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1077 - dice_coef: 0.9343 - val_loss: 0.1132 - val_dice_coef: 0.9357\n",
      "Epoch 213/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1094 - dice_coef: 0.9337Epoch 00212: val_loss improved from 0.11284 to 0.11246, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1081 - dice_coef: 0.9360 - val_loss: 0.1125 - val_dice_coef: 0.9343\n",
      "Epoch 214/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1093 - dice_coef: 0.9289Epoch 00213: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1085 - dice_coef: 0.9290 - val_loss: 0.1133 - val_dice_coef: 0.9403\n",
      "Epoch 215/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1089 - dice_coef: 0.9367Epoch 00214: val_loss improved from 0.11246 to 0.11231, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1152 - dice_coef: 0.9316 - val_loss: 0.1123 - val_dice_coef: 0.9326\n",
      "Epoch 216/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1102 - dice_coef: 0.9286Epoch 00215: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1049 - dice_coef: 0.9328 - val_loss: 0.1146 - val_dice_coef: 0.9422\n",
      "Epoch 217/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1092 - dice_coef: 0.9331Epoch 00216: val_loss improved from 0.11231 to 0.11158, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1126 - dice_coef: 0.9297 - val_loss: 0.1116 - val_dice_coef: 0.9364\n",
      "Epoch 218/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1069 - dice_coef: 0.9342Epoch 00217: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1112 - dice_coef: 0.9319 - val_loss: 0.1118 - val_dice_coef: 0.9381\n",
      "Epoch 219/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1096 - dice_coef: 0.9290Epoch 00218: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1120 - dice_coef: 0.9271 - val_loss: 0.1127 - val_dice_coef: 0.9402\n",
      "Epoch 220/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1084 - dice_coef: 0.9354Epoch 00219: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1065 - dice_coef: 0.9374 - val_loss: 0.1120 - val_dice_coef: 0.9360\n",
      "Epoch 221/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1089 - dice_coef: 0.9308Epoch 00220: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1091 - dice_coef: 0.9319 - val_loss: 0.1136 - val_dice_coef: 0.9393\n",
      "Epoch 222/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1074 - dice_coef: 0.9336Epoch 00221: val_loss improved from 0.11158 to 0.11109, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1099 - dice_coef: 0.9326 - val_loss: 0.1111 - val_dice_coef: 0.9351\n",
      "Epoch 223/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1098 - dice_coef: 0.9285Epoch 00222: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1080 - dice_coef: 0.9292 - val_loss: 0.1140 - val_dice_coef: 0.9433\n",
      "Epoch 224/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1106 - dice_coef: 0.9372Epoch 00223: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1104 - dice_coef: 0.9349 - val_loss: 0.1112 - val_dice_coef: 0.9357\n",
      "Epoch 225/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1068 - dice_coef: 0.9340Epoch 00224: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1065 - dice_coef: 0.9342 - val_loss: 0.1128 - val_dice_coef: 0.9410\n",
      "Epoch 226/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1089 - dice_coef: 0.9307Epoch 00225: val_loss improved from 0.11109 to 0.11056, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1057 - dice_coef: 0.9333 - val_loss: 0.1106 - val_dice_coef: 0.9400\n",
      "Epoch 227/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1082 - dice_coef: 0.9370Epoch 00226: val_loss improved from 0.11056 to 0.10914, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1073 - dice_coef: 0.9384 - val_loss: 0.1091 - val_dice_coef: 0.9348\n",
      "Epoch 228/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1092 - dice_coef: 0.9276Epoch 00227: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1070 - dice_coef: 0.9296 - val_loss: 0.1100 - val_dice_coef: 0.9413\n",
      "Epoch 229/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1084 - dice_coef: 0.9356Epoch 00228: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1067 - dice_coef: 0.9353 - val_loss: 0.1092 - val_dice_coef: 0.9374\n",
      "Epoch 230/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1079 - dice_coef: 0.9334Epoch 00229: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1048 - dice_coef: 0.9352 - val_loss: 0.1126 - val_dice_coef: 0.9431\n",
      "Epoch 231/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1095 - dice_coef: 0.9346Epoch 00230: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1060 - dice_coef: 0.9362 - val_loss: 0.1105 - val_dice_coef: 0.9358\n",
      "Epoch 232/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1072 - dice_coef: 0.9326Epoch 00231: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1077 - dice_coef: 0.9313 - val_loss: 0.1125 - val_dice_coef: 0.9437\n",
      "Epoch 233/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1078 - dice_coef: 0.9366Epoch 00232: val_loss improved from 0.10914 to 0.10888, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1056 - dice_coef: 0.9366 - val_loss: 0.1089 - val_dice_coef: 0.9354\n",
      "Epoch 234/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1071 - dice_coef: 0.9335Epoch 00233: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1141 - dice_coef: 0.9293 - val_loss: 0.1097 - val_dice_coef: 0.9407\n",
      "Epoch 235/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1073 - dice_coef: 0.9309Epoch 00234: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0980 - dice_coef: 0.9375 - val_loss: 0.1095 - val_dice_coef: 0.9412\n",
      "Epoch 236/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1064 - dice_coef: 0.9355Epoch 00235: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1080 - dice_coef: 0.9343 - val_loss: 0.1099 - val_dice_coef: 0.9385\n",
      "Epoch 237/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1076 - dice_coef: 0.9313Epoch 00236: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1132 - dice_coef: 0.9306 - val_loss: 0.1126 - val_dice_coef: 0.9427\n",
      "Epoch 238/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1069 - dice_coef: 0.9357Epoch 00237: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1010 - dice_coef: 0.9388 - val_loss: 0.1101 - val_dice_coef: 0.9383\n",
      "Epoch 239/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1076 - dice_coef: 0.9329Epoch 00238: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1061 - dice_coef: 0.9340 - val_loss: 0.1090 - val_dice_coef: 0.9416\n",
      "Epoch 240/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1051 - dice_coef: 0.9347Epoch 00239: val_loss improved from 0.10888 to 0.10771, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1069 - dice_coef: 0.9337 - val_loss: 0.1077 - val_dice_coef: 0.9380\n",
      "Epoch 241/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1058 - dice_coef: 0.9323Epoch 00240: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1078 - dice_coef: 0.9295 - val_loss: 0.1100 - val_dice_coef: 0.9450\n",
      "Epoch 242/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1089 - dice_coef: 0.9389Epoch 00241: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1107 - dice_coef: 0.9382 - val_loss: 0.1087 - val_dice_coef: 0.9307\n",
      "Epoch 243/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1090 - dice_coef: 0.9267Epoch 00242: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1068 - dice_coef: 0.9296 - val_loss: 0.1130 - val_dice_coef: 0.9464\n",
      "Epoch 244/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1086 - dice_coef: 0.9364Epoch 00243: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1108 - dice_coef: 0.9341 - val_loss: 0.1079 - val_dice_coef: 0.9321\n",
      "Epoch 245/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1077 - dice_coef: 0.9293Epoch 00244: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1070 - dice_coef: 0.9318 - val_loss: 0.1107 - val_dice_coef: 0.9440\n",
      "Epoch 246/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1064 - dice_coef: 0.9351Epoch 00245: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1098 - dice_coef: 0.9318 - val_loss: 0.1091 - val_dice_coef: 0.9365\n",
      "Epoch 247/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1067 - dice_coef: 0.9330Epoch 00246: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1037 - dice_coef: 0.9350 - val_loss: 0.1087 - val_dice_coef: 0.9430\n",
      "Epoch 248/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1064 - dice_coef: 0.9344Epoch 00247: val_loss improved from 0.10771 to 0.10607, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1040 - dice_coef: 0.9356 - val_loss: 0.1061 - val_dice_coef: 0.9388\n",
      "Epoch 249/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1064 - dice_coef: 0.9337Epoch 00248: val_loss improved from 0.10607 to 0.10602, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1045 - dice_coef: 0.9352 - val_loss: 0.1060 - val_dice_coef: 0.9409\n",
      "Epoch 250/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1051 - dice_coef: 0.9336Epoch 00249: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1029 - dice_coef: 0.9351 - val_loss: 0.1068 - val_dice_coef: 0.9406\n",
      "Epoch 251/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1061 - dice_coef: 0.9355Epoch 00250: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1061 - dice_coef: 0.9343 - val_loss: 0.1085 - val_dice_coef: 0.9388\n",
      "Epoch 252/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1054 - dice_coef: 0.9328Epoch 00251: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1052 - dice_coef: 0.9337 - val_loss: 0.1102 - val_dice_coef: 0.9426\n",
      "Epoch 253/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1051 - dice_coef: 0.9357Epoch 00252: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1047 - dice_coef: 0.9351 - val_loss: 0.1081 - val_dice_coef: 0.9389\n",
      "Epoch 254/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1053 - dice_coef: 0.9345Epoch 00253: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1031 - dice_coef: 0.9354 - val_loss: 0.1090 - val_dice_coef: 0.9430\n",
      "Epoch 255/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1045 - dice_coef: 0.9376Epoch 00254: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1043 - dice_coef: 0.9367 - val_loss: 0.1066 - val_dice_coef: 0.9391\n",
      "Epoch 256/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1049 - dice_coef: 0.9342Epoch 00255: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1056 - dice_coef: 0.9338 - val_loss: 0.1074 - val_dice_coef: 0.9426\n",
      "Epoch 257/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1068 - dice_coef: 0.9349Epoch 00256: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1056 - dice_coef: 0.9354 - val_loss: 0.1073 - val_dice_coef: 0.9391\n",
      "Epoch 258/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1048 - dice_coef: 0.9345Epoch 00257: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1032 - dice_coef: 0.9353 - val_loss: 0.1079 - val_dice_coef: 0.9420\n",
      "Epoch 259/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1045 - dice_coef: 0.9342Epoch 00258: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1073 - dice_coef: 0.9326 - val_loss: 0.1061 - val_dice_coef: 0.9397\n",
      "Epoch 260/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1048 - dice_coef: 0.9328Epoch 00259: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1020 - dice_coef: 0.9353 - val_loss: 0.1090 - val_dice_coef: 0.9440\n",
      "Epoch 261/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1065 - dice_coef: 0.9343Epoch 00260: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1000 - dice_coef: 0.9373 - val_loss: 0.1133 - val_dice_coef: 0.9465\n",
      "Epoch 262/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1080 - dice_coef: 0.9385Epoch 00261: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1009 - dice_coef: 0.9418 - val_loss: 0.1064 - val_dice_coef: 0.9336\n",
      "Epoch 263/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1061 - dice_coef: 0.9336Epoch 00262: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1105 - dice_coef: 0.9300 - val_loss: 0.1101 - val_dice_coef: 0.9462\n",
      "Epoch 264/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1069 - dice_coef: 0.9356Epoch 00263: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1032 - dice_coef: 0.9376 - val_loss: 0.1063 - val_dice_coef: 0.9365\n",
      "Epoch 265/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1055 - dice_coef: 0.9353Epoch 00264: val_loss improved from 0.10602 to 0.10547, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1039 - dice_coef: 0.9383 - val_loss: 0.1055 - val_dice_coef: 0.9396\n",
      "Epoch 266/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1049 - dice_coef: 0.9301Epoch 00265: val_loss improved from 0.10547 to 0.10426, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1062 - dice_coef: 0.9303 - val_loss: 0.1043 - val_dice_coef: 0.9414\n",
      "Epoch 267/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1050 - dice_coef: 0.9360Epoch 00266: val_loss improved from 0.10426 to 0.10423, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0995 - dice_coef: 0.9385 - val_loss: 0.1042 - val_dice_coef: 0.9410\n",
      "Epoch 268/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1046 - dice_coef: 0.9349Epoch 00267: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1031 - dice_coef: 0.9352 - val_loss: 0.1069 - val_dice_coef: 0.9422\n",
      "Epoch 269/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1059 - dice_coef: 0.9365Epoch 00268: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1082 - dice_coef: 0.9354 - val_loss: 0.1056 - val_dice_coef: 0.9331\n",
      "Epoch 270/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1086 - dice_coef: 0.9276Epoch 00269: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1064 - dice_coef: 0.9308 - val_loss: 0.1077 - val_dice_coef: 0.9453\n",
      "Epoch 271/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1077 - dice_coef: 0.9372Epoch 00270: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1038 - dice_coef: 0.9380 - val_loss: 0.1050 - val_dice_coef: 0.9373\n",
      "Epoch 272/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1044 - dice_coef: 0.9349Epoch 00271: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1028 - dice_coef: 0.9364 - val_loss: 0.1075 - val_dice_coef: 0.9413\n",
      "Epoch 273/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1048 - dice_coef: 0.9318Epoch 00272: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1001 - dice_coef: 0.9347 - val_loss: 0.1078 - val_dice_coef: 0.9453\n",
      "Epoch 274/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1058 - dice_coef: 0.9404Epoch 00273: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1069 - dice_coef: 0.9382 - val_loss: 0.1049 - val_dice_coef: 0.9365\n",
      "Epoch 275/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1045 - dice_coef: 0.9311Epoch 00274: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1098 - dice_coef: 0.9291 - val_loss: 0.1067 - val_dice_coef: 0.9439\n",
      "Epoch 276/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1037 - dice_coef: 0.9362Epoch 00275: val_loss improved from 0.10423 to 0.10382, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1024 - dice_coef: 0.9367 - val_loss: 0.1038 - val_dice_coef: 0.9367\n",
      "Epoch 277/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1040 - dice_coef: 0.9332Epoch 00276: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1076 - dice_coef: 0.9306 - val_loss: 0.1077 - val_dice_coef: 0.9445\n",
      "Epoch 278/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1043 - dice_coef: 0.9371Epoch 00277: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1036 - dice_coef: 0.9367 - val_loss: 0.1061 - val_dice_coef: 0.9398\n",
      "Epoch 279/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1030 - dice_coef: 0.9361Epoch 00278: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1035 - dice_coef: 0.9348 - val_loss: 0.1065 - val_dice_coef: 0.9424\n",
      "Epoch 280/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1036 - dice_coef: 0.9361Epoch 00279: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1059 - dice_coef: 0.9338 - val_loss: 0.1070 - val_dice_coef: 0.9415\n",
      "Epoch 281/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1049 - dice_coef: 0.9368Epoch 00280: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1000 - dice_coef: 0.9387 - val_loss: 0.1064 - val_dice_coef: 0.9416\n",
      "Epoch 282/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1030 - dice_coef: 0.9375Epoch 00281: val_loss improved from 0.10382 to 0.10361, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1083 - dice_coef: 0.9333 - val_loss: 0.1036 - val_dice_coef: 0.9411\n",
      "Epoch 283/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1033 - dice_coef: 0.9348Epoch 00282: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1051 - dice_coef: 0.9329 - val_loss: 0.1068 - val_dice_coef: 0.9448\n",
      "Epoch 284/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1040 - dice_coef: 0.9362Epoch 00283: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1019 - dice_coef: 0.9359 - val_loss: 0.1052 - val_dice_coef: 0.9424\n",
      "Epoch 285/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1024 - dice_coef: 0.9379Epoch 00284: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1054 - dice_coef: 0.9384 - val_loss: 0.1046 - val_dice_coef: 0.9389\n",
      "Epoch 286/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1026 - dice_coef: 0.9327Epoch 00285: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1074 - dice_coef: 0.9292 - val_loss: 0.1072 - val_dice_coef: 0.9457\n",
      "Epoch 287/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1028 - dice_coef: 0.9366Epoch 00286: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1007 - dice_coef: 0.9388 - val_loss: 0.1037 - val_dice_coef: 0.9381\n",
      "Epoch 288/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1025 - dice_coef: 0.9350Epoch 00287: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1057 - dice_coef: 0.9329 - val_loss: 0.1048 - val_dice_coef: 0.9451\n",
      "Epoch 289/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1014 - dice_coef: 0.9374Epoch 00288: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1035 - dice_coef: 0.9356 - val_loss: 0.1038 - val_dice_coef: 0.9407\n",
      "Epoch 290/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1020 - dice_coef: 0.9366Epoch 00289: val_loss improved from 0.10361 to 0.10242, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1026 - dice_coef: 0.9368 - val_loss: 0.1024 - val_dice_coef: 0.9400\n",
      "Epoch 291/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1028 - dice_coef: 0.9339Epoch 00290: val_loss improved from 0.10242 to 0.10240, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1075 - dice_coef: 0.9325 - val_loss: 0.1024 - val_dice_coef: 0.9420\n",
      "Epoch 292/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1033 - dice_coef: 0.9324Epoch 00291: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1023 - dice_coef: 0.9325 - val_loss: 0.1079 - val_dice_coef: 0.9474\n",
      "Epoch 293/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1049 - dice_coef: 0.9396Epoch 00292: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1047 - dice_coef: 0.9374 - val_loss: 0.1035 - val_dice_coef: 0.9358\n",
      "Epoch 294/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1042 - dice_coef: 0.9368Epoch 00293: val_loss improved from 0.10240 to 0.10214, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1024 - dice_coef: 0.9367 - val_loss: 0.1021 - val_dice_coef: 0.9423\n",
      "Epoch 295/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1015 - dice_coef: 0.9353Epoch 00294: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0976 - dice_coef: 0.9377 - val_loss: 0.1057 - val_dice_coef: 0.9459\n",
      "Epoch 296/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1028 - dice_coef: 0.9386Epoch 00295: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0998 - dice_coef: 0.9393 - val_loss: 0.1041 - val_dice_coef: 0.9394\n",
      "Epoch 297/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1034 - dice_coef: 0.9360Epoch 00296: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1012 - dice_coef: 0.9380 - val_loss: 0.1031 - val_dice_coef: 0.9393\n",
      "Epoch 298/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1041 - dice_coef: 0.9311Epoch 00297: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1037 - dice_coef: 0.9309 - val_loss: 0.1072 - val_dice_coef: 0.9477\n",
      "Epoch 299/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1038 - dice_coef: 0.9395Epoch 00298: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1094 - dice_coef: 0.9345 - val_loss: 0.1040 - val_dice_coef: 0.9368\n",
      "Epoch 300/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1030 - dice_coef: 0.9339Epoch 00299: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0944 - dice_coef: 0.9391 - val_loss: 0.1076 - val_dice_coef: 0.9479\n",
      "Epoch 301/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1013 - dice_coef: 0.9402Epoch 00300: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1058 - dice_coef: 0.9371 - val_loss: 0.1038 - val_dice_coef: 0.9326\n",
      "Epoch 302/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1051 - dice_coef: 0.9301Epoch 00301: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1013 - dice_coef: 0.9342 - val_loss: 0.1073 - val_dice_coef: 0.9482\n",
      "Epoch 303/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1041 - dice_coef: 0.9368Epoch 00302: val_loss improved from 0.10214 to 0.10182, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1037 - dice_coef: 0.9357 - val_loss: 0.1018 - val_dice_coef: 0.9402\n",
      "Epoch 304/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1013 - dice_coef: 0.9379Epoch 00303: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1090 - dice_coef: 0.9338 - val_loss: 0.1040 - val_dice_coef: 0.9414\n",
      "Epoch 305/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1027 - dice_coef: 0.9324Epoch 00304: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0980 - dice_coef: 0.9366 - val_loss: 0.1043 - val_dice_coef: 0.9430\n",
      "Epoch 306/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1028 - dice_coef: 0.9363Epoch 00305: val_loss improved from 0.10182 to 0.10083, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0973 - dice_coef: 0.9395 - val_loss: 0.1008 - val_dice_coef: 0.9409\n",
      "Epoch 307/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1012 - dice_coef: 0.9362Epoch 00306: val_loss improved from 0.10083 to 0.10037, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1005 - dice_coef: 0.9381 - val_loss: 0.1004 - val_dice_coef: 0.9416\n",
      "Epoch 308/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1018 - dice_coef: 0.9340Epoch 00307: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1078 - dice_coef: 0.9294 - val_loss: 0.1017 - val_dice_coef: 0.9452\n",
      "Epoch 309/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1013 - dice_coef: 0.9368Epoch 00308: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0959 - dice_coef: 0.9401 - val_loss: 0.1030 - val_dice_coef: 0.9449\n",
      "Epoch 310/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1019 - dice_coef: 0.9397Epoch 00309: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1032 - dice_coef: 0.9372 - val_loss: 0.1032 - val_dice_coef: 0.9425\n",
      "Epoch 311/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1002 - dice_coef: 0.9389Epoch 00310: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0956 - dice_coef: 0.9422 - val_loss: 0.1032 - val_dice_coef: 0.9433\n",
      "Epoch 312/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1019 - dice_coef: 0.9377Epoch 00311: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0987 - dice_coef: 0.9390 - val_loss: 0.1015 - val_dice_coef: 0.9407\n",
      "Epoch 313/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1004 - dice_coef: 0.9361Epoch 00312: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0980 - dice_coef: 0.9374 - val_loss: 0.1024 - val_dice_coef: 0.9449\n",
      "Epoch 314/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1001 - dice_coef: 0.9388Epoch 00313: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1037 - dice_coef: 0.9355 - val_loss: 0.1022 - val_dice_coef: 0.9405\n",
      "Epoch 315/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1013 - dice_coef: 0.9363Epoch 00314: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1011 - dice_coef: 0.9391 - val_loss: 0.1007 - val_dice_coef: 0.9409\n",
      "Epoch 316/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1007 - dice_coef: 0.9336Epoch 00315: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1038 - dice_coef: 0.9321 - val_loss: 0.1021 - val_dice_coef: 0.9481\n",
      "Epoch 317/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1008 - dice_coef: 0.9380Epoch 00316: val_loss improved from 0.10037 to 0.10032, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1020 - dice_coef: 0.9358 - val_loss: 0.1003 - val_dice_coef: 0.9415\n",
      "Epoch 318/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1003 - dice_coef: 0.9389Epoch 00317: val_loss improved from 0.10032 to 0.09996, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0996 - dice_coef: 0.9404 - val_loss: 0.1000 - val_dice_coef: 0.9393\n",
      "Epoch 319/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1004 - dice_coef: 0.9335Epoch 00318: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1026 - dice_coef: 0.9334 - val_loss: 0.1007 - val_dice_coef: 0.9461\n",
      "Epoch 320/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1001 - dice_coef: 0.9366Epoch 00319: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0941 - dice_coef: 0.9397 - val_loss: 0.1025 - val_dice_coef: 0.9445\n",
      "Epoch 321/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1006 - dice_coef: 0.9394Epoch 00320: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1027 - dice_coef: 0.9384 - val_loss: 0.1013 - val_dice_coef: 0.9372\n",
      "Epoch 322/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1026 - dice_coef: 0.9329Epoch 00321: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0974 - dice_coef: 0.9374 - val_loss: 0.1047 - val_dice_coef: 0.9501\n",
      "Epoch 323/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1021 - dice_coef: 0.9380Epoch 00322: val_loss improved from 0.09996 to 0.09987, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1037 - dice_coef: 0.9360 - val_loss: 0.0999 - val_dice_coef: 0.9402\n",
      "Epoch 324/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1013 - dice_coef: 0.9389Epoch 00323: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1031 - dice_coef: 0.9368 - val_loss: 0.1004 - val_dice_coef: 0.9427\n",
      "Epoch 325/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1002 - dice_coef: 0.9375Epoch 00324: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0990 - dice_coef: 0.9376 - val_loss: 0.1008 - val_dice_coef: 0.9447\n",
      "Epoch 326/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0985 - dice_coef: 0.9379Epoch 00325: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1005 - dice_coef: 0.9361 - val_loss: 0.1024 - val_dice_coef: 0.9472\n",
      "Epoch 327/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1010 - dice_coef: 0.9389Epoch 00326: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0968 - dice_coef: 0.9411 - val_loss: 0.0999 - val_dice_coef: 0.9418\n",
      "Epoch 328/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0985 - dice_coef: 0.9390Epoch 00327: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0986 - dice_coef: 0.9380 - val_loss: 0.1006 - val_dice_coef: 0.9455\n",
      "Epoch 329/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0989 - dice_coef: 0.9390Epoch 00328: val_loss improved from 0.09987 to 0.09919, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0993 - dice_coef: 0.9381 - val_loss: 0.0992 - val_dice_coef: 0.9408\n",
      "Epoch 330/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0984 - dice_coef: 0.9369Epoch 00329: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0992 - dice_coef: 0.9372 - val_loss: 0.1015 - val_dice_coef: 0.9467\n",
      "Epoch 331/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0991 - dice_coef: 0.9375Epoch 00330: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0997 - dice_coef: 0.9379 - val_loss: 0.1009 - val_dice_coef: 0.9439\n",
      "Epoch 332/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0976 - dice_coef: 0.9388Epoch 00331: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1008 - dice_coef: 0.9371 - val_loss: 0.1009 - val_dice_coef: 0.9381\n",
      "Epoch 333/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0994 - dice_coef: 0.9351Epoch 00332: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1022 - dice_coef: 0.9345 - val_loss: 0.1046 - val_dice_coef: 0.9469\n",
      "Epoch 334/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0988 - dice_coef: 0.9381Epoch 00333: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1018 - dice_coef: 0.9368 - val_loss: 0.1033 - val_dice_coef: 0.9409\n",
      "Epoch 335/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0981 - dice_coef: 0.9381Epoch 00334: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1010 - dice_coef: 0.9367 - val_loss: 0.1030 - val_dice_coef: 0.9441\n",
      "Epoch 336/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0983 - dice_coef: 0.9379Epoch 00335: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1021 - dice_coef: 0.9361 - val_loss: 0.1026 - val_dice_coef: 0.9409\n",
      "Epoch 337/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0972 - dice_coef: 0.9375Epoch 00336: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0960 - dice_coef: 0.9386 - val_loss: 0.1058 - val_dice_coef: 0.9493\n",
      "Epoch 338/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0988 - dice_coef: 0.9395Epoch 00337: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0962 - dice_coef: 0.9416 - val_loss: 0.1022 - val_dice_coef: 0.9464\n",
      "Epoch 339/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0999 - dice_coef: 0.9388Epoch 00338: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0993 - dice_coef: 0.9384 - val_loss: 0.1020 - val_dice_coef: 0.9439\n",
      "Epoch 340/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0982 - dice_coef: 0.9403Epoch 00339: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0924 - dice_coef: 0.9427 - val_loss: 0.1003 - val_dice_coef: 0.9420\n",
      "Epoch 341/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0977 - dice_coef: 0.9400Epoch 00340: val_loss improved from 0.09919 to 0.09888, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0939 - dice_coef: 0.9416 - val_loss: 0.0989 - val_dice_coef: 0.9441\n",
      "Epoch 342/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0972 - dice_coef: 0.9396Epoch 00341: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0921 - dice_coef: 0.9422 - val_loss: 0.1023 - val_dice_coef: 0.9484\n",
      "Epoch 343/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0980 - dice_coef: 0.9404Epoch 00342: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0943 - dice_coef: 0.9412 - val_loss: 0.1005 - val_dice_coef: 0.9429\n",
      "Epoch 344/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0982 - dice_coef: 0.9402Epoch 00343: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0914 - dice_coef: 0.9447 - val_loss: 0.1011 - val_dice_coef: 0.9442\n",
      "Epoch 345/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0961 - dice_coef: 0.9409Epoch 00344: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0933 - dice_coef: 0.9425 - val_loss: 0.1003 - val_dice_coef: 0.9407\n",
      "Epoch 346/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0961 - dice_coef: 0.9386Epoch 00345: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0986 - dice_coef: 0.9370 - val_loss: 0.1020 - val_dice_coef: 0.9475\n",
      "Epoch 347/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0955 - dice_coef: 0.9394Epoch 00346: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0921 - dice_coef: 0.9414 - val_loss: 0.1029 - val_dice_coef: 0.9481\n",
      "Epoch 348/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0976 - dice_coef: 0.9399Epoch 00347: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1020 - dice_coef: 0.9365 - val_loss: 0.1068 - val_dice_coef: 0.9504\n",
      "Epoch 349/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1011 - dice_coef: 0.9396Epoch 00348: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1016 - dice_coef: 0.9400 - val_loss: 0.1001 - val_dice_coef: 0.9403\n",
      "Epoch 350/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0975 - dice_coef: 0.9409Epoch 00349: val_loss improved from 0.09888 to 0.09872, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1004 - dice_coef: 0.9381 - val_loss: 0.0987 - val_dice_coef: 0.9411\n",
      "Epoch 351/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0956 - dice_coef: 0.9389Epoch 00350: val_loss improved from 0.09872 to 0.09852, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1020 - dice_coef: 0.9355 - val_loss: 0.0985 - val_dice_coef: 0.9410\n",
      "Epoch 352/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0962 - dice_coef: 0.9374Epoch 00351: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0945 - dice_coef: 0.9386 - val_loss: 0.1031 - val_dice_coef: 0.9457\n",
      "Epoch 353/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0965 - dice_coef: 0.9400Epoch 00352: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0967 - dice_coef: 0.9397 - val_loss: 0.1020 - val_dice_coef: 0.9470\n",
      "Epoch 354/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0945 - dice_coef: 0.9431Epoch 00353: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0948 - dice_coef: 0.9422 - val_loss: 0.0995 - val_dice_coef: 0.9449\n",
      "Epoch 355/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0956 - dice_coef: 0.9396Epoch 00354: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0988 - dice_coef: 0.9370 - val_loss: 0.1006 - val_dice_coef: 0.9457\n",
      "Epoch 356/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0966 - dice_coef: 0.9405Epoch 00355: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0967 - dice_coef: 0.9398 - val_loss: 0.1006 - val_dice_coef: 0.9483\n",
      "Epoch 357/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0956 - dice_coef: 0.9429Epoch 00356: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0957 - dice_coef: 0.9415 - val_loss: 0.0995 - val_dice_coef: 0.9440\n",
      "Epoch 358/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0936 - dice_coef: 0.9418Epoch 00357: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0913 - dice_coef: 0.9443 - val_loss: 0.0995 - val_dice_coef: 0.9436\n",
      "Epoch 359/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0936 - dice_coef: 0.9414Epoch 00358: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0949 - dice_coef: 0.9397 - val_loss: 0.0992 - val_dice_coef: 0.9402\n",
      "Epoch 360/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0983 - dice_coef: 0.9405Epoch 00359: val_loss improved from 0.09852 to 0.09826, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.1028 - dice_coef: 0.9377 - val_loss: 0.0983 - val_dice_coef: 0.9435\n",
      "Epoch 361/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0947 - dice_coef: 0.9394Epoch 00360: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0931 - dice_coef: 0.9425 - val_loss: 0.0985 - val_dice_coef: 0.9451\n",
      "Epoch 362/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0949 - dice_coef: 0.9407Epoch 00361: val_loss improved from 0.09826 to 0.09743, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0964 - dice_coef: 0.9405 - val_loss: 0.0974 - val_dice_coef: 0.9485\n",
      "Epoch 363/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0936 - dice_coef: 0.9416Epoch 00362: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0915 - dice_coef: 0.9424 - val_loss: 0.0988 - val_dice_coef: 0.9496\n",
      "Epoch 364/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0960 - dice_coef: 0.9394Epoch 00363: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0978 - dice_coef: 0.9381 - val_loss: 0.1003 - val_dice_coef: 0.9502\n",
      "Epoch 365/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0969 - dice_coef: 0.9423Epoch 00364: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1009 - dice_coef: 0.9396 - val_loss: 0.0977 - val_dice_coef: 0.9445\n",
      "Epoch 366/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0952 - dice_coef: 0.9425Epoch 00365: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0953 - dice_coef: 0.9431 - val_loss: 0.1043 - val_dice_coef: 0.9320\n",
      "Epoch 367/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.1004 - dice_coef: 0.9373Epoch 00366: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1021 - dice_coef: 0.9367 - val_loss: 0.1035 - val_dice_coef: 0.9518\n",
      "Epoch 368/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0967 - dice_coef: 0.9399Epoch 00367: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0980 - dice_coef: 0.9384 - val_loss: 0.1006 - val_dice_coef: 0.9471\n",
      "Epoch 369/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0952 - dice_coef: 0.9412Epoch 00368: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0925 - dice_coef: 0.9430 - val_loss: 0.0993 - val_dice_coef: 0.9468\n",
      "Epoch 370/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0934 - dice_coef: 0.9437Epoch 00369: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0986 - dice_coef: 0.9391 - val_loss: 0.0990 - val_dice_coef: 0.9416\n",
      "Epoch 371/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0926 - dice_coef: 0.9414Epoch 00370: val_loss improved from 0.09743 to 0.09736, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0942 - dice_coef: 0.9403 - val_loss: 0.0974 - val_dice_coef: 0.9459\n",
      "Epoch 372/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0936 - dice_coef: 0.9408Epoch 00371: val_loss improved from 0.09736 to 0.09724, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0860 - dice_coef: 0.9456 - val_loss: 0.0972 - val_dice_coef: 0.9496\n",
      "Epoch 373/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0926 - dice_coef: 0.9437Epoch 00372: val_loss improved from 0.09724 to 0.09722, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0925 - dice_coef: 0.9424 - val_loss: 0.0972 - val_dice_coef: 0.9461\n",
      "Epoch 374/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0936 - dice_coef: 0.9434Epoch 00373: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0910 - dice_coef: 0.9440 - val_loss: 0.0984 - val_dice_coef: 0.9457\n",
      "Epoch 375/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0924 - dice_coef: 0.9437Epoch 00374: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0913 - dice_coef: 0.9437 - val_loss: 0.0995 - val_dice_coef: 0.9470\n",
      "Epoch 376/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0943 - dice_coef: 0.9423Epoch 00375: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0943 - dice_coef: 0.9408 - val_loss: 0.1041 - val_dice_coef: 0.9521\n",
      "Epoch 377/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0970 - dice_coef: 0.9450Epoch 00376: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1000 - dice_coef: 0.9415 - val_loss: 0.0991 - val_dice_coef: 0.9493\n",
      "Epoch 378/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0955 - dice_coef: 0.9431Epoch 00377: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0937 - dice_coef: 0.9434 - val_loss: 0.0990 - val_dice_coef: 0.9427\n",
      "Epoch 379/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0925 - dice_coef: 0.9439Epoch 00378: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0996 - dice_coef: 0.9389 - val_loss: 0.0992 - val_dice_coef: 0.9464\n",
      "Epoch 380/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0928 - dice_coef: 0.9458Epoch 00379: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0961 - dice_coef: 0.9428 - val_loss: 0.0996 - val_dice_coef: 0.9402\n",
      "Epoch 381/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0944 - dice_coef: 0.9419Epoch 00380: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0927 - dice_coef: 0.9446 - val_loss: 0.1010 - val_dice_coef: 0.9466\n",
      "Epoch 382/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0931 - dice_coef: 0.9402Epoch 00381: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0891 - dice_coef: 0.9427 - val_loss: 0.0982 - val_dice_coef: 0.9479\n",
      "Epoch 383/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0922 - dice_coef: 0.9435Epoch 00382: val_loss improved from 0.09722 to 0.09679, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0993 - dice_coef: 0.9406 - val_loss: 0.0968 - val_dice_coef: 0.9420\n",
      "Epoch 384/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0940 - dice_coef: 0.9406Epoch 00383: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0915 - dice_coef: 0.9429 - val_loss: 0.0995 - val_dice_coef: 0.9488\n",
      "Epoch 385/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0943 - dice_coef: 0.9414Epoch 00384: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0976 - dice_coef: 0.9378 - val_loss: 0.0976 - val_dice_coef: 0.9457\n",
      "Epoch 386/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0922 - dice_coef: 0.9442Epoch 00385: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0947 - dice_coef: 0.9415 - val_loss: 0.0973 - val_dice_coef: 0.9457\n",
      "Epoch 387/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0916 - dice_coef: 0.9424Epoch 00386: val_loss improved from 0.09679 to 0.09551, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0907 - dice_coef: 0.9443 - val_loss: 0.0955 - val_dice_coef: 0.9451\n",
      "Epoch 388/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0920 - dice_coef: 0.9414Epoch 00387: val_loss improved from 0.09551 to 0.09511, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0892 - dice_coef: 0.9429 - val_loss: 0.0951 - val_dice_coef: 0.9499\n",
      "Epoch 389/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0899 - dice_coef: 0.9443Epoch 00388: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0946 - dice_coef: 0.9413 - val_loss: 0.0995 - val_dice_coef: 0.9519\n",
      "Epoch 390/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0939 - dice_coef: 0.9433Epoch 00389: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0903 - dice_coef: 0.9458 - val_loss: 0.0954 - val_dice_coef: 0.9452\n",
      "Epoch 391/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0917 - dice_coef: 0.9439Epoch 00390: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0929 - dice_coef: 0.9429 - val_loss: 0.0968 - val_dice_coef: 0.9493\n",
      "Epoch 392/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0923 - dice_coef: 0.9422Epoch 00391: val_loss improved from 0.09511 to 0.09431, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0891 - dice_coef: 0.9445 - val_loss: 0.0943 - val_dice_coef: 0.9457\n",
      "Epoch 393/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0904 - dice_coef: 0.9442Epoch 00392: val_loss improved from 0.09431 to 0.09374, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0882 - dice_coef: 0.9455 - val_loss: 0.0937 - val_dice_coef: 0.9444\n",
      "Epoch 394/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0913 - dice_coef: 0.9444Epoch 00393: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0886 - dice_coef: 0.9461 - val_loss: 0.0956 - val_dice_coef: 0.9407\n",
      "Epoch 395/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0935 - dice_coef: 0.9413Epoch 00394: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0982 - dice_coef: 0.9383 - val_loss: 0.0959 - val_dice_coef: 0.9496\n",
      "Epoch 396/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0894 - dice_coef: 0.9438Epoch 00395: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0906 - dice_coef: 0.9427 - val_loss: 0.0940 - val_dice_coef: 0.9475\n",
      "Epoch 397/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0926 - dice_coef: 0.9428Epoch 00396: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0914 - dice_coef: 0.9440 - val_loss: 0.0969 - val_dice_coef: 0.9502\n",
      "Epoch 398/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0917 - dice_coef: 0.9428Epoch 00397: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0912 - dice_coef: 0.9454 - val_loss: 0.1036 - val_dice_coef: 0.9542\n",
      "Epoch 399/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0920 - dice_coef: 0.9441Epoch 00398: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0947 - dice_coef: 0.9416 - val_loss: 0.0942 - val_dice_coef: 0.9487\n",
      "Epoch 400/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0909 - dice_coef: 0.9437Epoch 00399: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0847 - dice_coef: 0.9469 - val_loss: 0.0939 - val_dice_coef: 0.9487\n",
      "Epoch 401/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0886 - dice_coef: 0.9458Epoch 00400: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0890 - dice_coef: 0.9449 - val_loss: 0.0955 - val_dice_coef: 0.9494\n",
      "Epoch 402/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0913 - dice_coef: 0.9439Epoch 00401: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0988 - dice_coef: 0.9400 - val_loss: 0.0984 - val_dice_coef: 0.9388\n",
      "Epoch 403/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0961 - dice_coef: 0.9419Epoch 00402: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0894 - dice_coef: 0.9457 - val_loss: 0.0996 - val_dice_coef: 0.9484\n",
      "Epoch 404/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0899 - dice_coef: 0.9434Epoch 00403: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0935 - dice_coef: 0.9411 - val_loss: 0.0994 - val_dice_coef: 0.9471\n",
      "Epoch 405/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0894 - dice_coef: 0.9448Epoch 00404: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0892 - dice_coef: 0.9451 - val_loss: 0.1002 - val_dice_coef: 0.9488\n",
      "Epoch 406/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0905 - dice_coef: 0.9444Epoch 00405: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0916 - dice_coef: 0.9431 - val_loss: 0.0968 - val_dice_coef: 0.9466\n",
      "Epoch 407/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0902 - dice_coef: 0.9451Epoch 00406: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0876 - dice_coef: 0.9463 - val_loss: 0.0962 - val_dice_coef: 0.9490\n",
      "Epoch 408/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0897 - dice_coef: 0.9451Epoch 00407: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0946 - dice_coef: 0.9423 - val_loss: 0.0956 - val_dice_coef: 0.9428\n",
      "Epoch 409/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0910 - dice_coef: 0.9446Epoch 00408: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0891 - dice_coef: 0.9452 - val_loss: 0.0961 - val_dice_coef: 0.9468\n",
      "Epoch 410/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0908 - dice_coef: 0.9461Epoch 00409: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0929 - dice_coef: 0.9442 - val_loss: 0.0972 - val_dice_coef: 0.9448\n",
      "Epoch 411/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0891 - dice_coef: 0.9456Epoch 00410: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0916 - dice_coef: 0.9437 - val_loss: 0.0977 - val_dice_coef: 0.9412\n",
      "Epoch 412/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0936 - dice_coef: 0.9434Epoch 00411: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0909 - dice_coef: 0.9459 - val_loss: 0.0945 - val_dice_coef: 0.9475\n",
      "Epoch 413/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0904 - dice_coef: 0.9436Epoch 00412: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0976 - dice_coef: 0.9394 - val_loss: 0.0988 - val_dice_coef: 0.9509\n",
      "Epoch 414/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0898 - dice_coef: 0.9432Epoch 00413: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0907 - dice_coef: 0.9415 - val_loss: 0.0979 - val_dice_coef: 0.9503\n",
      "Epoch 415/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0916 - dice_coef: 0.9445Epoch 00414: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0884 - dice_coef: 0.9459 - val_loss: 0.0954 - val_dice_coef: 0.9493\n",
      "Epoch 416/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0885 - dice_coef: 0.9467Epoch 00415: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0877 - dice_coef: 0.9467 - val_loss: 0.0965 - val_dice_coef: 0.9418\n",
      "Epoch 417/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0941 - dice_coef: 0.9438Epoch 00416: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0933 - dice_coef: 0.9449 - val_loss: 0.0970 - val_dice_coef: 0.9488\n",
      "Epoch 418/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0884 - dice_coef: 0.9434Epoch 00417: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0892 - dice_coef: 0.9420 - val_loss: 0.1056 - val_dice_coef: 0.9526\n",
      "Epoch 419/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0956 - dice_coef: 0.9450Epoch 00418: val_loss improved from 0.09374 to 0.09356, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0927 - dice_coef: 0.9457 - val_loss: 0.0936 - val_dice_coef: 0.9452\n",
      "Epoch 420/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0885 - dice_coef: 0.9471Epoch 00419: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0892 - dice_coef: 0.9494 - val_loss: 0.0944 - val_dice_coef: 0.9417\n",
      "Epoch 421/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0902 - dice_coef: 0.9438Epoch 00420: val_loss improved from 0.09356 to 0.09234, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0917 - dice_coef: 0.9436 - val_loss: 0.0923 - val_dice_coef: 0.9437\n",
      "Epoch 422/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0908 - dice_coef: 0.9423Epoch 00421: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.1019 - dice_coef: 0.9379 - val_loss: 0.0956 - val_dice_coef: 0.9477\n",
      "Epoch 423/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0951 - dice_coef: 0.9393Epoch 00422: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0936 - dice_coef: 0.9411 - val_loss: 0.1098 - val_dice_coef: 0.9515\n",
      "Epoch 424/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0944 - dice_coef: 0.9435Epoch 00423: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0889 - dice_coef: 0.9459 - val_loss: 0.0996 - val_dice_coef: 0.9450\n",
      "Epoch 425/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0924 - dice_coef: 0.9468Epoch 00424: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0942 - dice_coef: 0.9458 - val_loss: 0.0976 - val_dice_coef: 0.9435\n",
      "Epoch 426/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0896 - dice_coef: 0.9440Epoch 00425: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0869 - dice_coef: 0.9467 - val_loss: 0.0989 - val_dice_coef: 0.9512\n",
      "Epoch 427/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0898 - dice_coef: 0.9451Epoch 00426: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0938 - dice_coef: 0.9421 - val_loss: 0.0935 - val_dice_coef: 0.9430\n",
      "Epoch 428/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0892 - dice_coef: 0.9445Epoch 00427: val_loss improved from 0.09234 to 0.09080, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0853 - dice_coef: 0.9472 - val_loss: 0.0908 - val_dice_coef: 0.9488\n",
      "Epoch 429/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0881 - dice_coef: 0.9443Epoch 00428: val_loss improved from 0.09080 to 0.09075, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0907 - dice_coef: 0.9420 - val_loss: 0.0908 - val_dice_coef: 0.9476\n",
      "Epoch 430/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0891 - dice_coef: 0.9440Epoch 00429: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0809 - dice_coef: 0.9490 - val_loss: 0.0948 - val_dice_coef: 0.9525\n",
      "Epoch 431/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0885 - dice_coef: 0.9459Epoch 00430: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0857 - dice_coef: 0.9486 - val_loss: 0.0932 - val_dice_coef: 0.9480\n",
      "Epoch 432/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0884 - dice_coef: 0.9465Epoch 00431: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0872 - dice_coef: 0.9463 - val_loss: 0.0928 - val_dice_coef: 0.9481\n",
      "Epoch 433/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0867 - dice_coef: 0.9463Epoch 00432: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0871 - dice_coef: 0.9456 - val_loss: 0.0931 - val_dice_coef: 0.9468\n",
      "Epoch 434/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0887 - dice_coef: 0.9454Epoch 00433: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0919 - dice_coef: 0.9439 - val_loss: 0.0928 - val_dice_coef: 0.9496\n",
      "Epoch 435/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0887 - dice_coef: 0.9452Epoch 00434: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0945 - dice_coef: 0.9424 - val_loss: 0.0954 - val_dice_coef: 0.9509\n",
      "Epoch 436/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0914 - dice_coef: 0.9438Epoch 00435: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0949 - dice_coef: 0.9433 - val_loss: 0.0963 - val_dice_coef: 0.9508\n",
      "Epoch 437/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0894 - dice_coef: 0.9431Epoch 00436: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0881 - dice_coef: 0.9448 - val_loss: 0.0963 - val_dice_coef: 0.9526\n",
      "Epoch 438/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0898 - dice_coef: 0.9454Epoch 00437: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0885 - dice_coef: 0.9457 - val_loss: 0.0955 - val_dice_coef: 0.9532\n",
      "Epoch 439/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0913 - dice_coef: 0.9481Epoch 00438: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0885 - dice_coef: 0.9484 - val_loss: 0.0933 - val_dice_coef: 0.9436\n",
      "Epoch 440/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0897 - dice_coef: 0.9463Epoch 00439: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0883 - dice_coef: 0.9474 - val_loss: 0.0921 - val_dice_coef: 0.9456\n",
      "Epoch 441/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0869 - dice_coef: 0.9450Epoch 00440: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0915 - dice_coef: 0.9435 - val_loss: 0.0965 - val_dice_coef: 0.9512\n",
      "Epoch 442/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0883 - dice_coef: 0.9446Epoch 00441: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0929 - dice_coef: 0.9411 - val_loss: 0.0936 - val_dice_coef: 0.9437\n",
      "Epoch 443/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0892 - dice_coef: 0.9445Epoch 00442: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0947 - dice_coef: 0.9455 - val_loss: 0.0940 - val_dice_coef: 0.9508\n",
      "Epoch 444/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0885 - dice_coef: 0.9432Epoch 00443: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0858 - dice_coef: 0.9454 - val_loss: 0.0983 - val_dice_coef: 0.9515\n",
      "Epoch 445/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0876 - dice_coef: 0.9457Epoch 00444: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0883 - dice_coef: 0.9445 - val_loss: 0.0929 - val_dice_coef: 0.9502\n",
      "Epoch 446/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0898 - dice_coef: 0.9481Epoch 00445: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0870 - dice_coef: 0.9483 - val_loss: 0.0980 - val_dice_coef: 0.9390\n",
      "Epoch 447/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0928 - dice_coef: 0.9456Epoch 00446: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0953 - dice_coef: 0.9443 - val_loss: 0.0924 - val_dice_coef: 0.9486\n",
      "Epoch 448/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0894 - dice_coef: 0.9433Epoch 00447: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0981 - dice_coef: 0.9398 - val_loss: 0.1017 - val_dice_coef: 0.9534\n",
      "Epoch 449/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0886 - dice_coef: 0.9461Epoch 00448: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0851 - dice_coef: 0.9486 - val_loss: 0.0948 - val_dice_coef: 0.9438\n",
      "Epoch 450/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0870 - dice_coef: 0.9461Epoch 00449: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0833 - dice_coef: 0.9500 - val_loss: 0.0915 - val_dice_coef: 0.9497\n",
      "Epoch 451/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0863 - dice_coef: 0.9450Epoch 00450: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0882 - dice_coef: 0.9427 - val_loss: 0.0918 - val_dice_coef: 0.9512\n",
      "Epoch 452/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0875 - dice_coef: 0.9466Epoch 00451: val_loss improved from 0.09075 to 0.09029, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0844 - dice_coef: 0.9476 - val_loss: 0.0903 - val_dice_coef: 0.9494\n",
      "Epoch 453/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0869 - dice_coef: 0.9475Epoch 00452: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0841 - dice_coef: 0.9484 - val_loss: 0.0922 - val_dice_coef: 0.9473\n",
      "Epoch 454/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0863 - dice_coef: 0.9464Epoch 00453: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0834 - dice_coef: 0.9475 - val_loss: 0.0920 - val_dice_coef: 0.9504\n",
      "Epoch 455/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0869 - dice_coef: 0.9479Epoch 00454: val_loss improved from 0.09029 to 0.08976, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0836 - dice_coef: 0.9503 - val_loss: 0.0898 - val_dice_coef: 0.9473\n",
      "Epoch 456/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0884 - dice_coef: 0.9477Epoch 00455: val_loss improved from 0.08976 to 0.08965, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0856 - dice_coef: 0.9484 - val_loss: 0.0897 - val_dice_coef: 0.9465\n",
      "Epoch 457/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0855 - dice_coef: 0.9472Epoch 00456: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0811 - dice_coef: 0.9497 - val_loss: 0.0901 - val_dice_coef: 0.9518\n",
      "Epoch 458/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0838 - dice_coef: 0.9485Epoch 00457: val_loss improved from 0.08965 to 0.08904, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0877 - dice_coef: 0.9455 - val_loss: 0.0890 - val_dice_coef: 0.9478\n",
      "Epoch 459/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0837 - dice_coef: 0.9478Epoch 00458: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0882 - dice_coef: 0.9466 - val_loss: 0.0917 - val_dice_coef: 0.9461\n",
      "Epoch 460/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0872 - dice_coef: 0.9457Epoch 00459: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0858 - dice_coef: 0.9468 - val_loss: 0.0925 - val_dice_coef: 0.9477\n",
      "Epoch 461/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0876 - dice_coef: 0.9448Epoch 00460: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0826 - dice_coef: 0.9486 - val_loss: 0.1036 - val_dice_coef: 0.9556\n",
      "Epoch 462/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0942 - dice_coef: 0.9455Epoch 00461: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0895 - dice_coef: 0.9478 - val_loss: 0.0941 - val_dice_coef: 0.9513\n",
      "Epoch 463/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0878 - dice_coef: 0.9498Epoch 00462: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0956 - dice_coef: 0.9450 - val_loss: 0.1007 - val_dice_coef: 0.9369\n",
      "Epoch 464/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0911 - dice_coef: 0.9447Epoch 00463: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0873 - dice_coef: 0.9467 - val_loss: 0.0990 - val_dice_coef: 0.9514\n",
      "Epoch 465/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0873 - dice_coef: 0.9445Epoch 00464: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0869 - dice_coef: 0.9469 - val_loss: 0.0940 - val_dice_coef: 0.9465\n",
      "Epoch 466/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0858 - dice_coef: 0.9462Epoch 00465: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0865 - dice_coef: 0.9456 - val_loss: 0.0942 - val_dice_coef: 0.9530\n",
      "Epoch 467/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0869 - dice_coef: 0.9487Epoch 00466: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0853 - dice_coef: 0.9494 - val_loss: 0.0914 - val_dice_coef: 0.9437\n",
      "Epoch 468/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0855 - dice_coef: 0.9459Epoch 00467: val_loss improved from 0.08904 to 0.08809, saving model to saved_models/endo_models/weights-500Epochs-NoDrop-Adam5.hdf5\n",
      "7/7 [==============================] - 11s - loss: 0.0841 - dice_coef: 0.9464 - val_loss: 0.0881 - val_dice_coef: 0.9509\n",
      "Epoch 469/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0864 - dice_coef: 0.9459Epoch 00468: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0820 - dice_coef: 0.9484 - val_loss: 0.0936 - val_dice_coef: 0.9544\n",
      "Epoch 470/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0875 - dice_coef: 0.9466Epoch 00469: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0854 - dice_coef: 0.9476 - val_loss: 0.0918 - val_dice_coef: 0.9519\n",
      "Epoch 471/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0857 - dice_coef: 0.9486Epoch 00470: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0897 - dice_coef: 0.9466 - val_loss: 0.0924 - val_dice_coef: 0.9450\n",
      "Epoch 472/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0866 - dice_coef: 0.9477Epoch 00471: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0857 - dice_coef: 0.9475 - val_loss: 0.0925 - val_dice_coef: 0.9504\n",
      "Epoch 473/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0867 - dice_coef: 0.9480Epoch 00472: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0877 - dice_coef: 0.9471 - val_loss: 0.0916 - val_dice_coef: 0.9474\n",
      "Epoch 474/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0854 - dice_coef: 0.9465Epoch 00473: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0796 - dice_coef: 0.9498 - val_loss: 0.0952 - val_dice_coef: 0.9528\n",
      "Epoch 475/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0873 - dice_coef: 0.9472Epoch 00474: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0873 - dice_coef: 0.9457 - val_loss: 0.0936 - val_dice_coef: 0.9539\n",
      "Epoch 476/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0868 - dice_coef: 0.9494Epoch 00475: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0833 - dice_coef: 0.9506 - val_loss: 0.0897 - val_dice_coef: 0.9484\n",
      "Epoch 477/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0855 - dice_coef: 0.9500Epoch 00476: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0833 - dice_coef: 0.9504 - val_loss: 0.0949 - val_dice_coef: 0.9418\n",
      "Epoch 478/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0899 - dice_coef: 0.9468Epoch 00477: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0896 - dice_coef: 0.9476 - val_loss: 0.0902 - val_dice_coef: 0.9469\n",
      "Epoch 479/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0873 - dice_coef: 0.9443Epoch 00478: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0816 - dice_coef: 0.9484 - val_loss: 0.1005 - val_dice_coef: 0.9548\n",
      "Epoch 480/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0892 - dice_coef: 0.9464Epoch 00479: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0854 - dice_coef: 0.9481 - val_loss: 0.0913 - val_dice_coef: 0.9491\n",
      "Epoch 481/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0863 - dice_coef: 0.9496Epoch 00480: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0837 - dice_coef: 0.9505 - val_loss: 0.0905 - val_dice_coef: 0.9493\n",
      "Epoch 482/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0841 - dice_coef: 0.9497Epoch 00481: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0861 - dice_coef: 0.9485 - val_loss: 0.0916 - val_dice_coef: 0.9444\n",
      "Epoch 483/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0864 - dice_coef: 0.9461Epoch 00482: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0853 - dice_coef: 0.9462 - val_loss: 0.0938 - val_dice_coef: 0.9425\n",
      "Epoch 484/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0898 - dice_coef: 0.9441Epoch 00483: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0872 - dice_coef: 0.9461 - val_loss: 0.0948 - val_dice_coef: 0.9546\n",
      "Epoch 485/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0861 - dice_coef: 0.9468Epoch 00484: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0823 - dice_coef: 0.9494 - val_loss: 0.0901 - val_dice_coef: 0.9521\n",
      "Epoch 486/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0841 - dice_coef: 0.9492Epoch 00485: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0871 - dice_coef: 0.9460 - val_loss: 0.0902 - val_dice_coef: 0.9510\n",
      "Epoch 487/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0846 - dice_coef: 0.9495Epoch 00486: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0800 - dice_coef: 0.9515 - val_loss: 0.0914 - val_dice_coef: 0.9470\n",
      "Epoch 488/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0833 - dice_coef: 0.9502Epoch 00487: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0855 - dice_coef: 0.9480 - val_loss: 0.0905 - val_dice_coef: 0.9498\n",
      "Epoch 489/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0821 - dice_coef: 0.9487Epoch 00488: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0796 - dice_coef: 0.9505 - val_loss: 0.0911 - val_dice_coef: 0.9517\n",
      "Epoch 490/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0838 - dice_coef: 0.9489Epoch 00489: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0808 - dice_coef: 0.9514 - val_loss: 0.0921 - val_dice_coef: 0.9464\n",
      "Epoch 491/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0829 - dice_coef: 0.9486Epoch 00490: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0846 - dice_coef: 0.9472 - val_loss: 0.0914 - val_dice_coef: 0.9473\n",
      "Epoch 492/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0844 - dice_coef: 0.9480Epoch 00491: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0881 - dice_coef: 0.9473 - val_loss: 0.0907 - val_dice_coef: 0.9511\n",
      "Epoch 493/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0830 - dice_coef: 0.9477Epoch 00492: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0837 - dice_coef: 0.9496 - val_loss: 0.0936 - val_dice_coef: 0.9528\n",
      "Epoch 494/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0829 - dice_coef: 0.9479Epoch 00493: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0804 - dice_coef: 0.9503 - val_loss: 0.0936 - val_dice_coef: 0.9531\n",
      "Epoch 495/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0835 - dice_coef: 0.9497Epoch 00494: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0823 - dice_coef: 0.9493 - val_loss: 0.0936 - val_dice_coef: 0.9536\n",
      "Epoch 496/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0857 - dice_coef: 0.9493Epoch 00495: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0883 - dice_coef: 0.9464 - val_loss: 0.0904 - val_dice_coef: 0.9483\n",
      "Epoch 497/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0851 - dice_coef: 0.9511Epoch 00496: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0883 - dice_coef: 0.9483 - val_loss: 0.0926 - val_dice_coef: 0.9469\n",
      "Epoch 498/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0857 - dice_coef: 0.9488Epoch 00497: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0822 - dice_coef: 0.9503 - val_loss: 0.0939 - val_dice_coef: 0.9441\n",
      "Epoch 499/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0834 - dice_coef: 0.9485Epoch 00498: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0902 - dice_coef: 0.9453 - val_loss: 0.0919 - val_dice_coef: 0.9516\n",
      "Epoch 500/500\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0838 - dice_coef: 0.9479Epoch 00499: val_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 0.0819 - dice_coef: 0.9491 - val_loss: 0.0953 - val_dice_coef: 0.9493\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=weight_file, verbose=1, save_best_only=True)\n",
    "\n",
    "hist = model.fit_generator(train_generator,steps_per_epoch=train_steps,epochs=epochs,verbose=1,callbacks=[checkpointer],\n",
    "                   validation_data=(validation_images,validation_inner_masks),validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJE6hICIicQoFERGJUyiIiEjc/weZAAlgMKRaXgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd639975160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nByLnjysGYAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd6372759e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd6371e3f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_plots(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model.load_weights(weight_file)\n",
    "\n",
    "def calculate_dice(images, masks_true):\n",
    "    dices = []\n",
    "    masks_pred = np.concatenate([model.predict(image[None,:,:,:]) for image in images])\n",
    "    for mask_true, mask_pred in zip(masks_true, masks_pred):\n",
    "        y_true = mask_true.astype('float64')\n",
    "        y_pred = mask_pred.astype('float64')\n",
    "        dices.append(dice_coef_np(y_true.flatten(), y_pred.flatten()))\n",
    "    print(\"Dice Average: {:.2f} Dice Stdev: {:.2f}\".format(np.mean(dices), np.std(dices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Statistics(No Dropout)...\")\n",
    "calculate_dice(train_images, train_inner_masks)\n",
    "print(\"Validation Statistics(No Dropout)...\")\n",
    "calculate_dice(validation_images, validation_inner_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Predictions on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_masks(images, i_masks_true):\n",
    "    masks_pred = np.concatenate([model.predict(image[None,:,:,:]) for image in images])\n",
    "    counter = 0\n",
    "    for (image,i_mask,mask_pred) in zip(images,i_masks_true,masks_pred):\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(i_mask, cmap=plt.cm.gray)\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(np.where(mask_pred[:,:,1]>0.25,255,0),cmap=plt.cm.gray)\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(image[:,:,0], cmap=plt.cm.gray)\n",
    "        counter += 1\n",
    "        filename = \"{:2d}.png\".format(counter)\n",
    "        plt.savefig(os.path.join(save_imgs_dir, filename))\n",
    "        \n",
    "show_masks(images[split_index:], inner_masks[split_index:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
