{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training U-Net model\n",
    "## 250 Epochs, No Dropout, Adam Optimizer, Learning Rate 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os, re, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from src import data,unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import utils\n",
    "train_dir = \"/home/ubuntu/trainingdata/TrainingSet\"\n",
    "weight_file = 'saved_models/endo_models/weights-250Epochs-NoDrop-Adam5.hdf5'\n",
    "save_imgs_dir = 'images/train250NoDrpAdam5'\n",
    "\n",
    "images = []\n",
    "inner_masks = []\n",
    "outer_masks = []\n",
    "\n",
    "patient_directories = sorted(glob.glob(os.path.join(train_dir, \"patient*\")))\n",
    "\n",
    "for patient_dir in patient_directories:\n",
    "    imgdata = data.ImageData(patient_dir)\n",
    "    images += imgdata.labeled_images\n",
    "    inner_masks += imgdata.endo_masks\n",
    "    outer_masks += imgdata.epi_masks\n",
    "\n",
    "images = np.asarray(images)[:,:,:,None].astype('float64')\n",
    "i_masks = np.asarray(inner_masks)\n",
    "o_masks = np.asarray(outer_masks)\n",
    "\n",
    "dims = i_masks.shape\n",
    "classes = len(set(i_masks[0].flatten()))\n",
    "new_shape = dims + (classes,)\n",
    "i_masks = utils.to_categorical(i_masks).reshape(new_shape)\n",
    "o_masks = utils.to_categorical(o_masks).reshape(new_shape)\n",
    "\n",
    "def normalize(x, epsilon=1e-7, axis=(1,2)):\n",
    "    x -= np.mean(x, axis=axis, keepdims=True)\n",
    "    x /= np.std(x, axis=axis, keepdims=True) + epsilon\n",
    "    \n",
    "normalize(images,axis=(1,2))\n",
    "\n",
    "print(\"There are %d total training images.\" % len(images))\n",
    "print(\"There are %d total inner masks.\" % len(inner_masks))\n",
    "print(\"There are %d total outer masks.\" % len(outer_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height,width,_ = images[0].shape\n",
    "dropout = 0.0\n",
    "unet_conv = unet.UNet()\n",
    "\n",
    "model = unet_conv.get_unet(height=height, width=width, channels=1,features=32,steps=3,dropout=dropout,padding='same')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    flat_y_true = K.flatten(y_true)\n",
    "    flat_y_pred = K.flatten(y_pred)\n",
    "    intersection = K.sum(flat_y_true * flat_y_pred)\n",
    "    return (2. * intersection + 1.) / (K.sum(flat_y_true) + K.sum(flat_y_pred) + 1.)\n",
    "\n",
    "def dice_coef_np(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    return (2. * intersection + 1.) / (np.sum(y_true) + np.sum(y_pred) + 1.)\n",
    "\n",
    "\n",
    "def pixelwise_crossentropy(y_true, y_pred, weights=[0.5,0.5], epsilon=1e-8):\n",
    "    ndim = K.ndim(y_pred)\n",
    "    ncategory = K.int_shape(y_pred)[-1]\n",
    "    # scale predictions so class probabilities of each pixel sum to 1\n",
    "    y_pred /= K.sum(y_pred, axis=(ndim-1), keepdims=True)\n",
    "    y_pred = K.clip(y_pred, epsilon, 1-epsilon)\n",
    "    w = K.constant(weights) * (ncategory / sum(weights))\n",
    "    # first, average over all axis except classes\n",
    "    cross_entropies = -K.mean(y_true * K.log(y_pred), axis=tuple(range(ndim-1)))\n",
    "    return K.sum(w * cross_entropies)\n",
    "\n",
    "\n",
    "def show_plots(history):    \n",
    "    plt.plot(history.history['dice_coef'])\n",
    "    plt.plot(history.history['val_dice_coef'])\n",
    "    plt.title('model dice')\n",
    "    plt.ylabel('dice')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "model.compile(optimizer=Adam(lr=1e-5),loss=[pixelwise_crossentropy],metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "seed = 78\n",
    "\n",
    "validation_split=0.2\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "split_index = int((1 - validation_split) * len(images))\n",
    "\n",
    "train_steps = ceil(split_index / batch_size)\n",
    "val_steps = ceil((len(images)-split_index )/batch_size)\n",
    "\n",
    "train_images = images[:split_index]\n",
    "train_inner_masks = i_masks[:split_index]\n",
    "\n",
    "validation_images = images[split_index:]\n",
    "validation_inner_masks = i_masks[split_index:]\n",
    "\n",
    "\n",
    "data_gen_args = dict(rotation_range=180,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     shear_range=0.1,\n",
    "                     zoom_range=0.05,\n",
    "                     fill_mode='nearest')\n",
    "\n",
    "train_images_datagen = ImageDataGenerator(**data_gen_args)\n",
    "train_masks_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "\n",
    "#seed = 1\n",
    "#height,width,channels = train_images[0].shape\n",
    "#print(train_images[0].shape)\n",
    "#print(train_inner_masks[0].shape)\n",
    "train_images_datagen.fit(train_images,augment=True,seed=seed)\n",
    "train_masks_datagen.fit(train_inner_masks,augment=True,seed=seed)\n",
    "\n",
    "train_images_generator = train_images_datagen.flow(train_images, y=None, seed=seed)\n",
    "train_masks_generator = train_images_datagen.flow(train_inner_masks, y=None, seed=seed)\n",
    "\n",
    "\n",
    "train_generator = zip(train_images_generator, train_masks_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=weight_file, verbose=1, save_best_only=True)\n",
    "\n",
    "hist = model.fit_generator(train_generator,steps_per_epoch=train_steps,epochs=epochs,verbose=1,callbacks=[checkpointer],\n",
    "                   validation_data=(validation_images,validation_inner_masks),validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model.load_weights(weight_file)\n",
    "\n",
    "def calculate_dice(images, masks_true):\n",
    "    dices = []\n",
    "    masks_pred = np.concatenate([model.predict(image[None,:,:,:]) for image in images])\n",
    "    for mask_true, mask_pred in zip(masks_true, masks_pred):\n",
    "        y_true = mask_true.astype('float64')\n",
    "        y_pred = mask_pred.astype('float64')\n",
    "        dices.append(dice_coef_np(y_true.flatten(), y_pred.flatten()))\n",
    "    print(\"Dice Average: {:.2f} Dice Stdev: {:.2f}\".format(np.mean(dices), np.std(dices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Statistics(No Dropout)...\")\n",
    "calculate_dice(train_images, train_inner_masks)\n",
    "print(\"Validation Statistics(No Dropout)...\")\n",
    "calculate_dice(validation_images, validation_innter_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Predictions on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_masks(images, i_masks_true):\n",
    "    masks_pred = np.concatenate([model.predict(image[None,:,:,:]) for image in images])\n",
    "    counter = 0\n",
    "    for (image,i_mask,mask_pred) in zip(images,i_masks_true,masks_pred):\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(i_mask, cmap=plt.cm.gray)\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(np.where(mask_pred[:,:,1]>0.5,255,0),cmap=plt.cm.gray)\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(image[:,:,0], cmap=plt.cm.gray)\n",
    "        counter += 1\n",
    "        filename = \"{:2d}.png\".format(counter)\n",
    "        savefig(os.path.join(save_imgs_dir, filename))\n",
    "        \n",
    "show_masks(images[:10], outer_masks[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
