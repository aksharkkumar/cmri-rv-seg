{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Model for RV Segmentation\n",
    "\n",
    "## Training U-Net CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os, re, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from src import data,unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 243 total training images.\n",
      "There are 243 total inner masks.\n",
      "There are 243 total outer masks.\n"
     ]
    }
   ],
   "source": [
    "from keras import utils\n",
    "\n",
    "train_dir = \"/home/ubuntu/training/TrainingSet\"\n",
    "#train_dir = \"/Users/aksharkumar/Documents/mlndCapstone/trainingdata/TrainingSet\"\n",
    "\n",
    "images=[]\n",
    "inner_masks=[]\n",
    "outer_masks = []\n",
    "\n",
    "patient_directories = sorted(glob.glob(os.path.join(train_dir, \"patient*\")))\n",
    "\n",
    "for patient_dir in patient_directories:\n",
    "    imgdata = data.ImageData(patient_dir)\n",
    "    images += imgdata.labeled_images\n",
    "    inner_masks += imgdata.endo_masks.values()\n",
    "    outer_masks += imgdata.epi_masks.values()\n",
    "\n",
    "images = np.asarray(images)[:,:,:,None].astype('float64')\n",
    "i_masks = np.asarray(inner_masks)\n",
    "o_masks = np.asarray(outer_masks)\n",
    "\n",
    "dims = i_masks.shape\n",
    "classes = len(set(i_masks[0].flatten()))\n",
    "new_shape = dims + (classes,)\n",
    "i_masks = utils.to_categorical(i_masks).reshape(new_shape)\n",
    "o_masks = utils.to_categorical(o_masks).reshape(new_shape)\n",
    "\n",
    "print(\"There are %d total training images.\" % len(images))\n",
    "print(\"There are %d total inner masks.\" % len(inner_masks))\n",
    "print(\"There are %d total outer masks.\" % len(outer_masks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 216, 256, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 216, 256, 32)  320         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 216, 256, 32)  0           conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 216, 256, 32)  0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 216, 256, 32)  9248        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 216, 256, 32)  0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 216, 256, 32)  0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 108, 128, 32)  0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 108, 128, 64)  18496       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 108, 128, 64)  0           conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 108, 128, 64)  0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 108, 128, 64)  36928       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 108, 128, 64)  0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 108, 128, 64)  0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 54, 64, 64)    0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 54, 64, 128)   73856       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 54, 64, 128)   0           conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 54, 64, 128)   0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 54, 64, 128)   147584      dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 54, 64, 128)   0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 54, 64, 128)   0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 27, 32, 128)   0           dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 27, 32, 256)   295168      max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 27, 32, 256)   0           conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 27, 32, 256)   0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 27, 32, 256)   590080      dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 27, 32, 256)   0           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 27, 32, 256)   0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTransp (None, 54, 64, 128)   131200      dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 54, 64, 256)   0           conv2d_transpose_1[0][0]         \n",
      "                                                                   conv2d_transpose_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 54, 64, 128)   295040      concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 54, 64, 128)   0           conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 54, 64, 128)   0           activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 54, 64, 128)   147584      dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 54, 64, 128)   0           conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 54, 64, 128)   0           activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTransp (None, 108, 128, 64)  32832       dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 108, 128, 128) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                   conv2d_transpose_2[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 108, 128, 64)  73792       concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 108, 128, 64)  0           conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 108, 128, 64)  0           activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 108, 128, 64)  36928       dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 108, 128, 64)  0           conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 108, 128, 64)  0           activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTransp (None, 216, 256, 32)  8224        dropout_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 216, 256, 64)  0           conv2d_transpose_3[0][0]         \n",
      "                                                                   conv2d_transpose_3[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 216, 256, 32)  18464       concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 216, 256, 32)  0           conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 216, 256, 32)  0           activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 216, 256, 32)  9248        dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 216, 256, 32)  0           conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 216, 256, 32)  0           activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 216, 256, 2)   66          dropout_14[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1,925,058\n",
      "Trainable params: 1,925,058\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "height,width,_ = images[0].shape\n",
    "dropout = 0\n",
    "\n",
    "unet_conv = unet.UNet()\n",
    "\n",
    "model = unet_conv.get_unet(height=height,width=width,channels=1,features=32,steps=3,dropout=dropout,padding='same')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    flat_y_true = K.flatten(y_true)\n",
    "    flat_y_pred = K.flatten(y_pred)\n",
    "    intersection = K.sum(flat_y_true * flat_y_pred)\n",
    "    return (2. * intersection + 1.) / (K.sum(flat_y_true) + K.sum(flat_y_pred) + 1.)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true,y_pred)\n",
    "\n",
    "def show_plots(history):    \n",
    "    plt.plot(history.history['dice_coef'])\n",
    "    plt.plot(history.history['val_dice_coef'])\n",
    "    plt.title('model dice')\n",
    "    plt.ylabel('dice')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-5),loss='categorical_crossentropy',metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/preprocessing/image.py:653: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (194, 216, 256, 2) (2 channels).\n",
      "/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/preprocessing/image.py:787: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (194, 216, 256, 2) (2 channels).\n"
     ]
    }
   ],
   "source": [
    "#TODO: 1. split data into training and validation set\n",
    "#      2. Augment the data\n",
    "#      3. Train model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "seed = 0\n",
    "\n",
    "validation_split=0.2\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 20\n",
    "\n",
    "\n",
    "split_index = int((1 - validation_split) * len(images))\n",
    "\n",
    "train_steps = ceil(split_index / batch_size)\n",
    "val_steps = ceil((len(images)-split_index )/batch_size)\n",
    "\n",
    "train_images = images[:split_index]\n",
    "train_inner_masks = i_masks[:split_index]\n",
    "\n",
    "validation_images = images[split_index:]\n",
    "validation_inner_masks = i_masks[split_index:]\n",
    "\n",
    "\n",
    "data_gen_args = dict(rotation_range=180,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     shear_range=0.1,\n",
    "                     zoom_range=0.01,\n",
    "                     fill_mode='nearest')\n",
    "\n",
    "train_images_datagen = ImageDataGenerator(**data_gen_args)\n",
    "train_masks_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "\n",
    "seed = 1\n",
    "#height,width,channels = train_images[0].shape\n",
    "#print(train_images[0].shape)\n",
    "#print(train_inner_masks[0].shape)\n",
    "train_images_datagen.fit(train_images,augment=True,seed=seed)\n",
    "train_masks_datagen.fit(train_inner_masks,augment=True,seed=seed)\n",
    "\n",
    "train_images_generator = train_images_datagen.flow(train_images, y=None, seed=seed)\n",
    "train_masks_generator = train_images_datagen.flow(train_inner_masks, y=None, seed=seed)\n",
    "\n",
    "\n",
    "train_generator = zip(train_images_generator, train_masks_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.68696, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "25s - loss: 0.6959 - dice_coef: 0.4989 - val_loss: 0.6870 - val_dice_coef: 0.5033\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.68696 to 0.66982, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.6786 - dice_coef: 0.5077 - val_loss: 0.6698 - val_dice_coef: 0.5123\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.66982 to 0.63279, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.6517 - dice_coef: 0.5227 - val_loss: 0.6328 - val_dice_coef: 0.5333\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.63279 to 0.55557, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.5949 - dice_coef: 0.5579 - val_loss: 0.5556 - val_dice_coef: 0.5834\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.55557 to 0.44003, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.4870 - dice_coef: 0.6372 - val_loss: 0.4400 - val_dice_coef: 0.6788\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.44003 to 0.36485, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3969 - dice_coef: 0.7428 - val_loss: 0.3648 - val_dice_coef: 0.7781\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.36485 to 0.34659, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.3626 - dice_coef: 0.8124 - val_loss: 0.3466 - val_dice_coef: 0.8084\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.34659 to 0.34379, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3710 - dice_coef: 0.8095 - val_loss: 0.3438 - val_dice_coef: 0.7813\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.34379 to 0.33315, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3306 - dice_coef: 0.7975 - val_loss: 0.3331 - val_dice_coef: 0.7909\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.33315 to 0.32053, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.3453 - dice_coef: 0.8089 - val_loss: 0.3205 - val_dice_coef: 0.8088\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.32053 to 0.31711, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3386 - dice_coef: 0.8130 - val_loss: 0.3171 - val_dice_coef: 0.7985\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.31711 to 0.30372, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.3110 - dice_coef: 0.8176 - val_loss: 0.3037 - val_dice_coef: 0.8152\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.30372 to 0.29268, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3051 - dice_coef: 0.8356 - val_loss: 0.2927 - val_dice_coef: 0.8246\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.29268 to 0.28298, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.3041 - dice_coef: 0.8311 - val_loss: 0.2830 - val_dice_coef: 0.8282\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.28298 to 0.27230, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2903 - dice_coef: 0.8360 - val_loss: 0.2723 - val_dice_coef: 0.8372\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.27230 to 0.26600, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2874 - dice_coef: 0.8392 - val_loss: 0.2660 - val_dice_coef: 0.8353\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.26600 to 0.25473, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2602 - dice_coef: 0.8534 - val_loss: 0.2547 - val_dice_coef: 0.8538\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.25473 to 0.24950, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2758 - dice_coef: 0.8466 - val_loss: 0.2495 - val_dice_coef: 0.8491\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.24950 to 0.24665, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2766 - dice_coef: 0.8542 - val_loss: 0.2466 - val_dice_coef: 0.8439\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.24665 to 0.23853, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2566 - dice_coef: 0.8402 - val_loss: 0.2385 - val_dice_coef: 0.8545\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.23853 to 0.23105, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2461 - dice_coef: 0.8671 - val_loss: 0.2310 - val_dice_coef: 0.8687\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.23105 to 0.22972, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "16s - loss: 0.2485 - dice_coef: 0.8607 - val_loss: 0.2297 - val_dice_coef: 0.8578\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.22972 to 0.22208, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "16s - loss: 0.2310 - dice_coef: 0.8719 - val_loss: 0.2221 - val_dice_coef: 0.8806\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.22208 to 0.22014, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2366 - dice_coef: 0.8641 - val_loss: 0.2201 - val_dice_coef: 0.8651\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.22014 to 0.21424, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2268 - dice_coef: 0.8707 - val_loss: 0.2142 - val_dice_coef: 0.8836\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.21424 to 0.21164, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2311 - dice_coef: 0.8661 - val_loss: 0.2116 - val_dice_coef: 0.8718\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.21164 to 0.20654, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2157 - dice_coef: 0.8810 - val_loss: 0.2065 - val_dice_coef: 0.8809\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.20654 to 0.20307, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2040 - dice_coef: 0.8817 - val_loss: 0.2031 - val_dice_coef: 0.8849\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.20307 to 0.20278, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2148 - dice_coef: 0.8829 - val_loss: 0.2028 - val_dice_coef: 0.8770\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.20278 to 0.19900, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2128 - dice_coef: 0.8726 - val_loss: 0.1990 - val_dice_coef: 0.8878\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.19900 to 0.19701, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2149 - dice_coef: 0.8826 - val_loss: 0.1970 - val_dice_coef: 0.8847\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19701 to 0.19365, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1975 - dice_coef: 0.8892 - val_loss: 0.1937 - val_dice_coef: 0.8951\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.19365 to 0.19232, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2010 - dice_coef: 0.8812 - val_loss: 0.1923 - val_dice_coef: 0.8914\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19232 to 0.18996, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1949 - dice_coef: 0.8924 - val_loss: 0.1900 - val_dice_coef: 0.8940\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18996 to 0.18837, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1890 - dice_coef: 0.8931 - val_loss: 0.1884 - val_dice_coef: 0.8920\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "15s - loss: 0.1931 - dice_coef: 0.8815 - val_loss: 0.1918 - val_dice_coef: 0.9119\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "15s - loss: 0.1943 - dice_coef: 0.8950 - val_loss: 0.1904 - val_dice_coef: 0.8820\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18837 to 0.18521, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2023 - dice_coef: 0.8848 - val_loss: 0.1852 - val_dice_coef: 0.8918\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18521 to 0.18237, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1861 - dice_coef: 0.8894 - val_loss: 0.1824 - val_dice_coef: 0.9056\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.18237 to 0.18038, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1981 - dice_coef: 0.8867 - val_loss: 0.1804 - val_dice_coef: 0.8978\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00040: val_loss did not improve\n",
      "15s - loss: 0.2092 - dice_coef: 0.8864 - val_loss: 0.1913 - val_dice_coef: 0.8726\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "14s - loss: 0.1906 - dice_coef: 0.8865 - val_loss: 0.1804 - val_dice_coef: 0.9073\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "15s - loss: 0.1881 - dice_coef: 0.8904 - val_loss: 0.1816 - val_dice_coef: 0.8998\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "15s - loss: 0.1778 - dice_coef: 0.9017 - val_loss: 0.1816 - val_dice_coef: 0.9021\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "14s - loss: 0.1973 - dice_coef: 0.8870 - val_loss: 0.1865 - val_dice_coef: 0.8839\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "15s - loss: 0.1802 - dice_coef: 0.8946 - val_loss: 0.1845 - val_dice_coef: 0.9119\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "14s - loss: 0.1882 - dice_coef: 0.8964 - val_loss: 0.1845 - val_dice_coef: 0.8867\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "15s - loss: 0.1803 - dice_coef: 0.8907 - val_loss: 0.1807 - val_dice_coef: 0.9147\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.18038 to 0.17912, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1932 - dice_coef: 0.8864 - val_loss: 0.1791 - val_dice_coef: 0.8925\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.17912 to 0.17546, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "16s - loss: 0.1697 - dice_coef: 0.9079 - val_loss: 0.1755 - val_dice_coef: 0.9106\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.17546 to 0.17400, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1763 - dice_coef: 0.8961 - val_loss: 0.1740 - val_dice_coef: 0.9048\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.17400 to 0.17357, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1696 - dice_coef: 0.9011 - val_loss: 0.1736 - val_dice_coef: 0.9066\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "15s - loss: 0.1838 - dice_coef: 0.8932 - val_loss: 0.1777 - val_dice_coef: 0.8900\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "14s - loss: 0.2022 - dice_coef: 0.8890 - val_loss: 0.1738 - val_dice_coef: 0.8952\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.17357 to 0.16798, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1788 - dice_coef: 0.8916 - val_loss: 0.1680 - val_dice_coef: 0.9137\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "14s - loss: 0.1649 - dice_coef: 0.9028 - val_loss: 0.1703 - val_dice_coef: 0.9047\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "15s - loss: 0.1755 - dice_coef: 0.9033 - val_loss: 0.1725 - val_dice_coef: 0.9016\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "15s - loss: 0.1718 - dice_coef: 0.9023 - val_loss: 0.1717 - val_dice_coef: 0.9122\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "14s - loss: 0.1705 - dice_coef: 0.9012 - val_loss: 0.1696 - val_dice_coef: 0.9058\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "15s - loss: 0.1608 - dice_coef: 0.9079 - val_loss: 0.1695 - val_dice_coef: 0.9085\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "14s - loss: 0.1946 - dice_coef: 0.8810 - val_loss: 0.1724 - val_dice_coef: 0.9009\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "15s - loss: 0.1653 - dice_coef: 0.9113 - val_loss: 0.1710 - val_dice_coef: 0.9043\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "14s - loss: 0.1749 - dice_coef: 0.9038 - val_loss: 0.1695 - val_dice_coef: 0.9073\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.16798 to 0.16638, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1672 - dice_coef: 0.8982 - val_loss: 0.1664 - val_dice_coef: 0.9115\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "15s - loss: 0.1840 - dice_coef: 0.8988 - val_loss: 0.1717 - val_dice_coef: 0.8925\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "14s - loss: 0.1604 - dice_coef: 0.9102 - val_loss: 0.1700 - val_dice_coef: 0.9218\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "15s - loss: 0.1620 - dice_coef: 0.9051 - val_loss: 0.1674 - val_dice_coef: 0.9080\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "14s - loss: 0.1747 - dice_coef: 0.9004 - val_loss: 0.1682 - val_dice_coef: 0.9158\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.16638 to 0.16614, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "16s - loss: 0.1556 - dice_coef: 0.9190 - val_loss: 0.1661 - val_dice_coef: 0.9071\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.16614 to 0.16446, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1567 - dice_coef: 0.9068 - val_loss: 0.1645 - val_dice_coef: 0.9194\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.16446 to 0.16362, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1585 - dice_coef: 0.9097 - val_loss: 0.1636 - val_dice_coef: 0.9152\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.16362 to 0.16258, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1597 - dice_coef: 0.9103 - val_loss: 0.1626 - val_dice_coef: 0.9100\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.16258 to 0.15735, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1717 - dice_coef: 0.9030 - val_loss: 0.1573 - val_dice_coef: 0.9126\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "15s - loss: 0.1586 - dice_coef: 0.9101 - val_loss: 0.1594 - val_dice_coef: 0.9086\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "14s - loss: 0.1536 - dice_coef: 0.9098 - val_loss: 0.1619 - val_dice_coef: 0.9211\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "15s - loss: 0.1506 - dice_coef: 0.9151 - val_loss: 0.1623 - val_dice_coef: 0.9143\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "14s - loss: 0.1627 - dice_coef: 0.9004 - val_loss: 0.1643 - val_dice_coef: 0.9191\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "15s - loss: 0.1583 - dice_coef: 0.9127 - val_loss: 0.1617 - val_dice_coef: 0.9170\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "15s - loss: 0.1544 - dice_coef: 0.9188 - val_loss: 0.1614 - val_dice_coef: 0.9043\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "14s - loss: 0.1478 - dice_coef: 0.9169 - val_loss: 0.1604 - val_dice_coef: 0.9211\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "15s - loss: 0.1517 - dice_coef: 0.9135 - val_loss: 0.1598 - val_dice_coef: 0.9200\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "14s - loss: 0.1459 - dice_coef: 0.9166 - val_loss: 0.1593 - val_dice_coef: 0.9184\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "15s - loss: 0.1564 - dice_coef: 0.9125 - val_loss: 0.1591 - val_dice_coef: 0.9129\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "14s - loss: 0.1611 - dice_coef: 0.9068 - val_loss: 0.1640 - val_dice_coef: 0.9279\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "15s - loss: 0.1672 - dice_coef: 0.9058 - val_loss: 0.1580 - val_dice_coef: 0.9135\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "15s - loss: 0.1455 - dice_coef: 0.9206 - val_loss: 0.1602 - val_dice_coef: 0.9020\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "14s - loss: 0.1471 - dice_coef: 0.9153 - val_loss: 0.1577 - val_dice_coef: 0.9164\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "15s - loss: 0.1521 - dice_coef: 0.9124 - val_loss: 0.1581 - val_dice_coef: 0.9199\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.15735 to 0.15621, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1610 - dice_coef: 0.9068 - val_loss: 0.1562 - val_dice_coef: 0.9193\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "15s - loss: 0.1653 - dice_coef: 0.9074 - val_loss: 0.1572 - val_dice_coef: 0.9057\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "14s - loss: 0.1677 - dice_coef: 0.9103 - val_loss: 0.1567 - val_dice_coef: 0.9192\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.15621 to 0.15586, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1495 - dice_coef: 0.9154 - val_loss: 0.1559 - val_dice_coef: 0.9082\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.15586 to 0.15581, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1629 - dice_coef: 0.9047 - val_loss: 0.1558 - val_dice_coef: 0.9097\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "14s - loss: 0.1392 - dice_coef: 0.9219 - val_loss: 0.1573 - val_dice_coef: 0.9125\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00094: val_loss did not improve\n",
      "15s - loss: 0.1488 - dice_coef: 0.9188 - val_loss: 0.1572 - val_dice_coef: 0.9138\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "14s - loss: 0.1482 - dice_coef: 0.9147 - val_loss: 0.1563 - val_dice_coef: 0.9100\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.15581 to 0.15498, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1481 - dice_coef: 0.9156 - val_loss: 0.1550 - val_dice_coef: 0.9124\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "14s - loss: 0.1387 - dice_coef: 0.9223 - val_loss: 0.1563 - val_dice_coef: 0.9044\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "15s - loss: 0.1424 - dice_coef: 0.9196 - val_loss: 0.1563 - val_dice_coef: 0.9171\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.15498 to 0.15491, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1472 - dice_coef: 0.9185 - val_loss: 0.1549 - val_dice_coef: 0.9170\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "14s - loss: 0.1420 - dice_coef: 0.9170 - val_loss: 0.1623 - val_dice_coef: 0.9323\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "15s - loss: 0.1526 - dice_coef: 0.9098 - val_loss: 0.1551 - val_dice_coef: 0.9224\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "14s - loss: 0.1493 - dice_coef: 0.9144 - val_loss: 0.1561 - val_dice_coef: 0.9064\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "15s - loss: 0.1439 - dice_coef: 0.9217 - val_loss: 0.1552 - val_dice_coef: 0.9123\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "14s - loss: 0.1430 - dice_coef: 0.9171 - val_loss: 0.1549 - val_dice_coef: 0.9197\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "15s - loss: 0.1462 - dice_coef: 0.9155 - val_loss: 0.1549 - val_dice_coef: 0.9190\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.15491 to 0.15299, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1645 - dice_coef: 0.9013 - val_loss: 0.1530 - val_dice_coef: 0.9091\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "14s - loss: 0.1561 - dice_coef: 0.9122 - val_loss: 0.1580 - val_dice_coef: 0.8999\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "15s - loss: 0.1511 - dice_coef: 0.9172 - val_loss: 0.1556 - val_dice_coef: 0.9209\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "14s - loss: 0.1480 - dice_coef: 0.9124 - val_loss: 0.1568 - val_dice_coef: 0.9221\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "15s - loss: 0.1426 - dice_coef: 0.9199 - val_loss: 0.1545 - val_dice_coef: 0.9138\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "14s - loss: 0.1503 - dice_coef: 0.9146 - val_loss: 0.1553 - val_dice_coef: 0.9090\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "15s - loss: 0.1412 - dice_coef: 0.9179 - val_loss: 0.1551 - val_dice_coef: 0.9195\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "15s - loss: 0.1502 - dice_coef: 0.9156 - val_loss: 0.1542 - val_dice_coef: 0.9195\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "14s - loss: 0.1483 - dice_coef: 0.9116 - val_loss: 0.1557 - val_dice_coef: 0.9247\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.15299 to 0.15298, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "16s - loss: 0.1416 - dice_coef: 0.9217 - val_loss: 0.1530 - val_dice_coef: 0.9163\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "14s - loss: 0.1364 - dice_coef: 0.9214 - val_loss: 0.1543 - val_dice_coef: 0.9169\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "15s - loss: 0.1448 - dice_coef: 0.9186 - val_loss: 0.1536 - val_dice_coef: 0.9209\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "14s - loss: 0.1462 - dice_coef: 0.9155 - val_loss: 0.1532 - val_dice_coef: 0.9199\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.15298 to 0.15225, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "16s - loss: 0.1409 - dice_coef: 0.9206 - val_loss: 0.1522 - val_dice_coef: 0.9166\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "15s - loss: 0.1471 - dice_coef: 0.9160 - val_loss: 0.1527 - val_dice_coef: 0.9086\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.15225 to 0.15193, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1363 - dice_coef: 0.9195 - val_loss: 0.1519 - val_dice_coef: 0.9185\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "15s - loss: 0.1540 - dice_coef: 0.9108 - val_loss: 0.1522 - val_dice_coef: 0.9156\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "14s - loss: 0.1570 - dice_coef: 0.9109 - val_loss: 0.1533 - val_dice_coef: 0.9280\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "15s - loss: 0.1350 - dice_coef: 0.9220 - val_loss: 0.1529 - val_dice_coef: 0.9259\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "14s - loss: 0.1452 - dice_coef: 0.9148 - val_loss: 0.1553 - val_dice_coef: 0.9279\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "15s - loss: 0.1357 - dice_coef: 0.9225 - val_loss: 0.1562 - val_dice_coef: 0.9282\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "15s - loss: 0.1491 - dice_coef: 0.9169 - val_loss: 0.1528 - val_dice_coef: 0.9235\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "14s - loss: 0.1459 - dice_coef: 0.9143 - val_loss: 0.1602 - val_dice_coef: 0.9301\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "15s - loss: 0.1424 - dice_coef: 0.9191 - val_loss: 0.1553 - val_dice_coef: 0.9267\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "14s - loss: 0.1478 - dice_coef: 0.9145 - val_loss: 0.1535 - val_dice_coef: 0.9262\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "15s - loss: 0.1429 - dice_coef: 0.9186 - val_loss: 0.1520 - val_dice_coef: 0.9230\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.15193 to 0.15030, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1525 - dice_coef: 0.9116 - val_loss: 0.1503 - val_dice_coef: 0.9159\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.15030 to 0.14941, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1406 - dice_coef: 0.9191 - val_loss: 0.1494 - val_dice_coef: 0.9174\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "15s - loss: 0.1738 - dice_coef: 0.8926 - val_loss: 0.1595 - val_dice_coef: 0.8942\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "14s - loss: 0.1471 - dice_coef: 0.9208 - val_loss: 0.1543 - val_dice_coef: 0.9060\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "15s - loss: 0.1523 - dice_coef: 0.9128 - val_loss: 0.1503 - val_dice_coef: 0.9195\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "14s - loss: 0.1344 - dice_coef: 0.9240 - val_loss: 0.1500 - val_dice_coef: 0.9127\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "15s - loss: 0.1550 - dice_coef: 0.9094 - val_loss: 0.1500 - val_dice_coef: 0.9110\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.14941 to 0.14788, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1399 - dice_coef: 0.9183 - val_loss: 0.1479 - val_dice_coef: 0.9164\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "15s - loss: 0.1411 - dice_coef: 0.9182 - val_loss: 0.1513 - val_dice_coef: 0.9243\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "15s - loss: 0.1467 - dice_coef: 0.9183 - val_loss: 0.1508 - val_dice_coef: 0.9200\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "14s - loss: 0.1375 - dice_coef: 0.9244 - val_loss: 0.1515 - val_dice_coef: 0.9233\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "15s - loss: 0.1359 - dice_coef: 0.9202 - val_loss: 0.1498 - val_dice_coef: 0.9164\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "14s - loss: 0.1380 - dice_coef: 0.9200 - val_loss: 0.1503 - val_dice_coef: 0.9251\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.14788 to 0.14719, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1472 - dice_coef: 0.9144 - val_loss: 0.1472 - val_dice_coef: 0.9171\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "14s - loss: 0.1425 - dice_coef: 0.9206 - val_loss: 0.1499 - val_dice_coef: 0.9085\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "15s - loss: 0.1520 - dice_coef: 0.9093 - val_loss: 0.1505 - val_dice_coef: 0.9055\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "15s - loss: 0.1449 - dice_coef: 0.9175 - val_loss: 0.1511 - val_dice_coef: 0.9066\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "14s - loss: 0.1499 - dice_coef: 0.9122 - val_loss: 0.1516 - val_dice_coef: 0.9249\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00150: val_loss did not improve\n",
      "15s - loss: 0.1408 - dice_coef: 0.9175 - val_loss: 0.1508 - val_dice_coef: 0.9243\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "14s - loss: 0.1594 - dice_coef: 0.8997 - val_loss: 0.1505 - val_dice_coef: 0.9220\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "15s - loss: 0.1580 - dice_coef: 0.9132 - val_loss: 0.1639 - val_dice_coef: 0.8853\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "14s - loss: 0.1456 - dice_coef: 0.9157 - val_loss: 0.1485 - val_dice_coef: 0.9250\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "15s - loss: 0.1419 - dice_coef: 0.9153 - val_loss: 0.1514 - val_dice_coef: 0.9243\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "15s - loss: 0.1453 - dice_coef: 0.9193 - val_loss: 0.1511 - val_dice_coef: 0.9130\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "14s - loss: 0.1344 - dice_coef: 0.9232 - val_loss: 0.1491 - val_dice_coef: 0.9182\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "15s - loss: 0.1432 - dice_coef: 0.9189 - val_loss: 0.1479 - val_dice_coef: 0.9177\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "14s - loss: 0.1371 - dice_coef: 0.9211 - val_loss: 0.1490 - val_dice_coef: 0.9190\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "15s - loss: 0.1423 - dice_coef: 0.9167 - val_loss: 0.1502 - val_dice_coef: 0.9196\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "14s - loss: 0.1416 - dice_coef: 0.9169 - val_loss: 0.1514 - val_dice_coef: 0.9255\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "15s - loss: 0.1408 - dice_coef: 0.9224 - val_loss: 0.1491 - val_dice_coef: 0.9214\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "15s - loss: 0.1379 - dice_coef: 0.9196 - val_loss: 0.1496 - val_dice_coef: 0.9215\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "14s - loss: 0.1328 - dice_coef: 0.9244 - val_loss: 0.1500 - val_dice_coef: 0.9258\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.14719 to 0.14644, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1599 - dice_coef: 0.9058 - val_loss: 0.1464 - val_dice_coef: 0.9108\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "14s - loss: 0.1446 - dice_coef: 0.9139 - val_loss: 0.1540 - val_dice_coef: 0.8989\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "15s - loss: 0.1464 - dice_coef: 0.9222 - val_loss: 0.1498 - val_dice_coef: 0.9231\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "14s - loss: 0.1405 - dice_coef: 0.9150 - val_loss: 0.1488 - val_dice_coef: 0.9208\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "15s - loss: 0.1460 - dice_coef: 0.9203 - val_loss: 0.1504 - val_dice_coef: 0.9064\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "15s - loss: 0.1429 - dice_coef: 0.9186 - val_loss: 0.1477 - val_dice_coef: 0.9173\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "14s - loss: 0.1372 - dice_coef: 0.9156 - val_loss: 0.1504 - val_dice_coef: 0.9265\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "15s - loss: 0.1457 - dice_coef: 0.9155 - val_loss: 0.1472 - val_dice_coef: 0.9156\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "14s - loss: 0.1363 - dice_coef: 0.9232 - val_loss: 0.1472 - val_dice_coef: 0.9177\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.14644 to 0.14610, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1372 - dice_coef: 0.9226 - val_loss: 0.1461 - val_dice_coef: 0.9225\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.14610 to 0.14556, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1376 - dice_coef: 0.9197 - val_loss: 0.1456 - val_dice_coef: 0.9224\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "15s - loss: 0.1376 - dice_coef: 0.9208 - val_loss: 0.1468 - val_dice_coef: 0.9228\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "15s - loss: 0.1535 - dice_coef: 0.9092 - val_loss: 0.1466 - val_dice_coef: 0.9203\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "14s - loss: 0.1459 - dice_coef: 0.9195 - val_loss: 0.1592 - val_dice_coef: 0.8892\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.14556 to 0.14503, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "16s - loss: 0.1465 - dice_coef: 0.9165 - val_loss: 0.1450 - val_dice_coef: 0.9202\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "14s - loss: 0.1400 - dice_coef: 0.9108 - val_loss: 0.1518 - val_dice_coef: 0.9303\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "15s - loss: 0.1487 - dice_coef: 0.9166 - val_loss: 0.1531 - val_dice_coef: 0.8995\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "14s - loss: 0.1363 - dice_coef: 0.9221 - val_loss: 0.1496 - val_dice_coef: 0.9079\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "15s - loss: 0.1377 - dice_coef: 0.9203 - val_loss: 0.1533 - val_dice_coef: 0.9289\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "15s - loss: 0.1403 - dice_coef: 0.9154 - val_loss: 0.1484 - val_dice_coef: 0.9223\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "14s - loss: 0.1406 - dice_coef: 0.9219 - val_loss: 0.1464 - val_dice_coef: 0.9157\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "15s - loss: 0.1354 - dice_coef: 0.9217 - val_loss: 0.1458 - val_dice_coef: 0.9163\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "14s - loss: 0.1379 - dice_coef: 0.9168 - val_loss: 0.1457 - val_dice_coef: 0.9195\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "15s - loss: 0.1605 - dice_coef: 0.9098 - val_loss: 0.1463 - val_dice_coef: 0.9081\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "14s - loss: 0.1397 - dice_coef: 0.9180 - val_loss: 0.1457 - val_dice_coef: 0.9178\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "15s - loss: 0.1317 - dice_coef: 0.9255 - val_loss: 0.1486 - val_dice_coef: 0.9232\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "15s - loss: 0.1375 - dice_coef: 0.9206 - val_loss: 0.1457 - val_dice_coef: 0.9176\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "14s - loss: 0.1349 - dice_coef: 0.9213 - val_loss: 0.1477 - val_dice_coef: 0.9278\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "15s - loss: 0.1365 - dice_coef: 0.9197 - val_loss: 0.1467 - val_dice_coef: 0.9269\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "14s - loss: 0.1401 - dice_coef: 0.9147 - val_loss: 0.1507 - val_dice_coef: 0.9327\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.14503 to 0.14456, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1408 - dice_coef: 0.9192 - val_loss: 0.1446 - val_dice_coef: 0.9194\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "14s - loss: 0.1393 - dice_coef: 0.9233 - val_loss: 0.1488 - val_dice_coef: 0.9055\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "15s - loss: 0.1393 - dice_coef: 0.9188 - val_loss: 0.1473 - val_dice_coef: 0.9276\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "15s - loss: 0.1405 - dice_coef: 0.9165 - val_loss: 0.1449 - val_dice_coef: 0.9255\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "14s - loss: 0.1385 - dice_coef: 0.9184 - val_loss: 0.1493 - val_dice_coef: 0.9311\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.14456 to 0.14426, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1365 - dice_coef: 0.9205 - val_loss: 0.1443 - val_dice_coef: 0.9178\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/endo_models/weightsNoDrop.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "hist = model.fit_generator(train_generator,steps_per_epoch=train_steps,epochs=epochs,verbose=2,callbacks=[checkpointer],\n",
    "                   validation_data=(validation_images,validation_inner_masks),validation_steps=val_steps)\n",
    "#show_plots(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXBTMzKzyH2F6+VZAw4AiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6327253780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wF+3yOFZLcUngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6325c0d978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(np.max(hist.history['val_dice_coef']))\n",
    "#print(np.max(hist.history['dice_coef']))\n",
    "\n",
    "# model.load_weights('saved_models/weights.hdf5')\n",
    "show_plots(hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Statistics(No Dropout)...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected float64, got list containing Tensors of type '_Message' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e3004827db4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Statistics(No Dropout)...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mcalculate_dice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_inner_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Statistics(No Dropout)...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mcalculate_dice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_inner_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-e3004827db4f>\u001b[0m in \u001b[0;36mcalculate_dice\u001b[0;34m(images, masks_true)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice_coef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#print(dices)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdice_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dice: {:.2f} Loss: {:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice_tf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice_tf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 102\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    103\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    374\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m       \u001b[0m_AssertCompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m       \u001b[0;31m# check to them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n\u001b[0;32m--> 302\u001b[0;31m                       (dtype.name, repr(mismatch), type(mismatch).__name__))\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected float64, got list containing Tensors of type '_Message' instead."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model.load_weights('saved_models/endo_models/weightsNoDrop.hdf5')\n",
    "def calculate_dice(images, masks_true):\n",
    "    dices = []\n",
    "    #for image,mask_true in zip(images,masks_true):\n",
    "     #   mask_pred = model.predict(image[None,:,:,:])\n",
    "      #  y_true = mask_true[:,:,1].astype('float64')\n",
    "       # y_pred = mask_pred[:,:,1].astype('float64')\n",
    "        #dices.append(dice_coef(y_true,y_pred))\n",
    "    masks_pred = np.concatenate([model.predict(image[None,:,:,:]) for image in images])\n",
    "    for mask_true, mask_pred in zip(masks_true, masks_pred):\n",
    "        y_true = mask_true[:,:,1].astype('float64')\n",
    "        y_pred = mask_pred[:,:,1].astype('float64')\n",
    "        dices.append(dice_coef(y_true, y_pred))\n",
    "    #print(dices)\n",
    "    dice_tf = K.constant(dices,dtype='float64')\n",
    "    print(\"Dice: {:.2f} Loss: {:.2f}\".format(K.mean(dice_tf), K.std(dice_tf)))\n",
    "    \n",
    "print(\"Training Statistics(No Dropout)...\")\n",
    "calculate_dice(train_images,train_inner_masks)\n",
    "print(\"Validation Statistics(No Dropout)...\")\n",
    "calculate_dice(validation_images,validation_inner_masks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Results of Endocardium Model\n",
    "\n",
    "## Training\n",
    "hyperparams: {Dropout:0.5, Epochs:50, Batch Size: 20}\n",
    "\n",
    "- train_dice = 0.62365097794\n",
    "- val_dice = 0.522672422078\n",
    "\n",
    "hyperparams: {Dropout:0.5, Epochs: 200, Batch Size: 20}\n",
    "\n",
    "- train_dice = 0.878794970879\n",
    "- val_dice = 0.841971736781\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 216, 256, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 216, 256, 32)  320         input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 216, 256, 32)  0           conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 216, 256, 32)  0           activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 216, 256, 32)  9248        dropout_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 216, 256, 32)  0           conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 216, 256, 32)  0           activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, 108, 128, 32)  0           dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 108, 128, 64)  18496       max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 108, 128, 64)  0           conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 108, 128, 64)  0           activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 108, 128, 64)  36928       dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 108, 128, 64)  0           conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)             (None, 108, 128, 64)  0           activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, 54, 64, 64)    0           dropout_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 54, 64, 128)   73856       max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 54, 64, 128)   0           conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)             (None, 54, 64, 128)   0           activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, 54, 64, 128)   147584      dropout_19[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 54, 64, 128)   0           conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)             (None, 54, 64, 128)   0           activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)   (None, 27, 32, 128)   0           dropout_20[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 27, 32, 256)   295168      max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 27, 32, 256)   0           conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)             (None, 27, 32, 256)   0           activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 27, 32, 256)   590080      dropout_21[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 27, 32, 256)   0           conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)             (None, 27, 32, 256)   0           activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTransp (None, 54, 64, 128)   131200      dropout_22[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 54, 64, 256)   0           conv2d_transpose_4[0][0]         \n",
      "                                                                   conv2d_transpose_4[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 54, 64, 128)   295040      concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 54, 64, 128)   0           conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)             (None, 54, 64, 128)   0           activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 54, 64, 128)   147584      dropout_23[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 54, 64, 128)   0           conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)             (None, 54, 64, 128)   0           activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTransp (None, 108, 128, 64)  32832       dropout_24[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 108, 128, 128) 0           conv2d_transpose_5[0][0]         \n",
      "                                                                   conv2d_transpose_5[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 108, 128, 64)  73792       concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 108, 128, 64)  0           conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)             (None, 108, 128, 64)  0           activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, 108, 128, 64)  36928       dropout_25[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 108, 128, 64)  0           conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)             (None, 108, 128, 64)  0           activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTransp (None, 216, 256, 32)  8224        dropout_26[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)      (None, 216, 256, 64)  0           conv2d_transpose_6[0][0]         \n",
      "                                                                   conv2d_transpose_6[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, 216, 256, 32)  18464       concatenate_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 216, 256, 32)  0           conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)             (None, 216, 256, 32)  0           activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, 216, 256, 32)  9248        dropout_27[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 216, 256, 32)  0           conv2d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)             (None, 216, 256, 32)  0           activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, 216, 256, 2)   66          dropout_28[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1,925,058\n",
      "Trainable params: 1,925,058\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_epi = unet_conv.get_unet(height=height,width=width,channels=1,features=32,steps=3,dropout=dropout,padding='same')\n",
    "\n",
    "model_epi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/preprocessing/image.py:653: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (194, 216, 256, 2) (2 channels).\n",
      "/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/preprocessing/image.py:787: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (194, 216, 256, 2) (2 channels).\n"
     ]
    }
   ],
   "source": [
    "seed_epi = 10\n",
    "\n",
    "train_outer_masks = o_masks[:split_index]\n",
    "\n",
    "train_images_datagen.fit(train_images,augment=True,seed=seed)\n",
    "train_masks_datagen.fit(train_outer_masks,augment=True,seed=seed)\n",
    "\n",
    "train_images_generator = train_images_datagen.flow(train_images, y=None, seed=seed)\n",
    "train_masks_generator = train_images_datagen.flow(train_outer_masks, y=None, seed=seed)\n",
    "\n",
    "\n",
    "train_outer_generator = zip(train_images_generator, train_masks_generator)\n",
    "\n",
    "validation_outer_masks = o_masks[split_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.69272, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "17s - loss: 0.7114 - dice_coef: 0.4918 - val_loss: 0.6927 - val_dice_coef: 0.5005\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.69272 to 0.67302, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.6831 - dice_coef: 0.5055 - val_loss: 0.6730 - val_dice_coef: 0.5106\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.67302 to 0.63828, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.6564 - dice_coef: 0.5199 - val_loss: 0.6383 - val_dice_coef: 0.5298\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.63828 to 0.56203, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.6017 - dice_coef: 0.5529 - val_loss: 0.5620 - val_dice_coef: 0.5782\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.56203 to 0.44360, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.4909 - dice_coef: 0.6352 - val_loss: 0.4436 - val_dice_coef: 0.6824\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.44360 to 0.39946, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.4201 - dice_coef: 0.7466 - val_loss: 0.3995 - val_dice_coef: 0.7733\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.39946 to 0.38907, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.4039 - dice_coef: 0.7908 - val_loss: 0.3891 - val_dice_coef: 0.7677\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "15s - loss: 0.4084 - dice_coef: 0.7649 - val_loss: 0.3920 - val_dice_coef: 0.7357\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.38907 to 0.37557, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3768 - dice_coef: 0.7580 - val_loss: 0.3756 - val_dice_coef: 0.7597\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.37557 to 0.36362, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.3884 - dice_coef: 0.7781 - val_loss: 0.3636 - val_dice_coef: 0.7774\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.36362 to 0.36139, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3818 - dice_coef: 0.7776 - val_loss: 0.3614 - val_dice_coef: 0.7625\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.36139 to 0.34674, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.3543 - dice_coef: 0.7831 - val_loss: 0.3467 - val_dice_coef: 0.7826\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.34674 to 0.33638, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3493 - dice_coef: 0.8021 - val_loss: 0.3364 - val_dice_coef: 0.7913\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.33638 to 0.32689, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.3478 - dice_coef: 0.7960 - val_loss: 0.3269 - val_dice_coef: 0.7943\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.32689 to 0.31562, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3337 - dice_coef: 0.8030 - val_loss: 0.3156 - val_dice_coef: 0.8033\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.31562 to 0.31010, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3371 - dice_coef: 0.8011 - val_loss: 0.3101 - val_dice_coef: 0.7982\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.31010 to 0.29514, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.3040 - dice_coef: 0.8201 - val_loss: 0.2951 - val_dice_coef: 0.8241\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.29514 to 0.28937, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3182 - dice_coef: 0.8145 - val_loss: 0.2894 - val_dice_coef: 0.8175\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.28937 to 0.28394, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.3164 - dice_coef: 0.8225 - val_loss: 0.2839 - val_dice_coef: 0.8168\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.28394 to 0.27574, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2951 - dice_coef: 0.8108 - val_loss: 0.2757 - val_dice_coef: 0.8260\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.27574 to 0.26734, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2837 - dice_coef: 0.8363 - val_loss: 0.2673 - val_dice_coef: 0.8399\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.26734 to 0.26369, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "16s - loss: 0.2845 - dice_coef: 0.8323 - val_loss: 0.2637 - val_dice_coef: 0.8357\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.26369 to 0.25702, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2667 - dice_coef: 0.8445 - val_loss: 0.2570 - val_dice_coef: 0.8513\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.25702 to 0.25546, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2738 - dice_coef: 0.8354 - val_loss: 0.2555 - val_dice_coef: 0.8381\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.25546 to 0.25004, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2612 - dice_coef: 0.8418 - val_loss: 0.2500 - val_dice_coef: 0.8602\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.25004 to 0.24807, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2678 - dice_coef: 0.8375 - val_loss: 0.2481 - val_dice_coef: 0.8438\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.24807 to 0.24275, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2504 - dice_coef: 0.8532 - val_loss: 0.2428 - val_dice_coef: 0.8568\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.24275 to 0.24001, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2379 - dice_coef: 0.8558 - val_loss: 0.2400 - val_dice_coef: 0.8591\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.24001 to 0.23948, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2509 - dice_coef: 0.8546 - val_loss: 0.2395 - val_dice_coef: 0.8528\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.23948 to 0.23716, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2436 - dice_coef: 0.8492 - val_loss: 0.2372 - val_dice_coef: 0.8632\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.23716 to 0.23483, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2550 - dice_coef: 0.8558 - val_loss: 0.2348 - val_dice_coef: 0.8570\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.23483 to 0.23111, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2325 - dice_coef: 0.8642 - val_loss: 0.2311 - val_dice_coef: 0.8663\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.23111 to 0.22938, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2366 - dice_coef: 0.8530 - val_loss: 0.2294 - val_dice_coef: 0.8687\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.22938 to 0.22721, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2303 - dice_coef: 0.8659 - val_loss: 0.2272 - val_dice_coef: 0.8667\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.22721 to 0.22606, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2267 - dice_coef: 0.8665 - val_loss: 0.2261 - val_dice_coef: 0.8627\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "15s - loss: 0.2304 - dice_coef: 0.8533 - val_loss: 0.2307 - val_dice_coef: 0.8879\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "15s - loss: 0.2290 - dice_coef: 0.8666 - val_loss: 0.2271 - val_dice_coef: 0.8560\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.22606 to 0.22285, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2358 - dice_coef: 0.8617 - val_loss: 0.2229 - val_dice_coef: 0.8631\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.22285 to 0.22028, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2235 - dice_coef: 0.8591 - val_loss: 0.2203 - val_dice_coef: 0.8815\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.22028 to 0.21776, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2331 - dice_coef: 0.8617 - val_loss: 0.2178 - val_dice_coef: 0.8692\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "15s - loss: 0.2366 - dice_coef: 0.8616 - val_loss: 0.2217 - val_dice_coef: 0.8568\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00041: val_loss improved from 0.21776 to 0.21727, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2240 - dice_coef: 0.8644 - val_loss: 0.2173 - val_dice_coef: 0.8753\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "15s - loss: 0.2223 - dice_coef: 0.8653 - val_loss: 0.2179 - val_dice_coef: 0.8787\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.21727 to 0.21656, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2155 - dice_coef: 0.8734 - val_loss: 0.2166 - val_dice_coef: 0.8738\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "14s - loss: 0.2279 - dice_coef: 0.8646 - val_loss: 0.2176 - val_dice_coef: 0.8647\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "15s - loss: 0.2122 - dice_coef: 0.8738 - val_loss: 0.2176 - val_dice_coef: 0.8703\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "14s - loss: 0.2273 - dice_coef: 0.8650 - val_loss: 0.2167 - val_dice_coef: 0.8684\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.21656 to 0.21517, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "16s - loss: 0.2159 - dice_coef: 0.8661 - val_loss: 0.2152 - val_dice_coef: 0.8880\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.21517 to 0.21233, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2308 - dice_coef: 0.8555 - val_loss: 0.2123 - val_dice_coef: 0.8712\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.21233 to 0.21007, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2020 - dice_coef: 0.8833 - val_loss: 0.2101 - val_dice_coef: 0.8803\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.21007 to 0.20886, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2089 - dice_coef: 0.8740 - val_loss: 0.2089 - val_dice_coef: 0.8833\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "14s - loss: 0.2029 - dice_coef: 0.8739 - val_loss: 0.2093 - val_dice_coef: 0.8872\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "15s - loss: 0.2198 - dice_coef: 0.8678 - val_loss: 0.2109 - val_dice_coef: 0.8659\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.20886 to 0.20583, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2230 - dice_coef: 0.8702 - val_loss: 0.2058 - val_dice_coef: 0.8751\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.20583 to 0.20241, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2110 - dice_coef: 0.8699 - val_loss: 0.2024 - val_dice_coef: 0.8835\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "14s - loss: 0.1995 - dice_coef: 0.8779 - val_loss: 0.2054 - val_dice_coef: 0.8887\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "15s - loss: 0.2105 - dice_coef: 0.8755 - val_loss: 0.2038 - val_dice_coef: 0.8827\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "15s - loss: 0.2039 - dice_coef: 0.8793 - val_loss: 0.2035 - val_dice_coef: 0.8813\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "14s - loss: 0.2022 - dice_coef: 0.8775 - val_loss: 0.2034 - val_dice_coef: 0.8774\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "15s - loss: 0.1962 - dice_coef: 0.8796 - val_loss: 0.2036 - val_dice_coef: 0.8808\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "14s - loss: 0.2243 - dice_coef: 0.8658 - val_loss: 0.2045 - val_dice_coef: 0.8838\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "15s - loss: 0.1963 - dice_coef: 0.8838 - val_loss: 0.2031 - val_dice_coef: 0.8842\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "14s - loss: 0.2040 - dice_coef: 0.8826 - val_loss: 0.2032 - val_dice_coef: 0.8728\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "15s - loss: 0.2037 - dice_coef: 0.8719 - val_loss: 0.2033 - val_dice_coef: 0.8964\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "15s - loss: 0.2222 - dice_coef: 0.8629 - val_loss: 0.2095 - val_dice_coef: 0.8598\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.20241 to 0.20218, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1976 - dice_coef: 0.8870 - val_loss: 0.2022 - val_dice_coef: 0.8867\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "15s - loss: 0.1962 - dice_coef: 0.8774 - val_loss: 0.2033 - val_dice_coef: 0.8904\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "14s - loss: 0.2167 - dice_coef: 0.8738 - val_loss: 0.2023 - val_dice_coef: 0.8843\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.20218 to 0.20145, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "16s - loss: 0.1920 - dice_coef: 0.8934 - val_loss: 0.2014 - val_dice_coef: 0.8771\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.20145 to 0.20101, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1930 - dice_coef: 0.8814 - val_loss: 0.2010 - val_dice_coef: 0.8946\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.20101 to 0.19867, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1932 - dice_coef: 0.8831 - val_loss: 0.1987 - val_dice_coef: 0.8887\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.19867 to 0.19804, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1944 - dice_coef: 0.8862 - val_loss: 0.1980 - val_dice_coef: 0.8839\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.19804 to 0.19409, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2084 - dice_coef: 0.8758 - val_loss: 0.1941 - val_dice_coef: 0.8903\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.19409 to 0.19376, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "16s - loss: 0.1928 - dice_coef: 0.8859 - val_loss: 0.1938 - val_dice_coef: 0.8842\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "14s - loss: 0.1901 - dice_coef: 0.8836 - val_loss: 0.1977 - val_dice_coef: 0.8959\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "15s - loss: 0.1851 - dice_coef: 0.8888 - val_loss: 0.1967 - val_dice_coef: 0.8906\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "14s - loss: 0.1977 - dice_coef: 0.8755 - val_loss: 0.1985 - val_dice_coef: 0.8938\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "15s - loss: 0.1960 - dice_coef: 0.8848 - val_loss: 0.1962 - val_dice_coef: 0.8888\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "15s - loss: 0.1900 - dice_coef: 0.8947 - val_loss: 0.1967 - val_dice_coef: 0.8763\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "14s - loss: 0.1833 - dice_coef: 0.8902 - val_loss: 0.1948 - val_dice_coef: 0.8941\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "15s - loss: 0.1885 - dice_coef: 0.8873 - val_loss: 0.1939 - val_dice_coef: 0.8926\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "14s - loss: 0.1811 - dice_coef: 0.8908 - val_loss: 0.1942 - val_dice_coef: 0.8924\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.19376 to 0.19361, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1924 - dice_coef: 0.8865 - val_loss: 0.1936 - val_dice_coef: 0.8871\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "14s - loss: 0.1999 - dice_coef: 0.8815 - val_loss: 0.1982 - val_dice_coef: 0.9010\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.19361 to 0.19247, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2012 - dice_coef: 0.8824 - val_loss: 0.1925 - val_dice_coef: 0.8888\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "15s - loss: 0.1792 - dice_coef: 0.8957 - val_loss: 0.1951 - val_dice_coef: 0.8754\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "14s - loss: 0.1825 - dice_coef: 0.8902 - val_loss: 0.1925 - val_dice_coef: 0.8889\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "15s - loss: 0.1889 - dice_coef: 0.8856 - val_loss: 0.1928 - val_dice_coef: 0.8928\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.19247 to 0.18983, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2002 - dice_coef: 0.8822 - val_loss: 0.1898 - val_dice_coef: 0.8906\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "15s - loss: 0.2018 - dice_coef: 0.8827 - val_loss: 0.1914 - val_dice_coef: 0.8835\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "14s - loss: 0.2046 - dice_coef: 0.8817 - val_loss: 0.1933 - val_dice_coef: 0.8949\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "15s - loss: 0.1845 - dice_coef: 0.8917 - val_loss: 0.1904 - val_dice_coef: 0.8853\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "15s - loss: 0.1960 - dice_coef: 0.8800 - val_loss: 0.1910 - val_dice_coef: 0.8827\n",
      "Epoch 94/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00093: val_loss did not improve\n",
      "14s - loss: 0.1746 - dice_coef: 0.8956 - val_loss: 0.1924 - val_dice_coef: 0.8854\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "15s - loss: 0.1857 - dice_coef: 0.8942 - val_loss: 0.1921 - val_dice_coef: 0.8841\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "14s - loss: 0.1833 - dice_coef: 0.8889 - val_loss: 0.1910 - val_dice_coef: 0.8827\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.18983 to 0.18977, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1837 - dice_coef: 0.8899 - val_loss: 0.1898 - val_dice_coef: 0.8849\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "14s - loss: 0.1748 - dice_coef: 0.8965 - val_loss: 0.1932 - val_dice_coef: 0.8744\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "15s - loss: 0.1802 - dice_coef: 0.8953 - val_loss: 0.1899 - val_dice_coef: 0.8885\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.18977 to 0.18926, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1831 - dice_coef: 0.8929 - val_loss: 0.1893 - val_dice_coef: 0.8886\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "14s - loss: 0.1746 - dice_coef: 0.8949 - val_loss: 0.1928 - val_dice_coef: 0.9021\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "15s - loss: 0.1876 - dice_coef: 0.8843 - val_loss: 0.1903 - val_dice_coef: 0.8960\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "14s - loss: 0.1842 - dice_coef: 0.8892 - val_loss: 0.1907 - val_dice_coef: 0.8798\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "15s - loss: 0.1797 - dice_coef: 0.8963 - val_loss: 0.1897 - val_dice_coef: 0.8828\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.18926 to 0.18871, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1784 - dice_coef: 0.8926 - val_loss: 0.1887 - val_dice_coef: 0.8892\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.18871 to 0.18835, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1812 - dice_coef: 0.8917 - val_loss: 0.1884 - val_dice_coef: 0.8905\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.18835 to 0.18728, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1942 - dice_coef: 0.8801 - val_loss: 0.1873 - val_dice_coef: 0.8888\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "14s - loss: 0.1908 - dice_coef: 0.8849 - val_loss: 0.1923 - val_dice_coef: 0.8788\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "15s - loss: 0.1863 - dice_coef: 0.8956 - val_loss: 0.1895 - val_dice_coef: 0.8887\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "14s - loss: 0.1818 - dice_coef: 0.8891 - val_loss: 0.1935 - val_dice_coef: 0.9012\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "15s - loss: 0.1761 - dice_coef: 0.8925 - val_loss: 0.1916 - val_dice_coef: 0.8983\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "14s - loss: 0.1866 - dice_coef: 0.8876 - val_loss: 0.1897 - val_dice_coef: 0.8922\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "15s - loss: 0.1756 - dice_coef: 0.8947 - val_loss: 0.1891 - val_dice_coef: 0.8980\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.18728 to 0.18668, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1861 - dice_coef: 0.8901 - val_loss: 0.1867 - val_dice_coef: 0.8937\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "14s - loss: 0.1838 - dice_coef: 0.8873 - val_loss: 0.1883 - val_dice_coef: 0.8976\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.18668 to 0.18639, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1760 - dice_coef: 0.8971 - val_loss: 0.1864 - val_dice_coef: 0.8909\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "14s - loss: 0.1707 - dice_coef: 0.8954 - val_loss: 0.1883 - val_dice_coef: 0.8967\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "15s - loss: 0.1828 - dice_coef: 0.8912 - val_loss: 0.1879 - val_dice_coef: 0.8982\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "14s - loss: 0.1827 - dice_coef: 0.8897 - val_loss: 0.1870 - val_dice_coef: 0.8952\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.18639 to 0.18549, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1749 - dice_coef: 0.8969 - val_loss: 0.1855 - val_dice_coef: 0.8920\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "15s - loss: 0.1836 - dice_coef: 0.8914 - val_loss: 0.1872 - val_dice_coef: 0.8805\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.18549 to 0.18498, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1709 - dice_coef: 0.8949 - val_loss: 0.1850 - val_dice_coef: 0.8928\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "15s - loss: 0.1879 - dice_coef: 0.8881 - val_loss: 0.1851 - val_dice_coef: 0.8918\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.18498 to 0.18180, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1952 - dice_coef: 0.8832 - val_loss: 0.1818 - val_dice_coef: 0.8908\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "15s - loss: 0.1693 - dice_coef: 0.8977 - val_loss: 0.1865 - val_dice_coef: 0.8954\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "14s - loss: 0.1828 - dice_coef: 0.8875 - val_loss: 0.1889 - val_dice_coef: 0.9008\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "15s - loss: 0.1704 - dice_coef: 0.8983 - val_loss: 0.1886 - val_dice_coef: 0.9026\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "15s - loss: 0.1870 - dice_coef: 0.8886 - val_loss: 0.1869 - val_dice_coef: 0.9003\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "14s - loss: 0.1848 - dice_coef: 0.8866 - val_loss: 0.1915 - val_dice_coef: 0.9040\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "15s - loss: 0.1759 - dice_coef: 0.8964 - val_loss: 0.1865 - val_dice_coef: 0.8994\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "14s - loss: 0.1841 - dice_coef: 0.8909 - val_loss: 0.1850 - val_dice_coef: 0.9012\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "15s - loss: 0.1754 - dice_coef: 0.8938 - val_loss: 0.1855 - val_dice_coef: 0.8995\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "14s - loss: 0.1908 - dice_coef: 0.8852 - val_loss: 0.1828 - val_dice_coef: 0.8930\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.18180 to 0.18171, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1771 - dice_coef: 0.8932 - val_loss: 0.1817 - val_dice_coef: 0.8931\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "15s - loss: 0.2125 - dice_coef: 0.8658 - val_loss: 0.2106 - val_dice_coef: 0.8496\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "14s - loss: 0.1906 - dice_coef: 0.8912 - val_loss: 0.1926 - val_dice_coef: 0.9003\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "15s - loss: 0.1907 - dice_coef: 0.8835 - val_loss: 0.1862 - val_dice_coef: 0.8838\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "14s - loss: 0.1734 - dice_coef: 0.8975 - val_loss: 0.1913 - val_dice_coef: 0.8738\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "15s - loss: 0.1933 - dice_coef: 0.8834 - val_loss: 0.1846 - val_dice_coef: 0.8839\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.18171 to 0.18085, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1757 - dice_coef: 0.8926 - val_loss: 0.1808 - val_dice_coef: 0.8905\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "15s - loss: 0.1751 - dice_coef: 0.8925 - val_loss: 0.1845 - val_dice_coef: 0.8985\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "15s - loss: 0.1813 - dice_coef: 0.8926 - val_loss: 0.1844 - val_dice_coef: 0.8930\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "14s - loss: 0.1733 - dice_coef: 0.8989 - val_loss: 0.1834 - val_dice_coef: 0.8938\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "15s - loss: 0.1709 - dice_coef: 0.8954 - val_loss: 0.1831 - val_dice_coef: 0.8885\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "14s - loss: 0.1711 - dice_coef: 0.8957 - val_loss: 0.1823 - val_dice_coef: 0.8951\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.18085 to 0.18067, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1819 - dice_coef: 0.8909 - val_loss: 0.1807 - val_dice_coef: 0.8891\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "14s - loss: 0.1753 - dice_coef: 0.8953 - val_loss: 0.1828 - val_dice_coef: 0.8873\n",
      "Epoch 148/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00147: val_loss did not improve\n",
      "15s - loss: 0.1876 - dice_coef: 0.8849 - val_loss: 0.1887 - val_dice_coef: 0.8745\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "15s - loss: 0.1808 - dice_coef: 0.8922 - val_loss: 0.1897 - val_dice_coef: 0.8748\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "14s - loss: 0.1869 - dice_coef: 0.8861 - val_loss: 0.1866 - val_dice_coef: 0.9015\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "15s - loss: 0.1749 - dice_coef: 0.8925 - val_loss: 0.1848 - val_dice_coef: 0.8984\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "14s - loss: 0.1950 - dice_coef: 0.8738 - val_loss: 0.1835 - val_dice_coef: 0.8878\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "15s - loss: 0.1864 - dice_coef: 0.8921 - val_loss: 0.1917 - val_dice_coef: 0.8696\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "14s - loss: 0.1773 - dice_coef: 0.8915 - val_loss: 0.1819 - val_dice_coef: 0.8911\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "15s - loss: 0.1770 - dice_coef: 0.8930 - val_loss: 0.1864 - val_dice_coef: 0.8983\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "15s - loss: 0.1799 - dice_coef: 0.8923 - val_loss: 0.1840 - val_dice_coef: 0.8910\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "14s - loss: 0.1686 - dice_coef: 0.8978 - val_loss: 0.1827 - val_dice_coef: 0.8895\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "15s - loss: 0.1802 - dice_coef: 0.8939 - val_loss: 0.1821 - val_dice_coef: 0.8884\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "14s - loss: 0.1732 - dice_coef: 0.8966 - val_loss: 0.1831 - val_dice_coef: 0.8884\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "15s - loss: 0.1784 - dice_coef: 0.8915 - val_loss: 0.1835 - val_dice_coef: 0.8919\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "14s - loss: 0.1772 - dice_coef: 0.8915 - val_loss: 0.1834 - val_dice_coef: 0.8994\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "15s - loss: 0.1759 - dice_coef: 0.8971 - val_loss: 0.1822 - val_dice_coef: 0.8950\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "15s - loss: 0.1723 - dice_coef: 0.8962 - val_loss: 0.1827 - val_dice_coef: 0.8957\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "14s - loss: 0.1693 - dice_coef: 0.8984 - val_loss: 0.1826 - val_dice_coef: 0.8997\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.18067 to 0.17852, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1978 - dice_coef: 0.8828 - val_loss: 0.1785 - val_dice_coef: 0.8889\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "14s - loss: 0.1759 - dice_coef: 0.8915 - val_loss: 0.1886 - val_dice_coef: 0.8782\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "15s - loss: 0.1806 - dice_coef: 0.8986 - val_loss: 0.1847 - val_dice_coef: 0.8912\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "14s - loss: 0.1708 - dice_coef: 0.8948 - val_loss: 0.1860 - val_dice_coef: 0.9021\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "15s - loss: 0.1810 - dice_coef: 0.8895 - val_loss: 0.1804 - val_dice_coef: 0.8903\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "15s - loss: 0.1740 - dice_coef: 0.8956 - val_loss: 0.1819 - val_dice_coef: 0.8857\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "14s - loss: 0.1717 - dice_coef: 0.8949 - val_loss: 0.1826 - val_dice_coef: 0.8850\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "15s - loss: 0.1797 - dice_coef: 0.8908 - val_loss: 0.1824 - val_dice_coef: 0.8935\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "14s - loss: 0.1703 - dice_coef: 0.8974 - val_loss: 0.1828 - val_dice_coef: 0.8985\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "15s - loss: 0.1729 - dice_coef: 0.8949 - val_loss: 0.1798 - val_dice_coef: 0.8987\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "14s - loss: 0.1715 - dice_coef: 0.8978 - val_loss: 0.1792 - val_dice_coef: 0.8898\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "15s - loss: 0.1703 - dice_coef: 0.8972 - val_loss: 0.1806 - val_dice_coef: 0.8939\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "15s - loss: 0.1870 - dice_coef: 0.8816 - val_loss: 0.1816 - val_dice_coef: 0.8962\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "14s - loss: 0.1811 - dice_coef: 0.8943 - val_loss: 0.1928 - val_dice_coef: 0.8660\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "15s - loss: 0.1778 - dice_coef: 0.8935 - val_loss: 0.1811 - val_dice_coef: 0.8834\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "14s - loss: 0.1721 - dice_coef: 0.8920 - val_loss: 0.1817 - val_dice_coef: 0.8971\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "15s - loss: 0.1768 - dice_coef: 0.8911 - val_loss: 0.1824 - val_dice_coef: 0.8928\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "14s - loss: 0.1676 - dice_coef: 0.8973 - val_loss: 0.1847 - val_dice_coef: 0.8801\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "15s - loss: 0.1683 - dice_coef: 0.9017 - val_loss: 0.1814 - val_dice_coef: 0.8920\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "15s - loss: 0.1740 - dice_coef: 0.8930 - val_loss: 0.1816 - val_dice_coef: 0.9007\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "14s - loss: 0.1764 - dice_coef: 0.8932 - val_loss: 0.1793 - val_dice_coef: 0.8981\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "15s - loss: 0.1690 - dice_coef: 0.8975 - val_loss: 0.1796 - val_dice_coef: 0.8931\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "14s - loss: 0.1716 - dice_coef: 0.8934 - val_loss: 0.1785 - val_dice_coef: 0.8896\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.17852 to 0.17830, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1926 - dice_coef: 0.8867 - val_loss: 0.1783 - val_dice_coef: 0.8836\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "14s - loss: 0.1718 - dice_coef: 0.8916 - val_loss: 0.1807 - val_dice_coef: 0.8990\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "15s - loss: 0.1667 - dice_coef: 0.9011 - val_loss: 0.1823 - val_dice_coef: 0.8972\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "15s - loss: 0.1711 - dice_coef: 0.8971 - val_loss: 0.1788 - val_dice_coef: 0.8874\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.17830 to 0.17722, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1675 - dice_coef: 0.8972 - val_loss: 0.1772 - val_dice_coef: 0.8972\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "15s - loss: 0.1705 - dice_coef: 0.8965 - val_loss: 0.1782 - val_dice_coef: 0.8990\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "14s - loss: 0.1722 - dice_coef: 0.8923 - val_loss: 0.1830 - val_dice_coef: 0.9074\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "15s - loss: 0.1739 - dice_coef: 0.8954 - val_loss: 0.1809 - val_dice_coef: 0.9022\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "14s - loss: 0.1721 - dice_coef: 0.8981 - val_loss: 0.1804 - val_dice_coef: 0.8859\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "15s - loss: 0.1719 - dice_coef: 0.8974 - val_loss: 0.1779 - val_dice_coef: 0.8865\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "15s - loss: 0.1741 - dice_coef: 0.8929 - val_loss: 0.1775 - val_dice_coef: 0.8886\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "14s - loss: 0.1761 - dice_coef: 0.8911 - val_loss: 0.1859 - val_dice_coef: 0.9089\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "15s - loss: 0.1731 - dice_coef: 0.8947 - val_loss: 0.1775 - val_dice_coef: 0.8946\n"
     ]
    }
   ],
   "source": [
    "model_epi.compile(optimizer=Adam(lr=1e-5),loss='categorical_crossentropy',metrics=[dice_coef])\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/epi_models/weightsNoDrop.hdf5',verbose=1,save_best_only=True)\n",
    "\n",
    "hist_epi = model_epi.fit_generator(train_outer_generator,steps_per_epoch=train_steps,epochs=epochs,verbose=2,callbacks=[checkpointer],\n",
    "                                 validation_data=(validation_images,validation_outer_masks),validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmdW5UzAzszp3CmZmVvcPFOSXGk0WK9sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f62b5e63fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlFJKVdJQUEopVUlDQSmlVKX/D0W4EIMkdjQ1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6324b4b208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_plots(hist_epi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
