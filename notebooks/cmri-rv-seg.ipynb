{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Model for RV Segmentation\n",
    "\n",
    "## Training U-Net CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os, re, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from src import data,unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 243 total training images.\n",
      "There are 243 total inner masks.\n",
      "There are 243 total outer masks.\n"
     ]
    }
   ],
   "source": [
    "from keras import utils\n",
    "\n",
    "train_dir = \"/home/ubuntu/training/TrainingSet\"\n",
    "#train_dir = \"/Users/aksharkumar/Documents/mlndCapstone/trainingdata/TrainingSet\"\n",
    "\n",
    "images=[]\n",
    "inner_masks=[]\n",
    "outer_masks = []\n",
    "\n",
    "patient_directories = sorted(glob.glob(os.path.join(train_dir, \"patient*\")))\n",
    "\n",
    "for patient_dir in patient_directories:\n",
    "    imgdata = data.ImageData(patient_dir)\n",
    "    images += imgdata.labeled_images\n",
    "    inner_masks += imgdata.endo_masks.values()\n",
    "    outer_masks += imgdata.epi_masks.values()\n",
    "\n",
    "images = np.asarray(images)[:,:,:,None].astype('float64')\n",
    "i_masks = np.asarray(inner_masks)\n",
    "o_masks = np.asarray(outer_masks)\n",
    "\n",
    "dims = i_masks.shape\n",
    "classes = len(set(i_masks[0].flatten()))\n",
    "new_shape = dims + (classes,)\n",
    "i_masks = utils.to_categorical(i_masks).reshape(new_shape)\n",
    "o_masks = utils.to_categorical(o_masks).reshape(new_shape)\n",
    "\n",
    "print(\"There are %d total training images.\" % len(images))\n",
    "print(\"There are %d total inner masks.\" % len(inner_masks))\n",
    "print(\"There are %d total outer masks.\" % len(outer_masks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 216, 256, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 216, 256, 32)  320         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 216, 256, 32)  0           conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 216, 256, 32)  0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 216, 256, 32)  9248        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 216, 256, 32)  0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 216, 256, 32)  0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 108, 128, 32)  0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 108, 128, 64)  18496       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 108, 128, 64)  0           conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 108, 128, 64)  0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 108, 128, 64)  36928       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 108, 128, 64)  0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 108, 128, 64)  0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 54, 64, 64)    0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 54, 64, 128)   73856       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 54, 64, 128)   0           conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 54, 64, 128)   0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 54, 64, 128)   147584      dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 54, 64, 128)   0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 54, 64, 128)   0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 27, 32, 128)   0           dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 27, 32, 256)   295168      max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 27, 32, 256)   0           conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 27, 32, 256)   0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 27, 32, 256)   590080      dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 27, 32, 256)   0           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 27, 32, 256)   0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTransp (None, 54, 64, 128)   131200      dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 54, 64, 256)   0           conv2d_transpose_1[0][0]         \n",
      "                                                                   conv2d_transpose_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 54, 64, 128)   295040      concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 54, 64, 128)   0           conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 54, 64, 128)   0           activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 54, 64, 128)   147584      dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 54, 64, 128)   0           conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 54, 64, 128)   0           activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTransp (None, 108, 128, 64)  32832       dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 108, 128, 128) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                   conv2d_transpose_2[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 108, 128, 64)  73792       concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 108, 128, 64)  0           conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 108, 128, 64)  0           activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 108, 128, 64)  36928       dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 108, 128, 64)  0           conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 108, 128, 64)  0           activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTransp (None, 216, 256, 32)  8224        dropout_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 216, 256, 64)  0           conv2d_transpose_3[0][0]         \n",
      "                                                                   conv2d_transpose_3[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 216, 256, 32)  18464       concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 216, 256, 32)  0           conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 216, 256, 32)  0           activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 216, 256, 32)  9248        dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 216, 256, 32)  0           conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 216, 256, 32)  0           activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 216, 256, 2)   66          dropout_14[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1,925,058\n",
      "Trainable params: 1,925,058\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "height,width,_ = images[0].shape\n",
    "dropout = 0\n",
    "\n",
    "unet_conv = unet.UNet()\n",
    "\n",
    "model = unet_conv.get_unet(height=height,width=width,channels=1,features=32,steps=3,dropout=dropout,padding='same')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "        flat_y_true = K.flatten(y_true)\n",
    "        flat_y_preds = K.flatten(y_pred)\n",
    "        intersection = K.sum(flat_y_true*flat_y_preds)\n",
    "        return (2. * intersection + 1.) / (K.sum(flat_y_true)+K.sum(flat_y_preds))\n",
    "\n",
    "def show_plots(history):    \n",
    "    plt.plot(history.history['dice_coef'])\n",
    "    plt.plot(history.history['val_dice_coef'])\n",
    "    plt.title('model dice')\n",
    "    plt.ylabel('dice')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-5),loss='categorical_crossentropy',metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/preprocessing/image.py:653: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (194, 216, 256, 2) (2 channels).\n",
      "/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/preprocessing/image.py:787: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (194, 216, 256, 2) (2 channels).\n"
     ]
    }
   ],
   "source": [
    "#TODO: 1. split data into training and validation set\n",
    "#      2. Augment the data\n",
    "#      3. Train model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "seed = 0\n",
    "\n",
    "validation_split=0.2\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 20\n",
    "\n",
    "\n",
    "split_index = int((1 - validation_split) * len(images))\n",
    "\n",
    "train_steps = ceil(split_index / batch_size)\n",
    "val_steps = ceil((len(images)-split_index )/batch_size)\n",
    "\n",
    "train_images = images[:split_index]\n",
    "train_inner_masks = i_masks[:split_index]\n",
    "\n",
    "validation_images = images[split_index:]\n",
    "validation_inner_masks = i_masks[split_index:]\n",
    "\n",
    "\n",
    "data_gen_args = dict(rotation_range=180,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     shear_range=0.1,\n",
    "                     zoom_range=0.01,\n",
    "                     fill_mode='nearest')\n",
    "\n",
    "train_images_datagen = ImageDataGenerator(**data_gen_args)\n",
    "train_masks_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "\n",
    "seed = 1\n",
    "#height,width,channels = train_images[0].shape\n",
    "#print(train_images[0].shape)\n",
    "#print(train_inner_masks[0].shape)\n",
    "train_images_datagen.fit(train_images,augment=True,seed=seed)\n",
    "train_masks_datagen.fit(train_inner_masks,augment=True,seed=seed)\n",
    "\n",
    "train_images_generator = train_images_datagen.flow(train_images, y=None, seed=seed)\n",
    "train_masks_generator = train_images_datagen.flow(train_inner_masks, y=None, seed=seed)\n",
    "\n",
    "\n",
    "train_generator = zip(train_images_generator, train_masks_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.68469, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "16s - loss: 0.6932 - dice_coef: 0.5002 - val_loss: 0.6847 - val_dice_coef: 0.5044\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.68469 to 0.66212, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.6742 - dice_coef: 0.5100 - val_loss: 0.6621 - val_dice_coef: 0.5164\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.66212 to 0.60857, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.6352 - dice_coef: 0.5318 - val_loss: 0.6086 - val_dice_coef: 0.5473\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.60857 to 0.50468, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.5578 - dice_coef: 0.5821 - val_loss: 0.5047 - val_dice_coef: 0.6186\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.50468 to 0.38493, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.4404 - dice_coef: 0.6817 - val_loss: 0.3849 - val_dice_coef: 0.7314\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.38493 to 0.34142, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3710 - dice_coef: 0.7855 - val_loss: 0.3414 - val_dice_coef: 0.8085\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.34142 to 0.33104, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.3408 - dice_coef: 0.8288 - val_loss: 0.3310 - val_dice_coef: 0.8087\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "15s - loss: 0.3652 - dice_coef: 0.8067 - val_loss: 0.3325 - val_dice_coef: 0.7844\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.33104 to 0.32637, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3506 - dice_coef: 0.7883 - val_loss: 0.3264 - val_dice_coef: 0.7856\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.32637 to 0.31145, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.3371 - dice_coef: 0.8071 - val_loss: 0.3115 - val_dice_coef: 0.8050\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.31145 to 0.30334, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3354 - dice_coef: 0.8117 - val_loss: 0.3033 - val_dice_coef: 0.8080\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.30334 to 0.29181, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.3133 - dice_coef: 0.8210 - val_loss: 0.2918 - val_dice_coef: 0.8188\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.29181 to 0.27853, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2895 - dice_coef: 0.8365 - val_loss: 0.2785 - val_dice_coef: 0.8356\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.27853 to 0.27282, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2951 - dice_coef: 0.8343 - val_loss: 0.2728 - val_dice_coef: 0.8288\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.27282 to 0.25919, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2774 - dice_coef: 0.8470 - val_loss: 0.2592 - val_dice_coef: 0.8481\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.25919 to 0.25031, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2643 - dice_coef: 0.8510 - val_loss: 0.2503 - val_dice_coef: 0.8529\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.25031 to 0.24205, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2496 - dice_coef: 0.8620 - val_loss: 0.2420 - val_dice_coef: 0.8588\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.24205 to 0.23489, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2554 - dice_coef: 0.8556 - val_loss: 0.2349 - val_dice_coef: 0.8666\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.23489 to 0.23049, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2483 - dice_coef: 0.8597 - val_loss: 0.2305 - val_dice_coef: 0.8632\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.23049 to 0.22440, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2367 - dice_coef: 0.8665 - val_loss: 0.2244 - val_dice_coef: 0.8749\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.22440 to 0.22171, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2346 - dice_coef: 0.8633 - val_loss: 0.2217 - val_dice_coef: 0.8652\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.22171 to 0.21596, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2263 - dice_coef: 0.8740 - val_loss: 0.2160 - val_dice_coef: 0.8888\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.21596 to 0.21569, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2282 - dice_coef: 0.8711 - val_loss: 0.2157 - val_dice_coef: 0.8656\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.21569 to 0.20876, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2197 - dice_coef: 0.8739 - val_loss: 0.2088 - val_dice_coef: 0.8910\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "15s - loss: 0.2466 - dice_coef: 0.8634 - val_loss: 0.2211 - val_dice_coef: 0.8483\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.20876 to 0.20229, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2320 - dice_coef: 0.8635 - val_loss: 0.2023 - val_dice_coef: 0.8912\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.20229 to 0.20108, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2027 - dice_coef: 0.8819 - val_loss: 0.2011 - val_dice_coef: 0.8868\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.20108 to 0.19882, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1983 - dice_coef: 0.8901 - val_loss: 0.1988 - val_dice_coef: 0.8901\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.19882 to 0.19658, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2006 - dice_coef: 0.8860 - val_loss: 0.1966 - val_dice_coef: 0.8986\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "15s - loss: 0.2049 - dice_coef: 0.8833 - val_loss: 0.1968 - val_dice_coef: 0.8834\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.19658 to 0.19368, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1973 - dice_coef: 0.8857 - val_loss: 0.1937 - val_dice_coef: 0.9005\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19368 to 0.19221, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1975 - dice_coef: 0.8887 - val_loss: 0.1922 - val_dice_coef: 0.8906\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "14s - loss: 0.2059 - dice_coef: 0.8814 - val_loss: 0.1924 - val_dice_coef: 0.8897\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19221 to 0.19016, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1977 - dice_coef: 0.8857 - val_loss: 0.1902 - val_dice_coef: 0.9007\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.19016 to 0.18964, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1898 - dice_coef: 0.8957 - val_loss: 0.1896 - val_dice_coef: 0.8897\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18964 to 0.18637, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1962 - dice_coef: 0.8836 - val_loss: 0.1864 - val_dice_coef: 0.9087\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "15s - loss: 0.1955 - dice_coef: 0.8858 - val_loss: 0.1893 - val_dice_coef: 0.8869\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "14s - loss: 0.1896 - dice_coef: 0.8960 - val_loss: 0.1882 - val_dice_coef: 0.8880\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18637 to 0.18534, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1829 - dice_coef: 0.8899 - val_loss: 0.1853 - val_dice_coef: 0.9114\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.18534 to 0.18466, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1888 - dice_coef: 0.8913 - val_loss: 0.1847 - val_dice_coef: 0.8938\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "15s - loss: 0.2180 - dice_coef: 0.8825 - val_loss: 0.1931 - val_dice_coef: 0.8721\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.18466 to 0.17960, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1969 - dice_coef: 0.8840 - val_loss: 0.1796 - val_dice_coef: 0.8972\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00042: val_loss did not improve\n",
      "15s - loss: 0.1860 - dice_coef: 0.8840 - val_loss: 0.1827 - val_dice_coef: 0.9152\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "15s - loss: 0.1805 - dice_coef: 0.9048 - val_loss: 0.1836 - val_dice_coef: 0.8928\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "14s - loss: 0.1975 - dice_coef: 0.8856 - val_loss: 0.1826 - val_dice_coef: 0.8928\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.17960 to 0.17924, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1744 - dice_coef: 0.8988 - val_loss: 0.1792 - val_dice_coef: 0.9130\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "14s - loss: 0.1852 - dice_coef: 0.8885 - val_loss: 0.1811 - val_dice_coef: 0.8942\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.17924 to 0.17808, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1783 - dice_coef: 0.9024 - val_loss: 0.1781 - val_dice_coef: 0.9135\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.17808 to 0.17637, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1798 - dice_coef: 0.8902 - val_loss: 0.1764 - val_dice_coef: 0.9063\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "15s - loss: 0.1769 - dice_coef: 0.9048 - val_loss: 0.1777 - val_dice_coef: 0.8967\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.17637 to 0.17384, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1771 - dice_coef: 0.8947 - val_loss: 0.1738 - val_dice_coef: 0.9117\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.17384 to 0.17373, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1658 - dice_coef: 0.9045 - val_loss: 0.1737 - val_dice_coef: 0.9047\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.17373 to 0.17327, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1799 - dice_coef: 0.8981 - val_loss: 0.1733 - val_dice_coef: 0.9029\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "14s - loss: 0.2027 - dice_coef: 0.8985 - val_loss: 0.1912 - val_dice_coef: 0.8691\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.17327 to 0.16975, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2029 - dice_coef: 0.8531 - val_loss: 0.1697 - val_dice_coef: 0.9024\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.16975 to 0.16951, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1845 - dice_coef: 0.9041 - val_loss: 0.1695 - val_dice_coef: 0.9032\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "15s - loss: 0.1665 - dice_coef: 0.9019 - val_loss: 0.1696 - val_dice_coef: 0.9163\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "15s - loss: 0.1846 - dice_coef: 0.9024 - val_loss: 0.1703 - val_dice_coef: 0.9053\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.16951 to 0.16931, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1736 - dice_coef: 0.8970 - val_loss: 0.1693 - val_dice_coef: 0.9102\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.16931 to 0.16915, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1717 - dice_coef: 0.9037 - val_loss: 0.1692 - val_dice_coef: 0.9062\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.16915 to 0.16680, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1760 - dice_coef: 0.8939 - val_loss: 0.1668 - val_dice_coef: 0.9131\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "15s - loss: 0.1672 - dice_coef: 0.9061 - val_loss: 0.1695 - val_dice_coef: 0.9038\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "14s - loss: 0.1626 - dice_coef: 0.9085 - val_loss: 0.1674 - val_dice_coef: 0.9135\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "15s - loss: 0.1767 - dice_coef: 0.8981 - val_loss: 0.1677 - val_dice_coef: 0.9005\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.16680 to 0.16298, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1653 - dice_coef: 0.9060 - val_loss: 0.1630 - val_dice_coef: 0.9105\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "14s - loss: 0.1728 - dice_coef: 0.9033 - val_loss: 0.1631 - val_dice_coef: 0.9038\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.16298 to 0.16193, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1649 - dice_coef: 0.9044 - val_loss: 0.1619 - val_dice_coef: 0.9078\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "14s - loss: 0.1875 - dice_coef: 0.8893 - val_loss: 0.1648 - val_dice_coef: 0.9043\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.16193 to 0.16027, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1547 - dice_coef: 0.9121 - val_loss: 0.1603 - val_dice_coef: 0.9162\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "14s - loss: 0.1727 - dice_coef: 0.8947 - val_loss: 0.1605 - val_dice_coef: 0.9145\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "15s - loss: 0.1663 - dice_coef: 0.9068 - val_loss: 0.1603 - val_dice_coef: 0.9153\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "15s - loss: 0.1765 - dice_coef: 0.8950 - val_loss: 0.1649 - val_dice_coef: 0.8992\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "14s - loss: 0.1609 - dice_coef: 0.9121 - val_loss: 0.1640 - val_dice_coef: 0.9008\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.16027 to 0.15832, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1680 - dice_coef: 0.9006 - val_loss: 0.1583 - val_dice_coef: 0.9145\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.15832 to 0.15827, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1584 - dice_coef: 0.9096 - val_loss: 0.1583 - val_dice_coef: 0.9062\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "15s - loss: 0.1776 - dice_coef: 0.8956 - val_loss: 0.1747 - val_dice_coef: 0.8804\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "14s - loss: 0.1833 - dice_coef: 0.9023 - val_loss: 0.1585 - val_dice_coef: 0.9096\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.15827 to 0.15446, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1712 - dice_coef: 0.8821 - val_loss: 0.1545 - val_dice_coef: 0.9159\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "15s - loss: 0.1606 - dice_coef: 0.9179 - val_loss: 0.1588 - val_dice_coef: 0.9029\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "14s - loss: 0.1683 - dice_coef: 0.8981 - val_loss: 0.1563 - val_dice_coef: 0.9167\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "15s - loss: 0.1580 - dice_coef: 0.9135 - val_loss: 0.1560 - val_dice_coef: 0.9160\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "14s - loss: 0.2035 - dice_coef: 0.8773 - val_loss: 0.1669 - val_dice_coef: 0.8866\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.15446 to 0.15323, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1581 - dice_coef: 0.9158 - val_loss: 0.1532 - val_dice_coef: 0.9191\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "14s - loss: 0.1611 - dice_coef: 0.8983 - val_loss: 0.1577 - val_dice_coef: 0.9041\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "15s - loss: 0.1564 - dice_coef: 0.9158 - val_loss: 0.1568 - val_dice_coef: 0.9250\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "15s - loss: 0.1565 - dice_coef: 0.9095 - val_loss: 0.1580 - val_dice_coef: 0.9036\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "14s - loss: 0.1543 - dice_coef: 0.9119 - val_loss: 0.1558 - val_dice_coef: 0.9243\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "15s - loss: 0.1550 - dice_coef: 0.9126 - val_loss: 0.1573 - val_dice_coef: 0.9041\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "14s - loss: 0.1564 - dice_coef: 0.9090 - val_loss: 0.1548 - val_dice_coef: 0.9247\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "15s - loss: 0.1557 - dice_coef: 0.9104 - val_loss: 0.1536 - val_dice_coef: 0.9133\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "14s - loss: 0.1535 - dice_coef: 0.9140 - val_loss: 0.1535 - val_dice_coef: 0.9123\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "15s - loss: 0.1601 - dice_coef: 0.9068 - val_loss: 0.1538 - val_dice_coef: 0.9106\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.15323 to 0.15285, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1468 - dice_coef: 0.9168 - val_loss: 0.1529 - val_dice_coef: 0.9136\n",
      "Epoch 94/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00093: val_loss did not improve\n",
      "14s - loss: 0.1642 - dice_coef: 0.9024 - val_loss: 0.1536 - val_dice_coef: 0.9093\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.15285 to 0.15164, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1548 - dice_coef: 0.9112 - val_loss: 0.1516 - val_dice_coef: 0.9135\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.15164 to 0.15153, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1475 - dice_coef: 0.9140 - val_loss: 0.1515 - val_dice_coef: 0.9138\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.15153 to 0.15118, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1499 - dice_coef: 0.9162 - val_loss: 0.1512 - val_dice_coef: 0.9158\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "14s - loss: 0.1463 - dice_coef: 0.9135 - val_loss: 0.1517 - val_dice_coef: 0.9157\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "15s - loss: 0.1630 - dice_coef: 0.9119 - val_loss: 0.1519 - val_dice_coef: 0.9143\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.15118 to 0.15090, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1449 - dice_coef: 0.9188 - val_loss: 0.1509 - val_dice_coef: 0.9148\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "14s - loss: 0.1507 - dice_coef: 0.9094 - val_loss: 0.1517 - val_dice_coef: 0.9262\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.15090 to 0.15085, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1516 - dice_coef: 0.9118 - val_loss: 0.1509 - val_dice_coef: 0.9130\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.15085 to 0.15054, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1463 - dice_coef: 0.9152 - val_loss: 0.1505 - val_dice_coef: 0.9153\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.15054 to 0.15046, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1455 - dice_coef: 0.9201 - val_loss: 0.1505 - val_dice_coef: 0.9191\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "14s - loss: 0.1469 - dice_coef: 0.9091 - val_loss: 0.1528 - val_dice_coef: 0.9277\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "15s - loss: 0.1498 - dice_coef: 0.9137 - val_loss: 0.1517 - val_dice_coef: 0.9113\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "15s - loss: 0.1485 - dice_coef: 0.9129 - val_loss: 0.1512 - val_dice_coef: 0.9146\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "14s - loss: 0.1521 - dice_coef: 0.9135 - val_loss: 0.1516 - val_dice_coef: 0.9253\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "15s - loss: 0.1594 - dice_coef: 0.9086 - val_loss: 0.1509 - val_dice_coef: 0.9127\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "14s - loss: 0.1494 - dice_coef: 0.9150 - val_loss: 0.1527 - val_dice_coef: 0.9079\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.15046 to 0.15018, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1440 - dice_coef: 0.9171 - val_loss: 0.1502 - val_dice_coef: 0.9209\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.15018 to 0.15009, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1458 - dice_coef: 0.9131 - val_loss: 0.1501 - val_dice_coef: 0.9251\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "15s - loss: 0.1469 - dice_coef: 0.9151 - val_loss: 0.1508 - val_dice_coef: 0.9116\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.15009 to 0.14853, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1565 - dice_coef: 0.9111 - val_loss: 0.1485 - val_dice_coef: 0.9176\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "14s - loss: 0.1443 - dice_coef: 0.9152 - val_loss: 0.1494 - val_dice_coef: 0.9301\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "15s - loss: 0.1592 - dice_coef: 0.9023 - val_loss: 0.1556 - val_dice_coef: 0.8984\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "14s - loss: 0.1540 - dice_coef: 0.9178 - val_loss: 0.1538 - val_dice_coef: 0.9032\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "15s - loss: 0.1520 - dice_coef: 0.9003 - val_loss: 0.1531 - val_dice_coef: 0.9288\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "14s - loss: 0.1487 - dice_coef: 0.9183 - val_loss: 0.1527 - val_dice_coef: 0.9064\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "15s - loss: 0.1473 - dice_coef: 0.9166 - val_loss: 0.1495 - val_dice_coef: 0.9154\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "15s - loss: 0.1482 - dice_coef: 0.9138 - val_loss: 0.1488 - val_dice_coef: 0.9203\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "14s - loss: 0.1506 - dice_coef: 0.9157 - val_loss: 0.1604 - val_dice_coef: 0.8925\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "15s - loss: 0.1509 - dice_coef: 0.9088 - val_loss: 0.1502 - val_dice_coef: 0.9267\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "14s - loss: 0.1390 - dice_coef: 0.9171 - val_loss: 0.1491 - val_dice_coef: 0.9185\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "15s - loss: 0.1489 - dice_coef: 0.9143 - val_loss: 0.1510 - val_dice_coef: 0.9103\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.14853 to 0.14826, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1534 - dice_coef: 0.9109 - val_loss: 0.1483 - val_dice_coef: 0.9217\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "15s - loss: 0.1394 - dice_coef: 0.9196 - val_loss: 0.1495 - val_dice_coef: 0.9268\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "15s - loss: 0.1465 - dice_coef: 0.9147 - val_loss: 0.1485 - val_dice_coef: 0.9188\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "14s - loss: 0.1446 - dice_coef: 0.9187 - val_loss: 0.1487 - val_dice_coef: 0.9268\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.14826 to 0.14699, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1414 - dice_coef: 0.9187 - val_loss: 0.1470 - val_dice_coef: 0.9244\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "14s - loss: 0.1450 - dice_coef: 0.9150 - val_loss: 0.1470 - val_dice_coef: 0.9170\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "15s - loss: 0.1359 - dice_coef: 0.9212 - val_loss: 0.1474 - val_dice_coef: 0.9240\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "14s - loss: 0.1569 - dice_coef: 0.9009 - val_loss: 0.1489 - val_dice_coef: 0.9273\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "15s - loss: 0.1603 - dice_coef: 0.9150 - val_loss: 0.1531 - val_dice_coef: 0.9016\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.14699 to 0.14664, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1450 - dice_coef: 0.9190 - val_loss: 0.1466 - val_dice_coef: 0.9191\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.14664 to 0.14544, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1507 - dice_coef: 0.9090 - val_loss: 0.1454 - val_dice_coef: 0.9237\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "15s - loss: 0.1456 - dice_coef: 0.9165 - val_loss: 0.1460 - val_dice_coef: 0.9150\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "14s - loss: 0.1341 - dice_coef: 0.9224 - val_loss: 0.1466 - val_dice_coef: 0.9143\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "15s - loss: 0.1469 - dice_coef: 0.9121 - val_loss: 0.1467 - val_dice_coef: 0.9161\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "14s - loss: 0.1423 - dice_coef: 0.9183 - val_loss: 0.1461 - val_dice_coef: 0.9178\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "15s - loss: 0.1428 - dice_coef: 0.9173 - val_loss: 0.1463 - val_dice_coef: 0.9280\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "15s - loss: 0.1456 - dice_coef: 0.9143 - val_loss: 0.1467 - val_dice_coef: 0.9272\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "14s - loss: 0.1448 - dice_coef: 0.9137 - val_loss: 0.1463 - val_dice_coef: 0.9246\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "15s - loss: 0.1496 - dice_coef: 0.9150 - val_loss: 0.1487 - val_dice_coef: 0.9059\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.14544 to 0.14506, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1437 - dice_coef: 0.9166 - val_loss: 0.1451 - val_dice_coef: 0.9121\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.14506 to 0.14491, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1447 - dice_coef: 0.9135 - val_loss: 0.1449 - val_dice_coef: 0.9183\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00146: val_loss did not improve\n",
      "14s - loss: 0.1572 - dice_coef: 0.9136 - val_loss: 0.1458 - val_dice_coef: 0.9148\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.14491 to 0.14375, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1475 - dice_coef: 0.9135 - val_loss: 0.1437 - val_dice_coef: 0.9177\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "15s - loss: 0.1424 - dice_coef: 0.9136 - val_loss: 0.1458 - val_dice_coef: 0.9252\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "14s - loss: 0.1360 - dice_coef: 0.9217 - val_loss: 0.1478 - val_dice_coef: 0.9099\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "15s - loss: 0.1444 - dice_coef: 0.9175 - val_loss: 0.1448 - val_dice_coef: 0.9204\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "14s - loss: 0.1403 - dice_coef: 0.9158 - val_loss: 0.1454 - val_dice_coef: 0.9231\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "15s - loss: 0.1447 - dice_coef: 0.9174 - val_loss: 0.1462 - val_dice_coef: 0.9109\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "14s - loss: 0.1473 - dice_coef: 0.9113 - val_loss: 0.1455 - val_dice_coef: 0.9183\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "15s - loss: 0.1533 - dice_coef: 0.9089 - val_loss: 0.1488 - val_dice_coef: 0.9077\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "15s - loss: 0.1465 - dice_coef: 0.9163 - val_loss: 0.1447 - val_dice_coef: 0.9183\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "14s - loss: 0.1327 - dice_coef: 0.9208 - val_loss: 0.1444 - val_dice_coef: 0.9239\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "15s - loss: 0.1401 - dice_coef: 0.9180 - val_loss: 0.1448 - val_dice_coef: 0.9183\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "14s - loss: 0.1304 - dice_coef: 0.9269 - val_loss: 0.1446 - val_dice_coef: 0.9165\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "15s - loss: 0.1471 - dice_coef: 0.9151 - val_loss: 0.1446 - val_dice_coef: 0.9142\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "14s - loss: 0.1351 - dice_coef: 0.9197 - val_loss: 0.1448 - val_dice_coef: 0.9194\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "15s - loss: 0.1357 - dice_coef: 0.9224 - val_loss: 0.1443 - val_dice_coef: 0.9237\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.14375 to 0.14302, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1324 - dice_coef: 0.9226 - val_loss: 0.1430 - val_dice_coef: 0.9196\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "14s - loss: 0.1305 - dice_coef: 0.9232 - val_loss: 0.1447 - val_dice_coef: 0.9296\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "15s - loss: 0.1523 - dice_coef: 0.9089 - val_loss: 0.1433 - val_dice_coef: 0.9220\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "14s - loss: 0.1516 - dice_coef: 0.9155 - val_loss: 0.1516 - val_dice_coef: 0.8994\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "15s - loss: 0.1441 - dice_coef: 0.9135 - val_loss: 0.1443 - val_dice_coef: 0.9114\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "14s - loss: 0.1413 - dice_coef: 0.9174 - val_loss: 0.1434 - val_dice_coef: 0.9237\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "15s - loss: 0.1365 - dice_coef: 0.9200 - val_loss: 0.1437 - val_dice_coef: 0.9211\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.14302 to 0.14296, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1430 - dice_coef: 0.9156 - val_loss: 0.1430 - val_dice_coef: 0.9212\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.14296 to 0.14269, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1355 - dice_coef: 0.9216 - val_loss: 0.1427 - val_dice_coef: 0.9187\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "15s - loss: 0.1431 - dice_coef: 0.9177 - val_loss: 0.1431 - val_dice_coef: 0.9170\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.14269 to 0.14238, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1338 - dice_coef: 0.9199 - val_loss: 0.1424 - val_dice_coef: 0.9214\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.14238 to 0.14177, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1461 - dice_coef: 0.9165 - val_loss: 0.1418 - val_dice_coef: 0.9210\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "14s - loss: 0.1347 - dice_coef: 0.9228 - val_loss: 0.1426 - val_dice_coef: 0.9151\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "15s - loss: 0.1436 - dice_coef: 0.9150 - val_loss: 0.1458 - val_dice_coef: 0.9056\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "15s - loss: 0.1365 - dice_coef: 0.9186 - val_loss: 0.1465 - val_dice_coef: 0.9079\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "14s - loss: 0.1369 - dice_coef: 0.9212 - val_loss: 0.1432 - val_dice_coef: 0.9171\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.14177 to 0.14058, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1370 - dice_coef: 0.9167 - val_loss: 0.1406 - val_dice_coef: 0.9267\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "14s - loss: 0.1372 - dice_coef: 0.9205 - val_loss: 0.1409 - val_dice_coef: 0.9170\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "15s - loss: 0.1500 - dice_coef: 0.9124 - val_loss: 0.1423 - val_dice_coef: 0.9115\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "14s - loss: 0.1332 - dice_coef: 0.9199 - val_loss: 0.1423 - val_dice_coef: 0.9165\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "15s - loss: 0.1319 - dice_coef: 0.9251 - val_loss: 0.1451 - val_dice_coef: 0.9302\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "15s - loss: 0.1397 - dice_coef: 0.9167 - val_loss: 0.1425 - val_dice_coef: 0.9294\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.14058 to 0.14024, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1460 - dice_coef: 0.9152 - val_loss: 0.1402 - val_dice_coef: 0.9294\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "15s - loss: 0.1440 - dice_coef: 0.9151 - val_loss: 0.1419 - val_dice_coef: 0.9199\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "14s - loss: 0.1379 - dice_coef: 0.9194 - val_loss: 0.1415 - val_dice_coef: 0.9194\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "15s - loss: 0.1420 - dice_coef: 0.9213 - val_loss: 0.1410 - val_dice_coef: 0.9185\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.14024 to 0.13988, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1561 - dice_coef: 0.9083 - val_loss: 0.1399 - val_dice_coef: 0.9237\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "15s - loss: 0.1407 - dice_coef: 0.9156 - val_loss: 0.1415 - val_dice_coef: 0.9264\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "15s - loss: 0.1393 - dice_coef: 0.9160 - val_loss: 0.1419 - val_dice_coef: 0.9249\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "14s - loss: 0.1350 - dice_coef: 0.9212 - val_loss: 0.1432 - val_dice_coef: 0.9298\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "15s - loss: 0.1342 - dice_coef: 0.9231 - val_loss: 0.1416 - val_dice_coef: 0.9234\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "14s - loss: 0.1359 - dice_coef: 0.9174 - val_loss: 0.1493 - val_dice_coef: 0.9375\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.13988 to 0.13960, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1375 - dice_coef: 0.9193 - val_loss: 0.1396 - val_dice_coef: 0.9240\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "14s - loss: 0.1349 - dice_coef: 0.9229 - val_loss: 0.1442 - val_dice_coef: 0.9129\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "15s - loss: 0.1396 - dice_coef: 0.9204 - val_loss: 0.1397 - val_dice_coef: 0.9225\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss improved from 0.13960 to 0.13930, saving model to saved_models/endo_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1348 - dice_coef: 0.9191 - val_loss: 0.1393 - val_dice_coef: 0.9244\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "14s - loss: 0.1426 - dice_coef: 0.9144 - val_loss: 0.1437 - val_dice_coef: 0.9333\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "15s - loss: 0.1307 - dice_coef: 0.9226 - val_loss: 0.1411 - val_dice_coef: 0.9281\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2394dfb9956b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m hist = model.fit_generator(train_generator,steps_per_epoch=train_steps,epochs=epochs,verbose=2,callbacks=[checkpointer],\n\u001b[1;32m      4\u001b[0m                    validation_data=(validation_images,validation_inner_masks),validation_steps=val_steps)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mshow_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-d54d48a88f16>\u001b[0m in \u001b[0;36mshow_plots\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dice_coef'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_dice_coef'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model dice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/endo_models/weightsNoDrop.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "hist = model.fit_generator(train_generator,steps_per_epoch=train_steps,epochs=epochs,verbose=2,callbacks=[checkpointer],\n",
    "                   validation_data=(validation_images,validation_inner_masks),validation_steps=val_steps)\n",
    "#show_plots(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3Xd8VfX5wPHPc3f2IgMIJGHvGRAE\nBTdgVZw46h4dWkcnttaqPzvVVuuq2FJ3UXHhQFwoOFkCsjckhJEEsnP39/fHuQkJBAiSEOA+79cr\nr9x7xj1PTpLznO88YoxBKaWUArC1dQBKKaWOHpoUlFJK1dOkoJRSqp4mBaWUUvU0KSillKqnSUEp\npVQ9TQpKNYOIPCMi9zdz200icnozt71GRD5v8L5KRLp83ziVOlyOtg5AKbWHMSa+rWNQ0U1LCkop\npeppUlDHjUi1za9EZKmIVIvIf0QkU0RmikiliHwkIikNtj9XRJaLSJmIfCoivRusGywiiyL7vQx4\n9jrWD0RkcWTfL0VkQDNjTBORGSJSISLzgK57rTci0i3yOkZEHhKRzSJSLiKfi0hMZN2IyHHLRGSJ\niIz93idOqQY0KajjzYXAGUAP4BxgJvBbIB3r7/1WABHpAfwPuD2y7j3gbRFxiYgLeBN4HkgFXo18\nLpF9BwNTgR8BacBTwAwRcTcjvscBL9AeuC7ytT8PAkOBEyNx/BoIi0hH4F3g/sjyXwKviUh6M46v\n1AFpUlDHm0eNMTuMMVuBucA3xphvjTFe4A1gcGS7ScC7xpgPjTEBrAtwDNYFeATgBB42xgSMMdOB\n+Q2OcRPwlDHmG2NMyBjzLOCL7LdfImLHSi53G2OqjTHLgGf3s60NK2HcZozZGjnOl8YYH/BD4D1j\nzHvGmLAx5kNgATDhUE+WUnvTpKCONzsavK5t4n1dQ24HYHPdCmNMGCgAOkbWbTWNZ4vc3OB1DvCL\nSNVNmYiUAZ0i+x1IOlbnjoL9fG5D7bCqrNY3sS4HuHiv44/GKn0odVi095GKVkVA/7o3IiJYF/at\ngAE6iog0SAyd2XOBLgD+aIz54yEesxgIRo6zqsHnNqUEq5qpK7Bkr3UFwPPGmBsP8fhKHZSWFFS0\negU4W0ROExEn8AusKqAvga+wLt63iohTRC4AhjfY92ngxyJygljiRORsEUk40AGNMSHgdeAeEYkV\nkT7A1fvZNozVbvF3EekgInYRGRlpt3gBOEdEzoos94jIWBHJPqwzohSaFFSUMsasxqqbfxTrrvwc\n4BxjjN8Y4wcuAK4BdmG1P7zeYN8FwI3AY8BuYF1k2+a4BasKazvwDPDfA2z7S+A7rPaMXcBfAZsx\npgA4D6sBvRir5PAr9P9ZtQDRh+wopZSqo3cWSiml6mlSUEopVU+TglJKqXqaFJRSStU75sYptGvX\nzuTm5rZ1GEopdUxZuHBhiTHmoFOhHHNJITc3lwULFrR1GEopdUwRkf2Nnm9Eq4+UUkrV06SglFKq\nniYFpZRS9Y65NoWmBAIBCgsL8Xq9bR3KccHj8ZCdnY3T6WzrUJRSR9hxkRQKCwtJSEggNzcXa7JL\n9X0ZYygtLaWwsJC8vLy2DkcpdYQdF9VHXq+XtLQ0TQgtQERIS0vTUpdSUeq4SAqAJoQWpOdSqeh1\n3CQFpZQ6JgV9sPAZCAXbOhJAk0KLKCsr44knnjjk/SZMmEBZWVkrRKSUOmaseAvevg3WzGzrSABN\nCi1if0khGDxw5n/vvfdITk5urbCUUseCzV9Y3zd93vT6TZ/DgqlHLJzjovdRW5s8eTLr169n0KBB\nOJ1OPB4PKSkprFq1ijVr1jBx4kQKCgrwer3cdttt3HTTTcCeKTuqqqoYP348o0eP5ssvv6Rjx468\n9dZbxMTEtPFPpo4K1SUQkwo2vYc7Ku3eBDEp4Ek6tP3CYet3uvlL631TScEYeO/XsHM5pORC11MP\nN9qDOu6Swr1vL2dFUUWLfmafDon84Zy++13/l7/8hWXLlrF48WI+/fRTzj77bJYtW1bfpXPq1Kmk\npqZSW1vLsGHDuPDCC0lLS2v0GWvXruV///sfTz/9NJdccgmvvfYaP/zhD1v051BtKBQA+/cY91FR\nBP8cDBOfgH4XWstK11t3l0OuatkYvw9jYMdySO0Crti2jaVyO/x3Apz7T8gdfWSOWVEEjw6FcAiS\nOlm/4/F/g+6nH3i/Za/D+5Phwn9DyRqIy4Ady6BmF8Sm7tmu6FsrIdhdMOM2+OlX4I5v1R9Jbz1a\nwfDhwxv18f/nP//JwIEDGTFiBAUFBaxdu3afffLy8hg0aBAAQ4cOZdOmTUcqXNVSqophw6f7Lv9u\nOvw117rjP1TrPoagF3au2rNs3tMw42fgq2x6n0XPw/rZ+y5f8jIsfdV6vfJtmPOA1chZxxiY/Wd4\n+RBuRr57Ff41Cv7SCV6/af8xHQnLXodd6+Gzv7X8Z/sq4f07obq08fKNcyEchGE3QM6J4C2Hrx5r\n+jPKCuCrx6FwAbx9O1TtgFevtdad+DPre11VUp1vXwCHBya9AOUFMG9Ky/5cTTjuSgoHuqM/UuLi\n4upff/rpp3z00Ud89dVXxMbGMnbs2CbHALjd7vrXdrud2traIxJr1DAGXr0GBl4GPcdZF8V2PSG9\nB3z+D0jtCn3OPbxjzL4fFj0Hv1rf+G7v6yfAXwWF86HneGvZ/y6DxA5w9kONY5z5Gwj54JxHrGUb\nIhf3yqI92+3eZH0vXQcdBu8bx8f3gisefrZoT5XT1oXw5o/BEQNdxloXpZoSWPYG/HA6JLS3Lnrf\nPGltH/CC02O9LttirW+qpPPddEjsCL3PsS5YRd/C9R9CzH7ayqpL4L/jrbvprqfs50TuZfsyiE2D\nxPb7rjMGtn8Hmf1g+euAwMbPrGVZ/fdsV7zaivP73mUvfdn6Pcamwcm/3HP4TZ8TdCbiP/WPxMW4\n4ZP7Ye5DVqklIWvP/pu+gFeuhJpIUnHGwdBrrF5HjhjIvw5m/4nghjlM2dGbCf3akyvbrfPb5zzo\ncRZc+Trknvz94j8EWlJoAQkJCVRWNn2HVF5eTkpKCrGxsaxatYqvv/76CEenAOuubMWbVk+PUBCm\nXw9zH7TqdT/7G3z218P7fGNgzSww4cZ3e9uXWRdksC6YYF0wVr8Hy16zjl/nm3/BvKdg8UsQqLXW\n1ZU8KrYBMG/jLkK7NlrLStbtG0coaF14d2/ck1CCfnjrFnAnQqAaXr7CSggn/QJK18KcB63jfPMk\nZPSx9inbYn0vXGBVX8363b7Hqi2D9Z9A3/Nh/F/h4metqpCNc/Z/nuZHqktWvWO9D9TCWzfDk6Ob\n7pJZVgD/Ph2enwihAEsLy1i9vcH/2hePwFMnwRs3QeF8Kof+FOOMha8adPyo2glPjoIpY2DL11C8\npvGxjIEdK6CsAH8gxKrtTVQ/L33F+r7s9canYO1nfOrtziOzN1gL+l9i/Q0sew1jDN5ACF/xBnjx\nYqvd4aq3YNTtBM6fwv+Sf0S5I43tyYOsZJUzksrlH/C391cz5ZF7CT12AsaEYMRPAJhZ0xtvuPXH\nEGlSaAFpaWmMGjWKfv368atf/arRunHjxhEMBunduzeTJ09mxIgRbRRllKousep7i1db70vWWHfa\nIR/sXGkVyQM1Vn1uWcH3P872pVBpXbjZOHfP8kXPWvXByZ1h6yJr2ap3re+1u2H7kkhc66wLb0oe\nhPxWqWL7UuvO0u6CiiJ2Vfu5dMqXhOuSQmkkKYTDVgljzQdQvRMw1vK6Hiur3oadK1gy9I/sTh0E\nBd9Aux5w6u9hwCRY/CLBD/5AmSOdLSf8wdpn9ybKdxUTePlqq3pkyf8I+ar512fr+XJ9pBpszfsQ\nDuDveY71vtvpIDbrXDYlUGtVfQEV677i3reWEn7mHKuKZMd3sLWJ56TMuhMTDkDxKnZ/8giXTvma\ncx/7nNcWFvK/l18g/NG9VDjSrGos4Owvu1HQ/szG3TvXfwLhAKHKnTD1LHh8GMEpp/LmR3N4+KM1\nfPfvH8GTI+Hhfnz4t0sY9/BcPl29s373Bd8uss5ZWjfYuZzQ9hUA+HcVElu1ma/DvZg2bws1/qBV\n8mw/iNC8f/PQX3/PuXc/zbePX2X9Rq580yqlnXEv96/N5c53N3KR/x4uKPohy4vK8Xc5k5SaTUzM\nrubXruksCeXwQI8XCWUNYsGmXfzkxUU88+Wmps9tCzruqo/ayksvvdTkcrfbzcyZTfc/rms3aNeu\nHcuW7flH+uUvf9nk9uogwiHwV4Mn0XofqIVHBsFpd0NklHa4eDW24pXW+pI1sHPFnv3XzrLqhiOq\nfNbdZLy7Gf8ma2YBYlVZbJzDO0uLeHXGDKaEnqWmy3hSEhIIr56JzxckZtU7VDrbkRAogQ2fEsoa\nRHjVTJwmBJe+hPnXKL755C16d84kCaDHONj4Gau2VZBmynGGrXaA0i3LCVZ4yVz+H/jmXxQVFXBv\n8VieAvxpvXCseo/tm9fSYfX7mJg0rvoijVMCo3jYuZiVnS7loecWUlGQzyvB53HsWMLDgavI3JbA\nT4B5337LopUvc6PZSu0pdxPz6X1Me/Yx/rKhH26Hjecu70nPz58maE9n5NOl3HPuZq44Iceqhtux\nfM95+eKfVmlkwkNW1VpNCf6OJxC7dT4bd8zA5pqPd8xdeOb8mfCaDxF/NfLlo3D5y1AwD1a+zT9C\nkxhqX8vwLx7gfNt1LE07i3tf/ZIP3HexxdaBa839/J/tMRKcBq+zM3PLM7iidjdvfLGUUQN6kLHu\nY8Kx7ZgY+htd/QsY0dHBhB1TOXP7RXwcHkx/+9e8HByLjTAX8xEzEk7hgVmJ9O2QxO/fXEb3VU+Q\n74TlIx6i97vn88bzj3DBL/7F3I/e5DQgb+iZVMwL8tqirVw5Iofw6J8Tmn4DvzSP8stIrfD8Hr+n\nqzOTt77YSKzLzrNfbeaaE3O5/fQzOOMfc7jj5cWclJ7H74F73C+SHCplc/c7eGJBNaV8x8rtFWQl\nerhqZM4h/lMcOk0K0cIY8JaBJ7n+Atki3rrFqjs99a7D+5y1H8HH91gX5ZhUqN0FQ67eE2vQBwg4\nXI33WzCVcM1uHvWfy4+qn8Tz7X8gOQcu/q/1s/orYcNs/HFZuACbv3JP9UbQG7mYA/GZsGYW//ae\nSkaih3MHduDGZxfgsAvPX3/CnuMFauHLx6wqIlccdDuN2k4ns+vrV0lJH0hsv4nw0T3MnjmdfwQf\npJRE7qm4hCd7bMO++AXu/c/L/Ll4Di8GxnGKfSld1nzCVStGckPBa3Szd6C4NovO8b1wb/4U79ZK\nEjoMwdZhMKycwdqtO+kk1h2ssbvZvv47/u/RabwUvhcbUFywjpC/F7jg3ZSrOK/kd3zy4l+43PYx\nG1NHU747zBdxY/ixP4YPv+pOVnIFfTr3Y9a6YQySdbzvOpM+xU5+7IhhyXeLGerZzhp/J9YkTWJs\nzH/pXfgKvx0xBJa/Sa+XryNJanjIdi39OybzuzeWsX5nNXdl9iO8dRHz1pfg27GGkz68BwchViz6\ngp5sZHPcIF6pnsBkvuGB1Bl4K52M/7I3z8T0oWLu67Rb+Bbta9fCxrlsmfsCySaWOemX8l24nORd\n9/FH2xOE3F9SmJNG5s5y5MY3mN1hMHA+hMNc8uFaPpmTxBVOeP6dj5m+vIoXyj5hiWsIy3Z46D54\nEpMXbeU/nl78L28m52x6m1D2CEZNfA6bCWCeO4m/2F5iSFEOpz74Kb5QiD8lzGOhrx8XvlbNc86+\nnFz1PtM+X0768reoscVyxXk/4JWir3ly9jr6tE/ktTVdmFY7lYdOT2Ri6maemrWI2aUjyXp7OW8t\nttqGctJi+fW4nsS6HPz1wv78+IVFrNkR5uqELnTe+im44jn/0hvYMHsLj35ilQj/MWkgsa7Wv2Rr\nUogWvkqr2iQlb08jYNBndZV0x4Ovyqpvjs9s/mf6q2HJNGv/MZPB3uDPqXAB+CqsftVrPrCqOkb+\ndP+ftegZq3Hw7dv2LMseBpl9qfEHiX3xfKuRb9Lze9aXb4X378Rg47GqblyXPBNXem9sxSvZsWQW\nmb1PsrYr+AZfYnfE2HFKiPCKGdgQwFC5+A38JLPaczIj1r/FV8tfYE1cPkM7J9Nv87OEbC4CoWE4\nl71K9bxn8RatJM3sosDdnZhwDe1WvUMM0BF4zX0dF+ZZDYEP1f4enyuV9wY8yQef+3m/W0fOBq7a\n/lfEFuRTOQFHKETelo9Y6i1kVOwqZtrG8OC0xdzo7co1trchDL8uuxnnxzv5I7C9YAOdI0mhPGM4\nuUXzuMT3GjViY6Urn2z/BrId5QC8uiOLLMdQLvG9iU2CPFPSkwHZSfzp/P7c8bKH3+Rnc92oPBx2\nG4U7plFRU8HIeRV8ub6EqpgO5Ph2MMixhfdD/Zm5bAcbAmdxh+3fDFl8EQAbUkez9oRfcfPQk7jN\nJtz/7kqmfrGRzslxXOPdzE1Pz+avzin47U6+aH81Y7ZNZZ77RG6t+Qm+2momeyC9ajVluWfhLk/k\ntZKe/NwxHSL9K759fyq5JZ+xOGYEz954Eh6njVVFYzBlH2F/fzI5NYth1G2NG9ptNiYO7sA7n1oN\nvH09xSzauAhxl/BcWVduGJ3Hbyf0ZkyPdPp1TKJd+hWwayP2+AyyXZHOIaf9npQ3f8Ll7TYwNzyA\n/55pJ/XNLVSO/itdl8Rhz/897WZPotdHVzPEto5d+b8g1u7gD+f05ccvLOTCJ60xBzed3I2Jp/VC\nRAiWjeSbD9YAZVw3Ko9huSn0bp9Yf4E/tVcmS+4+k2A4TPwX38LcB6yGe2cMPz+jBwCbSms4b2DH\ng/xDtgxNCsebkN9qyEzMbjzYKRD5bws26PlUsdW6sGf2g+piqyThirfugAFeuhQGXAL9Lmj6WFu+\nhnDAqhvf8pX1DyoCNie8cpX12b9cAx/cBbs2WL0tgl6r0Tejd4OYA7DhM6vf/YBJmMrtyGvXw9aF\nzK3I4PZnPmOB80sEIokt19rvs79A0IsdGG+bR4K3iA39riNl58OUFG4grUMX6w+8ppRYbwWfh/sy\nxr4UW9V2ipMHkV62mIRQGctdA7l361CmuWbyH9dDFPuTKH6qK79zWm0AJa8LaSuepYT2rKMHn6ec\nz2x/TypqA+T4VtDTVkAwviPv7OzGyfG9qXHksimcyYk3P8vJwST4fDa/nhviDIeDPrbNPBk8hxFj\nx1G62o6reCZPJjyDJ1DLoDHnsn2Wl8+kF9c432Z9ymgWhwfRySwAgYqdm+uTwte2QYyTuUy0f8W8\nhDNZVB5DvizkxLRawqXCvGIHFSdchWvJAoLYebOiF/eNz6VfxyQ+/PmYRr/G7Mx2QDv6Fm7gjW+3\nsiktgyG2FTi95dBhAO8v3877nMLwCWcxKqYAsvrTpdNwujT4jHvO7UvXjHjmz1rCNcDbJ24gb9E8\nQidPZsypd8Lu2xme1ImvRKjwBuHpB2DXepKHXMC7/U/Cu8kNz01nty2FeYGunFYyE4eEGfmDa3DG\nWL2eBnZOhc6XQJdTrHaSgZfv8yfZLSOBxKyuBHbZuWUgfLJhLVRCz1HnceP43ogI5w1qcHFN3Wt6\n+L4XwMzJ3Je3AjPxZzg+uBPsbnJGXcrHp1s3U5s2X8aQDS+xLbYn7cfdCcDQnBQ+uP1k/jVnPSd3\nT2dUt3b1H3neoI48+MEaMhLc/OLMHsQ1UR0Z47IDduh/IXz1qFVKxpqc8hdn9txn+9akSeFY5y0H\nh9vqy1z3vqbUqjqpq1uHBkmhQb/0gNdqRAwH9ySLqh3WQKRQwGqs2/4d9PrBvtU2YHX9szmtxsVl\nr8G7v7AacIdcZSUcoObjvxFbEmnkLfjaKlmseAtuW2KVSoJeqwHWV8F3scPpnzuatxcXMsbE4do0\nny9jhzPQrEQijafPPnoPJ//0cfIcu6wGygGXYpa+zK0Oq1fIF4FeDDVpOKqLqCoupK5jpD0c4Bvp\nTz5riaOWt0raM9FdRLvQTvoOHM4E9+mM+awT087wUv7Jw5xQ+y1P2C9jWHAhw5b/lwJXF86v/QPP\n/fgU/tAxiT8AgVCYVxb0pLjSx4T+7Zn+jzlc99wivqv6E/dP7IczqT2dgcGdk/l2Sxnf5FxNn7xO\nFFacxm9G57EibxIfP/sapwXmAkLesPE8kFBDRWUXqC6n68hb+CAlhwderIC14N+9lUEJZWyrTeXN\nbSmMA2zhACMuuIURuzbAW9MZaNtAKQkEcdDtxImw5e+QnMc/hp3Mqb0yDvin1KeD9feyqCKJq+1W\niSO7zwjYYEhP8DB81Klg33/flCtH5HBlryvh4b+St/gBiM/EPirS/z7FqgsXICnGCZ2GWz2ceozD\nbhPicvOhwxBcfS8ndbfgWLAAHDE4ezQxCCw+3erCuR93nTuQ2umdyPQXcHFyMV53X3589sgD/uz1\nnB7ocy725W9A4AGrS2jPcY262OZc/Ge2v2kn7dRbGnXTTYlzcef43vt8ZKfUWCaP70X/jklNJoRG\nMnrDnVsbl7qPME0KxzJjYNdGq6tb5J+u/qIfrAUaJIXgXkkhHLYu4AD+GuviLHYrqQRqrRIHQEUh\nLJ3W5OjZ8IY52LKHWdVHC/9rLbS74OP7oMNggmVbcX/5ECGxYbPZkDWzMKveRYJe1r52L+1jgsRv\nmAU5IwmJncs/8vDO4GpmrdhJcrgLA7csYFlCOaNtKwngYF3sYM6u/pjpSzdzdcYGYkyYqoHXUrX+\nW7pVr6bCxPLSxniyTBq9a7fh21VItXETFjsJ1FCb1I1q6UpcxTK69hlKWjgI6z6E9J7cNrw7Pxnb\nFZfDxp0lPbhh3hquP7U/v5+3lDvcM7h/12lcOqYX/TrumcrAabdZjasRA7KTWFpYzvh+WVxxQuf6\n5RcNzea7wnI6TryPtPR4/hhZPqJrO4K/nAZTRltjFmJTuWBI3fiGB+r3H9S3D6yFtHApvT272FKT\nwZKadPBglZo6j7SSOJBe8R0rTRo5abF0yUiEa2fisLs5Pa7xCPqm9G1v/WybwulgBxD6DD6RrDkL\nuXJkDs4DJIR6SdnWdA/echh75/7HBZzyO2vMSN3F1maHm2YTBwzzVcK3v4Vup+0ptR6C4Xmp0LE3\nbFuCo2IrjpG3HNoHDJgE3z4Pz0ywuu4OmNRotcQkk3XZfgao7cePx3Rt/sZtmBCglbukisg4EVkt\nIutEZHIT63NE5GMRWSoin4pIdmvGc9wJegHTuEqo7qLvbzD4LRzas03d91CDfby7re+J7QGxShpB\nH7iToP0g+OwBq799A/NWbICixWxOHAq9zrYWnvBjmPgkxuGBU+5iXeY47GKYE+rPGmcvzIKpiL+K\nleFOdN/0EvErX8EfDMKa91nn6kslsXy4YgdfrS9lielKQtlq1hTuZKR9FYvC3Xik/GTaSQXbls1l\nybLvAPi82MMKj1WvPC/ck5U7a9hm0kgO7CRUUcR2k8qiUDcAHJm9Sc+zBjSdMvpkJKOXFXe69d3l\nsP4drjghh9iEZM4b3JHOnfP4UemlFJh0LsnvdMBfx+2nd+f03pn87aIBjZ5Jcfnwzsz9zSl0Sd/3\nAulIzIDrP7D6+O/HyN45VJhYsmQX7QLb2GnPYjsp7I7pbJ1zEUi2YrP5q3Aktee6UXlWDIkdoBkJ\nASAp1kl2SgxbTKREkdYVd1wyn//mFH46tpkXNRHomG+d08FX7n+75E7QZUzT69wJcMWrcNafmnfM\npqR1hbLNVim422mHtm/OKKv6decqK3n1nPD94zgGtVpSEBE78DgwHugDXCYiffba7EHgOWPMAOA+\n4M+tFc/RJD7eujgUFRVx0UUXNbnN2LFjWbCgiX7bDTz8j39QU1trXcCNsabiLi22VgZq9mxYlwhc\ncWBCVNV4raqjOl6rqmBbrQPjSSRcs5tgwEuoY771j+krh3+NZu1HU7ni318T+PIJer0zEZsY/rAs\nndtX9OSe0LUs6XUHi5NPp5/3aRY4h/CO7RRC2JBBlzOzugcS8lNiEpnW5c+EHLF8HncGp9b8kWB6\nX14KjgVg6ucb2VXtZ6npio0QvXzf0U828U24FyvC1j1D7c71bNywBr+xs7oyhvnSD4D5xvrzKnWk\nE2+qcJdvYIdJ4aPwEApNOzI6dUXaDwS7G9J7Qt5YiEtvPPIV6Ncxifm/O52u6fEM7pwCwMguaeS2\nO/Bd66m9Mvn31fkkeBqP/BUR2icdYHLDlNw9Jb0mxLsdVDjTGWxbh6N6O7XxnTHYWDLxYyspgHUR\ns1pd6NmtG1efmHvAWPenb4dEtphIZ4OsAQA47LZDe/DSRf+B694/vDveLmMOeE4OKs26EcAZB50O\ncWyQzWYNMrv5Gxjz65btrXcMaM2SwnBgnTFmgzHGD0wDzttrmz7AJ5HXs5tYf1zr0KED06dPP/BG\ntWV7RpeCVWVUuh5qd/Pw409SU+sFE4JwkPfefZfkeA8gVtVQOGTtU9eeEGNd4ErKKjBBr7WdKwFM\nmDBCiVcIuJKxmSAOE+SbYDee2pzF+c4nCMZmsOnrN/liXSm2uQ8SMnBn4HoW0pOZq8t4RcbxxOeF\n/OvT9VQH7bz+7Vbe25HKrztNY8z5N1GeeSIAn8gIbr/4LOy/WEncJVMoNBm8OPglnq0eQVKMk6Jy\nK1l16D0KgLsdz2EjxI6UfLp264URG9nsILZ2O9tMGhtLa/jY25t3Uq9mcZp1R5fewWoCTalaT7Gk\nMsM5gdG+R+ielQz511uTisUkW5OW/Wrd/qdkIFIVAVzWoDqoLSRkdGagbQPiiqcg25qOo3/HpD0X\nLIdrz7QKCU1MB9FMV47I5Qcnj7BGP+eO+n4fEpNS/7fWZtp1t77nndR0e9hB9+9mlTaiUGtWXnUE\nGg4RLQRO2GubJcAFwCPA+UCCiKQZYxrNOiUiNwE3AXTu3Lb/nE2ZPHkynTp14uabbwbgnnvuweFw\nMHv2bHbv3k0gEOD+++/nvPMa57xNmzbxgx/8gGXLllFbW8u1117LkiVL6NUtj9rKyMN3akr5yR2T\nmb98PbVeHxedfy73/vQS/vnUMxRt28EpF/+IdinJzJ79Cbk9+7Hgnf/SrkMuf3/kcaZOnwli44Yr\nLuT2ay5kY9EuJky4gEHDRrAtMig+AAAgAElEQVR00QI6ZmXw1svPEQP4cGKA7T4XHY11r/Dk+jTm\nrlmFiLDUlURsuAQnQey1pSzreD6vVZ7OJ7edjMNm44WvN/P4p1Z/apfdxjtLiqjwBrk4vxdis3H1\npEt44anPyTjlJ6TEuQAX/bPDxLsdTP3CGqF7/eg8/v7hGrqkx3HSkN5sXJNJtpQQHHoDvz71BhwO\nJzzRkS7lJbQ3pZQ7M9lYWkNRZYgFQ3/E6DgXMVt2k5iWC0VgI0yVO4Nh2al8tHInPbMSrAvEIfyz\nD81J4d1bR9OnfeLBN25FSRk5UDQXJvyNc9qPIC27hLR4d+ONkjtbo6oPpVvxXkZ3b8fo7u1g7FIr\nMRyr0ntbJcK6qk3VbG3d0PxL4DERuQaYA2wFQntvZIyZAkwByM/PNwf8xJmTrR4zLSmrP4z/y35X\nT5o0idtvv70+KbzyyivMmjWLW2+9lcTEREpKShgxYgTnnnvufovhTz75JLGxsaxcvpyls19nyFmX\nWnf6gRr++JubSe3Uk1BcBqeNPYmlYwdx6zUX8PcnpzL7jedpl+iGoA8Ttk7NwpWb+O8rM/jmsw8x\nse04IX8wY04YTFyn/qzdWMDjjz/KmL/fxSU3/Yqp02dy8/mj8BoXIkJZbZB4iQOEDa6ejO+axTUn\n5rLjmRR6OwpJD1jJqpgUkmKcZKdY0yVffWIuU+ZY87/87uze/GGGNap1aI51x5ibkUTOXc80+vkd\ndhvDclOYvdqq8rpyRA7/m7eF03tnMiQnhXH+u+mSmcy0c35AffNuSi5DTTnxvjLWxQ5izfZKagMh\nspI89Y15H3y557z6YjK5aGg2obAhK9HTzF94Y307HOI8+a0h/1prCoWBl9FDhB6ZCftuk9TJmo7h\nMEoK9dr6Tv9wxaXB7d9B/IF7XKl9tWZS2Ao0bJnLjiyrZ4wpwiopICLxwIXGmGPu+ZSDBw9m586d\nFBUVUVxcTEpKCllZWdxxxx3MmTMHm83G1q1b2bFjB1lZWU1+xpw5c7j11lvBW8aA3l0Z0Lu7NbNm\n2MUrb3/IlJd+ShAH24oKWbFuCwP69AAMYXcCECQc8BI2VlKY+81izh9/GnEuG8THc8H4U5k7fzGn\ndOhLbqeOjOjbBVvYR59+A1i7yfqVeHHRLt5FcaWPcmc6xFfx4Z39iHHaERGqhvQjZsUKMiON0tvC\nVlKok57gZvL4Xhjg4vxs/jxzJcGQYUD2ngtqUwlxZNc0Zq8uplNqDClxLmbdcTIehx2Xw0Z25zwG\n5qY23iElh/Y73wf/bmjfidpt1j1Ewwt+QnonwkawicHEZzGuX3vG9WuBC2Vbys63vg4k0tjcaHbO\naJbw/UtM0aw1k8J8oLuI5GElg0uBRqNNRKQdsMsYEwbuBA7/mXMHuKNvTRdffDHTp09n+/btTJo0\niRdffJHi4mIWLlyI0+kkNze38ZTZ1SVW+wBYRf661zUlVrdOgNrdbNxSy4NTXmT+O8+SktOXa669\nDi9uglafQWpxgsNO0F+LYAgZG9VBQxA7fm8NrnDImrVRHHgDYZxuN7Fi9VAK2Vz4Qn4KTTqVxNI9\nwU15TYDkeA/bS92NhtTHp2WDv9KazhcoDCY3SgoA143eMxDo3IEd2FHhw+O0H/C8jexiDfLpF7kb\nT2zQSPvaT07cN5Ek51rnCPC021OVmNkgKWQkJ7CTZLLYjT35yIwCPSq062l1K046cC8ppQ6k1Rqa\njTFB4BZgFrASeMUYs1xE7hORuonrxwKrRWQNkAn1XbiPOZMmTWLatGlMnz6diy++mPLycjIyMnA6\nncyePZvNmzdbXT3rLv7lBdb4ABOGyu2cnN+Xl577L/irWbapmKUr10LQR0VlNXHxiSQlJbFj3WJm\nzv6CgN1DuYklIT6ObbtrweFBgj4EQ0CcdOufz1szP8ZbVcbuXaW88f5sTho9Gl8wRAgHu+K6sirc\niaDdhcthY5eJx+Vy4bDZ6NU+kZTYJhrmIlUS/W1W/f/mQCLJMU3Mrx/x1wsH8My1ww563vp0SGRA\ndhKn9d73rq7Jqra60cxActaeJJSV1CApJLgpMlY3TE9qFPVy7n+x1Yiud8jqMLRqm4Ix5j3gvb2W\n3d3g9XTgIN1vjg19+/alsrKSjh070r59e6644grOOecc+vfvT35+Pr16dLemnwjUUD+1sQnVv/7J\n5edw7c/vodeYi+jepz9DB1ndJAcO7M/gIUPoPuYi2mdlMiR/OMXVIYpNMpf/8Couu/gicjqk8+nL\njyMY7E43/Qf258orLuXEH/yQEA5+dNlEsrr3Z8WmIkTAExOLvzJMrMuOBK07+VjXge/o6y40gx0b\nCWGnwBvDsAMkheZ2YbTbhBm3HMKjExt0U2zXsSs22UTYNK4+inc72CntCJv1JLaLopKC3WF1tVXq\nMIgxB263Pdrk5+ebvfvvr1y5kt699x1eflSp2Go97CM5x5oTqKYkUsw3UF4IMal4AwHW+dMw2Oga\n5yW2toiQO5lNoXSq/UHS4qzG4JIqH3FuB+nxbjaVVhNnC5BpSoiJT8Ie1w5jdyK+Sti1ngoTS6LU\nsDycQwgbmYkeMhLcVPmCxLkdGANbdtWQmdi4umifc7pzJTwxglrc1DqSGBN4jAuHZnPPuUf4SXdV\nO+HBSHfDyQWMeXQhu6v9LL3nrEabPfinyQyr/YL4G95iaE5qEx+kVHQRkYXGmIM0TLV976PoUT/9\nhK/BVBN7nv5kkjqxaUcVMS4bCBRU2+hpg51eO15CdEqNJSXWRdgYQmFDcqyTOLcDh03wixvSumOP\nzKsiUD8XUoJ4MWInNSGG4kpffcNx/QArgbyDDMqyPshqvIzBx1ZbKpW+IMmx3+NB9IcrLh2csdac\nS55EumcksK1830eXzks7j8c2nsTn37PHkVLRSpPCkVKXCEK+PXMO1SUFsVPpC+EPhWmf5CEhxklp\nlZOCqvaIO54eSbE4I1Mw2ETolBpb/7HdMhKw2wS7ba/qGrs1UZ2YMNhjyEr0kOhxHryaaH88yVai\nCXrZGrIahfduaD4iRKzSlljn4/8m9sUXCO+zWUaCO/Jdk4JSh+K4SQrGmEMbin8kGWM9Jxes6SUi\nk5fVJwWbnd01fpx2GwkxTmwipCe4m9W1sG6+nn2IWLOnBmrB4UZEDj5DY324TVQpiliDoso2s9lv\nDWpqk6QAMOz6+pf7mz5icOcUtpbV7v/8KKWadFwkBY/HQ2lpKWlpaUdXYjDGKhWIDQgDtj2zlQKh\nYAC7CMbmoNoXIsHjwNaS8Ts8kaTQ/GH+xhhKS0vxeJq4w05oD2Wb2R62Bja1WVIYfuNBN7l+dB7X\nN+giq5RqnuMiKWRnZ1NYWEhxcXFbh9KYr9Kauyg2BWp2EXbEYIskhTCCkd3YbUJY7BQFqkmJdVK1\nowV/Jd5y6ysmCO6KZu/m8XjIzm6iK2ek5LITKym0SZuCUqpVHRdJwel0kpd3FN4VPn8BrP/YqgMv\n28xdgWu532k9d2C+6U22FJOV6GFTYj43rruED+44uenpC76v5W/AW9dYMz52OfiYgYOKJIUdpo1L\nCkqpVqMVrq3FXwObPrdel20mgJOvIlM7B4ydxLyhJJlKwtUlFHg9JHocdGtivv3D0nMCnP0Q5BzC\nOIAD2SspJGpSUOq4o0mhpVWXwNJX2L3sQ6s9obc1eHuzSee0ESMIY8cb14EueV2IFR/2kJfVlW6G\n5KRg27sH0eFyuGHYDS33JKe8MezOGMHmyHz7WlJQ6vijSaGlzfotvH4j4bduoca4uaPiMsLY2RTO\nZMLgztjSupDQvgfO+D0P9l5b5SI/5xiYlbLjEDaf8zI+XMQ47bgd37N7q1LqqHVctCkcNSq3w7LX\nKXVkkhbcwZrk0Xy01c7vA1dTEZvDP7OT4PynrCegla6r383nSuGUgzxU/WhRN9+RlhKUOj5pUmhJ\nC6ZiwkEurP01d/Wv4PQzzuZdWyd+92Yyp/TMsLrLZg+1tvXumSH84WtPQ46GOfuboW6yPE0KSh2f\nNCm0FF8V1V9M4avQIDJy+3LSJcPBYacz8Pz1ez9wDojd8zB1iW237/qjVILHgYj1kHel1PFH2xRa\nSNG7fyIuuJsV3X7EC9efcPD69gZJgdhjZ8I2m01IinFqSUGp45SWFFpCWQHtlj7NTDmJGy+7pHlT\nK3iSIyOdxXp9DBmWm8qgTsdWzEqp5tGkcLiMYfcrNxNjDBWjf0tMcyecs9kgJtWaU8h2bBXYnr7q\noLPvKqWOUcfW1egoZL55ipSiz3jMcTXnjWmi7eBAYtMaVyMppVQb05LC4fBXE/7wbj4LDSLzrJ8d\n9HnE+0jufPBtlFLqCNKkcBjMjhXYQz5mecbxf8O+xwV+4pMtH5RSSh0GTQqHoWjtIjoCI0aM/n7z\n9sent3hMSil1OLRN4TBsX7OIauNmzAktMAOpUkodBTQpfE/GGKR4BdtcuaTG6yMflVLHB00Kh8oY\nWDKNdZsL6BzchMns09YRKaVUi9E2hUMU2L4C5xs/Yod9ON2lAne3wW0dklJKtRgtKRyigmVfAjA6\nNA+AhM4D2zIcpZRqUZoUDlHlhnnUGhfGbs0WSkbftg1IKaVakCaFQxRTuox1ju7IsBshrZt2K1VK\nHVc0KRyCQMBPJ986qlL7wpn3w0+/buuQlFKqRWlSaKDWH+Lx2evwBkJNrl+zbCEx4icmd5g1iZ1d\np49WSh1fNCk0MGdtMQ/MWs0HK3Y0uX77qq8AyOl34pEMSymljhhNCg2UVPkA+Gx18T7rqn1BytZ9\nQw0xpHTSsQlKqeOTJoUGSqv8AHy2pphw2DRa98D7qxgWXIg/e8Qx9/wDpZRqLr26NVAaKSmUVPlY\nsa2ifvmq7RXM+2YOnaWY5MHnt1V4SinV6jQpNFBS5Sc1zhp/8NmaPVVI//p0PRMcCzEI9BzfVuEp\npVSr06RQp2YXGaXz+EHSJvpkJfD52hIACnbV8PbSbVwUvwTpdALEZ7RxoEop1Xp07qM60y7nD7us\n3kVP9niax1cnEQ4b/vP5Rs60LSSrZi2MurKNg1RKqdbVqiUFERknIqtFZJ2ITG5ifWcRmS0i34rI\nUhGZ0JrxHFDVDtbSCYAhMTup8gXZVFqNbfl0Hnf8HToMgSFXt1l4Sil1JLRaUhARO/A4MB7oA1wm\nInv35bwLeMUYMxi4FHiiteI5GOOvYUkojzB2utiscQofr9zJ2bVvUxbXBa55B2KS2yo8pZQ6Ilqz\npDAcWGeM2WCM8QPTgPP22sYAiZHXSUBRK8ZzQMZfRYWJpTqmPWn+QlwOG898sZEeUojJGQWuuLYK\nTSmljpjWTAodgYIG7wsjyxq6B/ihiBQC7wE/a+qDROQmEVkgIguKi/cdWHbYjEECNVTjwZuQg233\nJnq3T0QqCkiQWpJzdXpspVR0aOveR5cBzxhjsoEJwPMisk9Mxpgpxph8Y0x+enorzEoa9CEmTK1x\nE07Ng10b6N8xkR5i5TR7Vr+WP6ZSSh2FWjMpbIVIy60lO7KsoeuBVwCMMV8BHqBdK8bUtEANADW4\ncaR1AW8Z+elCr0hSIKPXEQ9JKaXaQmsmhflAdxHJExEXVkPyjL222QKcBiAivbGSQivUDx2Evwqw\nkoInszsAI1PLGeIpIhDfETxJRzwkpZRqC602TsEYExSRW4BZgB2YaoxZLiL3AQuMMTOAXwBPi8gd\nWI3O1xhjzP4/tZX4rZKCX2KIzbKSQmagiMy0XZCkVUdKqejRqoPXjDHvYTUgN1x2d4PXK4BRrRlD\nswSqAXB44pGUPECgZDWUrIHuZ7RtbEopdQS1dUPz0SFSUnDGxoPTA4kd4NsXIByATH0Gs1IqemhS\nAPBbJQV3TIL1vsNgqNkF/S6EXme3YWBKKXVk6dxHUF99ZHfHW+8vmgrhoA5YU0pFHU0KUF99hCvW\n+u5wA+42C0cppdqKVh9B/TgFLRkopaKdJgWoH6dgc2tSUEpFN00KAP4aQkZwuGLaOhKllGpTmhSA\nsL+aGjy4nfa2DkUppdqUJgUg7KumFjceTQpKqSinSQEI+6qoMW48Dj0dSqnopldBrJJCDR4tKSil\nop4mBcD4q6nBjdupp0MpFd30KggQqIlUH2lJQSkV3TQpAPi1oVkppUCTAkD985nd2tCslIpyehUE\nbMEaao1bxykopaKeJgXAFqi1HsWpDc1KqSinV8FwGEeoxup9pA3NSqkop0khWAtAjfFoSUEpFfX0\nKhh5lkKN9j5SSilNCnVPXavFrb2PlFJRT6+Ckecz1xgtKSillCaFSPWRV2Jw2vV0KKWiW7OvgiKS\nIyKnR17HiEhC64V1BEWqjwJ2TxsHopRSba9ZSUFEbgSmA09FFmUDb7ZWUEdUpKQQdsS2cSBKKdX2\nmltSuBkYBVQAGGPWAhmtFdQRFYgkBbs+ilMppZqbFHzGGH/dGxFxAKZ1QjrCgl4AjFOrj5RSqrlJ\n4TMR+S0QIyJnAK8Cb7deWEdQ0AeAODQpKKVUc5PCZKAY+A74EfAecFdrBXVERZKCzelu40CUUqrt\nOZq5XQww1RjzNICI2CPLalorsCMmUn0kWn2klFLNLil8jJUE6sQAH7V8OG0gZDWVODQpKKVUs5OC\nxxhTVfcm8vr46MMZ9BLAgdvV3EKTUkodv5qbFKpFZEjdGxEZCtS2TkhHWNCHH6dOm62UUjS/TeF2\n4FURKQIEyAImtVpUR1LQhw+nTputlFI0MykYY+aLSC+gZ2TRamNMoPXCOoIiJQWdDE8ppQ6SFETk\nVGPMJyJywV6reogIxpjXWzG2IyPoxWecOm22Ukpx8JLCycAnwDk0HsEskfcHTAoiMg54BLAD/zbG\n/GWv9f8ATom8jQUyjDHJzY6+BZiQD6/RkoJSSsHBk0KliPwcWIaVBCSy/KBTXETGMjwOnAEUAvNF\nZIYxZkXdNsaYOxps/zNg8KGFf/hMwIsPhyYFpZTi4L2P4oEEYCjwE6A90AH4MTDkAPsBDAfWGWM2\nROZNmgacd4DtLwP+15ygW1I44MWHVh8ppRQcpKRgjLkXQETmAEOMMZWR9/cA7x7kszsCBQ3eFwIn\nNLWhiOQAeVhVVUeUCfisNgUtKSilVLPHKWQC/gbv/ZFlLeVSYLoxJtTUShG5SUQWiMiC4uLiFjws\nmKDX6n2kJQWllGr2OIXngHki8kbk/UTgmYPssxXo1OB9dmRZUy7FemZDk4wxU4ApAPn5+S06ZbcJ\n+vCRqCUFpZSi+eMU/igiM4GTIouuNcZ8e5Dd5gPdRSQPKxlcCly+90aR8Q8pwFfNjrolRQavxWpJ\nQSmlml1SwBizCFh0CNsHReQWYBZWl9SpxpjlInIfsMAYMyOy6aXANGNMmzy0R4I+/MZJqpYUlFKq\n+Unh+zDGvIf17IWGy+7e6/09rRnDwUjIp72PlFIqIuqvhHVJQccpKKWUJgVsIb/OfaSUUhHRnRTC\nYWwmoHMfKaVURHRfCUPW85m1+kgppSzRnRQiz2f26/MUlFIKiPqksKekoE9eU0opTQoA2iVVKaUi\novtKGEkKIZsLm00OsrFSSh3/ojwpWG0Kxu5u40CUUuroEN1JIWRN/KpJQSmlLNGdFCIlBRyuto1D\nKaWOEpoUAOyeto1DKaWOElGeFCLPDXJq9ZFSSkHUJwWrpCAOLSkopRREfVKwuqTanJoUlFIKoj0p\nROY+0pKCUkpZojspREoKdpcmBaWUgqhPClabgs2lDc1KKQVRnxSs3kd2Z0wbB6KUUkeHKE8KXkII\nLpcOXlNKKdCkgM+49AE7SikVEdVJIRz06bTZSinVQFRfDcMBL34cWlJQSqmIqE4KIb8Xn3Hi0ZKC\nUkoBUZ4UwgEvPly4taSglFJAlCcFU199FNWnQSml6kX11dAEvfhw4nFoSUEppSDak0LAh8+4cGtJ\nQSmlgChPCoR8VvWRlhSUUgqI9qRQN05BG5qVUgqI8qQgkTYFHbymlFKWqL4aSsiHD53mQiml6kR1\nUrAHa6g2bu2SqpRSEVF9NXQEa6jBg1sbmpVSCojmpBD0YzcBqkyMlhSUUioieq+G/ioAanBrm4JS\nSkVEcVKoBqAWDw6btHEwSil1dGjVpCAi40RktYisE5HJ+9nmEhFZISLLReSl1oynkUhS8NtjEdGk\noJRSAI7W+mARsQOPA2cAhcB8EZlhjFnRYJvuwJ3AKGPMbhHJaK149hFJCkFH7BE7pFJKHe1as6Qw\nHFhnjNlgjPED04Dz9trmRuBxY8xuAGPMzlaMp7FIm0LQrklBKaXqtGZS6AgUNHhfGFnWUA+gh4h8\nISJfi8i4pj5IRG4SkQUisqC4uLhloqsvKcS1zOcppdRxoK0bmh1Ad2AscBnwtIgk772RMWaKMSbf\nGJOfnp7eMkeOJIWQVh8ppVS91kwKW4FODd5nR5Y1VAjMMMYEjDEbgTVYSaL1+SsBCDu1pKCUUnVa\nMynMB7qLSJ6IuIBLgRl7bfMmVikBEWmHVZ20oRVj2iNSUjBOLSkopVSdVksKxpggcAswC1gJvGKM\nWS4i94nIuZHNZgGlIrICmA38yhhT2loxNRJJCri0pKCUUnVarUsqgDHmPeC9vZbd3eC1AX4e+Tqy\n/FV4ceFyOo/4oZVS6mjV1g3NbcdfTY3E6BQXSinVQHQnBeMhzq1JQSml6kRvUvBVUWXcJMZo9ZFS\nStWJ2qQQ8lVRZTwkejQpKKVUnahNCmFvJTXGTZKWFJRSql70JgVfNdV4NCkopVQDUZsUCFRRg0fb\nFJRSqoGoTQrir6bKaElBKaUaitqkYA/WUKPVR0op1Uh0JoVQAHvYT7XxkOhp1UHdSil1TInOpBB5\nwI62KSilVGNRmhSsyfAC9hic9ug8BUop1ZTovCLWz5Aa37ZxKKXUUSZKk4JVfSRuTQpKKdVQlCYF\nq6SgSUEppRqL6qTg8CS0cSBKKXV0ic6k4LOqj5wxmhSUUqqhKE0KFQA4YzUpKKVUQ1E5citcsQ1j\nBEdiRluHopRSR5WoTAqB3YXsIoXE2Ji2DkUppY4qUVl9FC7fynaTqg/YUUqpvURlUpDKIraZVJ0M\nTyml9hKVScFRtc0qKWhSUEqpRqIvKXgrcASrtaSglFJNiL6kUFEEwHaTSnKsJgWllGooCpPCVgB2\n2dNJj3e3cTBKKXV0icKkYJUUXKnZ2GzSxsEopdTRJWqTQnJm5zYORCmljj5RN3gtWFbIbpNEXmZK\nW4eilFJHnagrKdSWFrDNpNI1XafNVkqpvUVdUjDlhWw3qXTNiGvrUJRS6qgTXUkhFMRTtZUi047c\nNE0KSim1t+hKCoXzcYVrWB87EI/T3tbRKKXUUSe6ksK6jwhhozRzZFtHopRSR6Wo6n0UXPsh34a7\nk9OxQ1uHopRSR6XoKSlU7cSxfQmfhgZyRp/Mto5GKaWOSq2aFERknIisFpF1IjK5ifXXiEixiCyO\nfN3QasGs/wSAFbHDGNwpudUOo5RSx7JWqz4SETvwOHAGUAjMF5EZxpgVe236sjHmltaKo04NbhaE\nB9JlwImI6PQWSinVlNYsKQwH1hljNhhj/MA04LxWPN4BvR8axlX+3zBhQMe2CkEppY56rZkUOgIF\nDd4XRpbt7UIRWSoi00WkU1MfJCI3icgCEVlQXFz8vYJJ8Dg5s0+mVh0ppdQBtHVD89tArjFmAPAh\n8GxTGxljphhj8o0x+enp6d/rQGf0yWTKVfk6M6pSSh1AayaFrUDDO//syLJ6xphSY4wv8vbfwNBW\njEcppdRBtGZSmA90F5E8EXEBlwIzGm4gIu0bvD0XWNmK8SillDqIVut9ZIwJisgtwCzADkw1xiwX\nkfuABcaYGcCtInIuEAR2Ade0VjxKKaUOTowxbR3DIcnPzzcLFixo6zCUUuqYIiILjTH5B9uurRua\nlVJKHUU0KSillKqnSUEppVQ9TQpKKaXqHXMNzSJSDGz+nru3A0paMJyWdLTGpnEdGo3r0B2tsR1v\nceUYYw46+veYSwqHQ0QWNKf1vS0crbFpXIdG4zp0R2ts0RqXVh8ppZSqp0lBKaVUvWhLClPaOoAD\nOFpj07gOjcZ16I7W2KIyrqhqU1BKKXVg0VZSUEopdQCaFJRSStWLmqQgIuNEZLWIrBORyW0YRycR\nmS0iK0RkuYjcFll+j4hsFZHFka8JbRDbJhH5LnL8BZFlqSLyoYisjXxPOcIx9WxwThaLSIWI3N5W\n50tEporIThFZ1mBZk+dILP+M/M0tFZEhRziuB0Rk1f+3d7chUlVxHMe/v7Sk1JTKRKzcXTPIoNRC\nJDUCo1LKtbKyzOwBIrAXElGKPdE7g+qVpESR1pZiKS1BIPpiwxc+5OamPfiYkLKuIGHZg5X+e3HO\njHfHvatszLlD+//AsHfO3Jn9z/+ee869d2bOif97raTBsbxO0h+Z3C1NHFfutpO0MOZrl6Q7qhVX\nN7GtysR1QNL2WJ4kZ920D+nqmJn972+Eobv3AQ3ABUAbMLqgWIYB4+LyQGA3MBp4FXiu4DwdAC6r\nKHsdWBCXFwCLC96Oh4ERReULuAUYB+w8W46AacAXgIAJwObEcd0O9I3LizNx1WXXKyBfXW67uB+0\nAf2A+rjP9kkZW8XjbwAvp8xZN+1DsjrWW84UxgN7zWy/mf0FrAQaiwjEzNrNrDUu/0qYWKiruatr\nRSOnp0ldDswoMJYpwD4z6+kv2v8zM/uSMPdHVl6OGoEVFmwCBldMLFXVuMxsnZn9E+9uIsx+mFRO\nvvI0AivN7ISZ/QjsJey7yWOTJOAB4ONq/f+cmPLah2R1rLd0CsOBnzL3D1IDDbGkOmAssDkWPRNP\nAd9LfZkmMmCdpG2SnoplQ82sPS4fBoYWEFfJLDrvpEXnqyQvR7VU754gHFGW1Ev6WlKLpMkFxNPV\ntqulfE0GOsxsT6Ysac4q2odkday3dAo1R9IA4FNgvpn9ArwNjATGAO2EU9fUJpnZOGAqME/SLdkH\nLZyvFvIdZoUpXacDqwSel64AAAOOSURBVGNRLeTrDEXmKI+kRYTZDZtiUTtwlZmNBZ4FPpJ0ccKQ\nanLbVXiIzgcgSXPWRftQVu061ls6hUPAlZn7V8SyQkg6n7DBm8xsDYCZdZjZSTM7BbxDFU+b85jZ\nofj3CLA2xtBROh2Nf4+kjiuaCrSaWUeMsfB8ZeTlqPB6J+kx4C5gdmxMiJdnjsblbYRr99ekiqmb\nbVd4vgAk9QXuBVaVylLmrKv2gYR1rLd0CluBUZLq4xHnLKC5iEDitcp3ge/N7M1MefY64D3Azsrn\nVjmu/pIGlpYJH1LuJORpblxtLvBZyrgyOh25FZ2vCnk5agYejd8QmQAcy1wCqDpJdwLPA9PN7PdM\n+RBJfeJyAzAK2J8wrrxt1wzMktRPUn2Ma0uquDJuA34ws4OlglQ5y2sfSFnHqv1peq3cCJ/S7yb0\n8IsKjGMS4dTvG2B7vE0DPgB2xPJmYFjiuBoI3/xoA74t5Qi4FNgA7AHWA5cUkLP+wFFgUKaskHwR\nOqZ24G/C9dsn83JE+EbIkljndgA3JY5rL+F6c6meLY3r3he38XagFbg7cVy52w5YFPO1C5iaelvG\n8veBpyvWTZKzbtqHZHXMh7lwzjlX1lsuHznnnDsH3ik455wr807BOedcmXcKzjnnyrxTcM45V+ad\ngnMJSbpV0udFx+FcHu8UnHPOlXmn4FwXJD0iaUscO3+ZpD6Sjkt6K45zv0HSkLjuGEmbdHregtJY\n91dLWi+pTVKrpJHx5QdI+kRhroOm+CtW52qCdwrOVZB0LfAgMNHMxgAngdmEX1Z/ZWbXAS3AK/Ep\nK4AXzOx6wq9KS+VNwBIzuwG4mfDrWQgjX84njJPfAEys+pty7hz1LToA52rQFOBGYGs8iL+QMADZ\nKU4PkvYhsEbSIGCwmbXE8uXA6jiO1HAzWwtgZn8CxNfbYnFcHYWZveqAjdV/W86dnXcKzp1JwHIz\nW9ipUHqpYr2ejhFzIrN8Et8PXQ3xy0fOnWkDMFPS5VCeH3cEYX+ZGdd5GNhoZseAnzOTrswBWizM\nmnVQ0oz4Gv0kXZT0XTjXA36E4lwFM/tO0ouEWejOI4yiOQ/4DRgfHztC+NwBwlDGS2Ojvx94PJbP\nAZZJei2+xv0J34ZzPeKjpDp3jiQdN7MBRcfhXDX55SPnnHNlfqbgnHOuzM8UnHPOlXmn4Jxzrsw7\nBeecc2XeKTjnnCvzTsE551zZv4u3DVEZnxOvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efca280fbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efce20bada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(np.max(hist.history['val_dice_coef']))\n",
    "#print(np.max(hist.history['dice_coef']))\n",
    "\n",
    "# model.load_weights('saved_models/weights.hdf5')\n",
    "show_plots(hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Statistics(No Dropout)...\n",
      "194/194 [==============================] - 3s     \n",
      "Dice: 0.92 Loss: 0.14\n",
      "Validation Statistics(No Dropout)...\n",
      "49/49 [==============================] - 0s     \n",
      "Dice: 0.93 Loss: 0.12\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('saved_models/endo_models/weightsNoDrop.hdf5')\n",
    "def calculate_dice(images, masks_true):\n",
    "    dices = []\n",
    "    metrics = model.evaluate(images,masks_true,batch_size=batch_size)\n",
    "    #for mask_true, mask_pred in zip(masks_true, masks_pred):\n",
    "     #   y_true = mask_true[:,:,1]\n",
    "      #  y_pred = mask_pred[:,:,1]\n",
    "       # dices.append(dice_coef(y_true, y_pred))\n",
    "    #print(metrics)\n",
    "    print(\"Dice: {:.2f} Loss: {:.2f}\".format(metrics[1], metrics[0]))\n",
    "    \n",
    "print(\"Training Statistics(No Dropout)...\")\n",
    "calculate_dice(train_images,train_inner_masks)\n",
    "print(\"Validation Statistics(No Dropout)...\")\n",
    "calculate_dice(validation_images,validation_inner_masks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Results of Endocardium Model\n",
    "\n",
    "## Training\n",
    "hyperparams: {Dropout:0.5, Epochs:50, Batch Size: 20}\n",
    "\n",
    "- train_dice = 0.62365097794\n",
    "- val_dice = 0.522672422078\n",
    "\n",
    "hyperparams: {Dropout:0.5, Epochs: 200, Batch Size: 20}\n",
    "\n",
    "- train_dice = 0.878794970879\n",
    "- val_dice = 0.841971736781\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 216, 256, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 216, 256, 32)  320         input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 216, 256, 32)  0           conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 216, 256, 32)  0           activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 216, 256, 32)  9248        dropout_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 216, 256, 32)  0           conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 216, 256, 32)  0           activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, 108, 128, 32)  0           dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 108, 128, 64)  18496       max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 108, 128, 64)  0           conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 108, 128, 64)  0           activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 108, 128, 64)  36928       dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 108, 128, 64)  0           conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)             (None, 108, 128, 64)  0           activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, 54, 64, 64)    0           dropout_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 54, 64, 128)   73856       max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 54, 64, 128)   0           conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)             (None, 54, 64, 128)   0           activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, 54, 64, 128)   147584      dropout_19[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 54, 64, 128)   0           conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)             (None, 54, 64, 128)   0           activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)   (None, 27, 32, 128)   0           dropout_20[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 27, 32, 256)   295168      max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 27, 32, 256)   0           conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)             (None, 27, 32, 256)   0           activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 27, 32, 256)   590080      dropout_21[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 27, 32, 256)   0           conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)             (None, 27, 32, 256)   0           activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTransp (None, 54, 64, 128)   131200      dropout_22[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 54, 64, 256)   0           conv2d_transpose_4[0][0]         \n",
      "                                                                   conv2d_transpose_4[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 54, 64, 128)   295040      concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 54, 64, 128)   0           conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)             (None, 54, 64, 128)   0           activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 54, 64, 128)   147584      dropout_23[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 54, 64, 128)   0           conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)             (None, 54, 64, 128)   0           activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTransp (None, 108, 128, 64)  32832       dropout_24[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 108, 128, 128) 0           conv2d_transpose_5[0][0]         \n",
      "                                                                   conv2d_transpose_5[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 108, 128, 64)  73792       concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 108, 128, 64)  0           conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)             (None, 108, 128, 64)  0           activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, 108, 128, 64)  36928       dropout_25[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 108, 128, 64)  0           conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)             (None, 108, 128, 64)  0           activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTransp (None, 216, 256, 32)  8224        dropout_26[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)      (None, 216, 256, 64)  0           conv2d_transpose_6[0][0]         \n",
      "                                                                   conv2d_transpose_6[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, 216, 256, 32)  18464       concatenate_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 216, 256, 32)  0           conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)             (None, 216, 256, 32)  0           activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, 216, 256, 32)  9248        dropout_27[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 216, 256, 32)  0           conv2d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)             (None, 216, 256, 32)  0           activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, 216, 256, 2)   66          dropout_28[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1,925,058\n",
      "Trainable params: 1,925,058\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_epi = unet_conv.get_unet(height=height,width=width,channels=1,features=32,steps=3,dropout=dropout,padding='same')\n",
    "\n",
    "model_epi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/preprocessing/image.py:653: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (194, 216, 256, 2) (2 channels).\n",
      "/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/preprocessing/image.py:787: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (194, 216, 256, 2) (2 channels).\n"
     ]
    }
   ],
   "source": [
    "seed_epi = 10\n",
    "\n",
    "train_outer_masks = o_masks[:split_index]\n",
    "\n",
    "train_images_datagen.fit(train_images,augment=True,seed=seed)\n",
    "train_masks_datagen.fit(train_outer_masks,augment=True,seed=seed)\n",
    "\n",
    "train_images_generator = train_images_datagen.flow(train_images, y=None, seed=seed)\n",
    "train_masks_generator = train_images_datagen.flow(train_outer_masks, y=None, seed=seed)\n",
    "\n",
    "\n",
    "train_outer_generator = zip(train_images_generator, train_masks_generator)\n",
    "\n",
    "validation_outer_masks = o_masks[split_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.62896, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "24s - loss: 0.6504 - dice_coef: 0.5231 - val_loss: 0.6290 - val_dice_coef: 0.5353\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.62896 to 0.55310, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.5887 - dice_coef: 0.5614 - val_loss: 0.5531 - val_dice_coef: 0.5850\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.55310 to 0.45783, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.4972 - dice_coef: 0.6345 - val_loss: 0.4578 - val_dice_coef: 0.6693\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.45783 to 0.40975, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.4287 - dice_coef: 0.7244 - val_loss: 0.4098 - val_dice_coef: 0.7504\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.40975 to 0.39880, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.4228 - dice_coef: 0.7733 - val_loss: 0.3988 - val_dice_coef: 0.7569\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.39880 to 0.39332, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3986 - dice_coef: 0.7682 - val_loss: 0.3933 - val_dice_coef: 0.7474\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.39332 to 0.38402, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.3845 - dice_coef: 0.7712 - val_loss: 0.3840 - val_dice_coef: 0.7562\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.38402 to 0.37834, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3893 - dice_coef: 0.7716 - val_loss: 0.3783 - val_dice_coef: 0.7529\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.37834 to 0.36606, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3742 - dice_coef: 0.7745 - val_loss: 0.3661 - val_dice_coef: 0.7689\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.36606 to 0.36038, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.3847 - dice_coef: 0.7727 - val_loss: 0.3604 - val_dice_coef: 0.7626\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.36038 to 0.34550, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3606 - dice_coef: 0.7832 - val_loss: 0.3455 - val_dice_coef: 0.7814\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.34550 to 0.33584, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.3566 - dice_coef: 0.7888 - val_loss: 0.3358 - val_dice_coef: 0.7811\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.33584 to 0.32191, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3333 - dice_coef: 0.8046 - val_loss: 0.3219 - val_dice_coef: 0.7925\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.32191 to 0.30711, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.3152 - dice_coef: 0.8149 - val_loss: 0.3071 - val_dice_coef: 0.8099\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.30711 to 0.30041, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3218 - dice_coef: 0.8081 - val_loss: 0.3004 - val_dice_coef: 0.8000\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.30041 to 0.28426, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.3152 - dice_coef: 0.8096 - val_loss: 0.2843 - val_dice_coef: 0.8217\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.28426 to 0.28089, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.3188 - dice_coef: 0.8083 - val_loss: 0.2809 - val_dice_coef: 0.8122\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.28089 to 0.26766, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2964 - dice_coef: 0.8229 - val_loss: 0.2677 - val_dice_coef: 0.8303\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.26766 to 0.26144, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2982 - dice_coef: 0.8153 - val_loss: 0.2614 - val_dice_coef: 0.8323\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.26144 to 0.25401, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2718 - dice_coef: 0.8427 - val_loss: 0.2540 - val_dice_coef: 0.8387\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.25401 to 0.24670, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2670 - dice_coef: 0.8340 - val_loss: 0.2467 - val_dice_coef: 0.8512\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "15s - loss: 0.2672 - dice_coef: 0.8459 - val_loss: 0.2489 - val_dice_coef: 0.8321\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.24670 to 0.23858, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2723 - dice_coef: 0.8311 - val_loss: 0.2386 - val_dice_coef: 0.8501\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.23858 to 0.23514, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2641 - dice_coef: 0.8411 - val_loss: 0.2351 - val_dice_coef: 0.8605\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "15s - loss: 0.2533 - dice_coef: 0.8498 - val_loss: 0.2371 - val_dice_coef: 0.8427\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.23514 to 0.22948, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2574 - dice_coef: 0.8427 - val_loss: 0.2295 - val_dice_coef: 0.8564\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.22948 to 0.22504, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2451 - dice_coef: 0.8491 - val_loss: 0.2250 - val_dice_coef: 0.8613\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.22504 to 0.22164, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2276 - dice_coef: 0.8653 - val_loss: 0.2216 - val_dice_coef: 0.8630\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "15s - loss: 0.2447 - dice_coef: 0.8546 - val_loss: 0.2233 - val_dice_coef: 0.8533\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.22164 to 0.21786, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2343 - dice_coef: 0.8596 - val_loss: 0.2179 - val_dice_coef: 0.8659\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "14s - loss: 0.2293 - dice_coef: 0.8626 - val_loss: 0.2209 - val_dice_coef: 0.8540\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.21786 to 0.21364, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2295 - dice_coef: 0.8621 - val_loss: 0.2136 - val_dice_coef: 0.8720\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "14s - loss: 0.2448 - dice_coef: 0.8527 - val_loss: 0.2159 - val_dice_coef: 0.8579\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "15s - loss: 0.2505 - dice_coef: 0.8485 - val_loss: 0.2227 - val_dice_coef: 0.8462\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.21364 to 0.21015, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2235 - dice_coef: 0.8686 - val_loss: 0.2102 - val_dice_coef: 0.8750\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.21015 to 0.20748, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2236 - dice_coef: 0.8609 - val_loss: 0.2075 - val_dice_coef: 0.8816\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "15s - loss: 0.2219 - dice_coef: 0.8738 - val_loss: 0.2081 - val_dice_coef: 0.8665\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.20748 to 0.20458, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2165 - dice_coef: 0.8679 - val_loss: 0.2046 - val_dice_coef: 0.8752\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.20458 to 0.20407, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2216 - dice_coef: 0.8660 - val_loss: 0.2041 - val_dice_coef: 0.8735\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.20407 to 0.20155, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2161 - dice_coef: 0.8699 - val_loss: 0.2016 - val_dice_coef: 0.8817\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.20155 to 0.20066, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2191 - dice_coef: 0.8727 - val_loss: 0.2007 - val_dice_coef: 0.8785\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "14s - loss: 0.2120 - dice_coef: 0.8723 - val_loss: 0.2028 - val_dice_coef: 0.8689\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00042: val_loss did not improve\n",
      "15s - loss: 0.2086 - dice_coef: 0.8729 - val_loss: 0.2034 - val_dice_coef: 0.8959\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "15s - loss: 0.2321 - dice_coef: 0.8526 - val_loss: 0.2116 - val_dice_coef: 0.8530\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.20066 to 0.19930, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2073 - dice_coef: 0.8810 - val_loss: 0.1993 - val_dice_coef: 0.8889\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "15s - loss: 0.2258 - dice_coef: 0.8612 - val_loss: 0.2060 - val_dice_coef: 0.8610\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.19930 to 0.19774, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2151 - dice_coef: 0.8732 - val_loss: 0.1977 - val_dice_coef: 0.8825\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.19774 to 0.19715, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2141 - dice_coef: 0.8692 - val_loss: 0.1972 - val_dice_coef: 0.8813\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.19715 to 0.19705, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2124 - dice_coef: 0.8737 - val_loss: 0.1971 - val_dice_coef: 0.8800\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.19705 to 0.19624, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2089 - dice_coef: 0.8766 - val_loss: 0.1962 - val_dice_coef: 0.8822\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.19624 to 0.19504, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2083 - dice_coef: 0.8729 - val_loss: 0.1950 - val_dice_coef: 0.8833\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "14s - loss: 0.1999 - dice_coef: 0.8787 - val_loss: 0.1985 - val_dice_coef: 0.8997\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.19504 to 0.19199, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2006 - dice_coef: 0.8771 - val_loss: 0.1920 - val_dice_coef: 0.8861\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.19199 to 0.19057, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2270 - dice_coef: 0.8635 - val_loss: 0.1906 - val_dice_coef: 0.8781\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "15s - loss: 0.2105 - dice_coef: 0.8723 - val_loss: 0.1906 - val_dice_coef: 0.8771\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.19057 to 0.18743, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.2073 - dice_coef: 0.8745 - val_loss: 0.1874 - val_dice_coef: 0.8827\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.18743 to 0.18597, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2042 - dice_coef: 0.8778 - val_loss: 0.1860 - val_dice_coef: 0.8899\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "15s - loss: 0.2026 - dice_coef: 0.8768 - val_loss: 0.1867 - val_dice_coef: 0.8845\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "14s - loss: 0.2040 - dice_coef: 0.8758 - val_loss: 0.1904 - val_dice_coef: 0.8974\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "15s - loss: 0.2336 - dice_coef: 0.8513 - val_loss: 0.2031 - val_dice_coef: 0.8561\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "14s - loss: 0.2034 - dice_coef: 0.8808 - val_loss: 0.1934 - val_dice_coef: 0.8721\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "15s - loss: 0.2032 - dice_coef: 0.8770 - val_loss: 0.1895 - val_dice_coef: 0.8922\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "14s - loss: 0.1897 - dice_coef: 0.8877 - val_loss: 0.1891 - val_dice_coef: 0.8849\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "15s - loss: 0.2064 - dice_coef: 0.8750 - val_loss: 0.1909 - val_dice_coef: 0.8758\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "15s - loss: 0.1972 - dice_coef: 0.8801 - val_loss: 0.1876 - val_dice_coef: 0.8812\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.18597 to 0.18340, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1926 - dice_coef: 0.8828 - val_loss: 0.1834 - val_dice_coef: 0.8920\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.18340 to 0.18195, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2143 - dice_coef: 0.8772 - val_loss: 0.1819 - val_dice_coef: 0.8946\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "14s - loss: 0.2000 - dice_coef: 0.8820 - val_loss: 0.1921 - val_dice_coef: 0.8672\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "15s - loss: 0.1987 - dice_coef: 0.8828 - val_loss: 0.1879 - val_dice_coef: 0.8728\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "14s - loss: 0.1847 - dice_coef: 0.8837 - val_loss: 0.1844 - val_dice_coef: 0.9032\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.18195 to 0.18125, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2050 - dice_coef: 0.8776 - val_loss: 0.1812 - val_dice_coef: 0.8946\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "15s - loss: 0.1898 - dice_coef: 0.8874 - val_loss: 0.1824 - val_dice_coef: 0.8859\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.18125 to 0.17870, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1918 - dice_coef: 0.8871 - val_loss: 0.1787 - val_dice_coef: 0.8938\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.17870 to 0.17654, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2001 - dice_coef: 0.8800 - val_loss: 0.1765 - val_dice_coef: 0.8927\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "14s - loss: 0.1909 - dice_coef: 0.8836 - val_loss: 0.1820 - val_dice_coef: 0.8798\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "15s - loss: 0.1894 - dice_coef: 0.8873 - val_loss: 0.1814 - val_dice_coef: 0.8832\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "14s - loss: 0.1897 - dice_coef: 0.8843 - val_loss: 0.1776 - val_dice_coef: 0.8942\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "15s - loss: 0.1945 - dice_coef: 0.8876 - val_loss: 0.1767 - val_dice_coef: 0.8953\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.17654 to 0.17588, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1926 - dice_coef: 0.8832 - val_loss: 0.1759 - val_dice_coef: 0.8947\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "14s - loss: 0.1915 - dice_coef: 0.8844 - val_loss: 0.1764 - val_dice_coef: 0.8918\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "15s - loss: 0.2010 - dice_coef: 0.8801 - val_loss: 0.1769 - val_dice_coef: 0.8918\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "14s - loss: 0.2232 - dice_coef: 0.8613 - val_loss: 0.1984 - val_dice_coef: 0.9181\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "15s - loss: 0.1951 - dice_coef: 0.8795 - val_loss: 0.1811 - val_dice_coef: 0.8848\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "14s - loss: 0.1994 - dice_coef: 0.8876 - val_loss: 0.1813 - val_dice_coef: 0.8818\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "15s - loss: 0.1984 - dice_coef: 0.8800 - val_loss: 0.1788 - val_dice_coef: 0.9025\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "15s - loss: 0.1809 - dice_coef: 0.8904 - val_loss: 0.1760 - val_dice_coef: 0.8965\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "14s - loss: 0.2028 - dice_coef: 0.8835 - val_loss: 0.2033 - val_dice_coef: 0.8501\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "15s - loss: 0.2027 - dice_coef: 0.8725 - val_loss: 0.1859 - val_dice_coef: 0.9062\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "14s - loss: 0.1970 - dice_coef: 0.8786 - val_loss: 0.1783 - val_dice_coef: 0.8920\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "15s - loss: 0.1858 - dice_coef: 0.8952 - val_loss: 0.1770 - val_dice_coef: 0.8883\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.17588 to 0.17469, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1886 - dice_coef: 0.8848 - val_loss: 0.1747 - val_dice_coef: 0.8954\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "15s - loss: 0.1944 - dice_coef: 0.8866 - val_loss: 0.1756 - val_dice_coef: 0.8937\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "15s - loss: 0.1878 - dice_coef: 0.8854 - val_loss: 0.1757 - val_dice_coef: 0.8964\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "14s - loss: 0.1976 - dice_coef: 0.8882 - val_loss: 0.1962 - val_dice_coef: 0.8570\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00094: val_loss did not improve\n",
      "15s - loss: 0.1970 - dice_coef: 0.8790 - val_loss: 0.1780 - val_dice_coef: 0.9006\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "14s - loss: 0.2024 - dice_coef: 0.8770 - val_loss: 0.1808 - val_dice_coef: 0.8795\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "15s - loss: 0.2013 - dice_coef: 0.8768 - val_loss: 0.1767 - val_dice_coef: 0.8898\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "14s - loss: 0.1757 - dice_coef: 0.8939 - val_loss: 0.1774 - val_dice_coef: 0.8866\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "15s - loss: 0.2064 - dice_coef: 0.8767 - val_loss: 0.1943 - val_dice_coef: 0.8596\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "15s - loss: 0.1884 - dice_coef: 0.8825 - val_loss: 0.1765 - val_dice_coef: 0.8917\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "14s - loss: 0.1964 - dice_coef: 0.8768 - val_loss: 0.1785 - val_dice_coef: 0.9035\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "15s - loss: 0.1770 - dice_coef: 0.8988 - val_loss: 0.1758 - val_dice_coef: 0.8907\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.17469 to 0.17444, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1788 - dice_coef: 0.8902 - val_loss: 0.1744 - val_dice_coef: 0.8964\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.17444 to 0.17327, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1823 - dice_coef: 0.8904 - val_loss: 0.1733 - val_dice_coef: 0.8956\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "14s - loss: 0.1760 - dice_coef: 0.8921 - val_loss: 0.1734 - val_dice_coef: 0.8958\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "15s - loss: 0.1868 - dice_coef: 0.8861 - val_loss: 0.1734 - val_dice_coef: 0.8939\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "15s - loss: 0.1881 - dice_coef: 0.8866 - val_loss: 0.1739 - val_dice_coef: 0.9011\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.17327 to 0.17210, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1969 - dice_coef: 0.8849 - val_loss: 0.1721 - val_dice_coef: 0.8968\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.17210 to 0.17140, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1838 - dice_coef: 0.8833 - val_loss: 0.1714 - val_dice_coef: 0.8935\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.17140 to 0.17113, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1844 - dice_coef: 0.8894 - val_loss: 0.1711 - val_dice_coef: 0.8979\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "15s - loss: 0.1828 - dice_coef: 0.8906 - val_loss: 0.1732 - val_dice_coef: 0.8873\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "14s - loss: 0.1852 - dice_coef: 0.8902 - val_loss: 0.1933 - val_dice_coef: 0.8596\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "15s - loss: 0.1990 - dice_coef: 0.8751 - val_loss: 0.1792 - val_dice_coef: 0.9074\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "15s - loss: 0.1819 - dice_coef: 0.8896 - val_loss: 0.1718 - val_dice_coef: 0.8949\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "14s - loss: 0.1939 - dice_coef: 0.8863 - val_loss: 0.1888 - val_dice_coef: 0.8635\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.17113 to 0.17016, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1950 - dice_coef: 0.8793 - val_loss: 0.1702 - val_dice_coef: 0.9006\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "14s - loss: 0.1809 - dice_coef: 0.8906 - val_loss: 0.1708 - val_dice_coef: 0.9031\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "15s - loss: 0.1838 - dice_coef: 0.8883 - val_loss: 0.1708 - val_dice_coef: 0.8983\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "14s - loss: 0.2083 - dice_coef: 0.8674 - val_loss: 0.1764 - val_dice_coef: 0.8789\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "15s - loss: 0.1835 - dice_coef: 0.8901 - val_loss: 0.1757 - val_dice_coef: 0.8832\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "15s - loss: 0.1859 - dice_coef: 0.8906 - val_loss: 0.1731 - val_dice_coef: 0.9009\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "14s - loss: 0.2060 - dice_coef: 0.8829 - val_loss: 0.1740 - val_dice_coef: 0.8834\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "15s - loss: 0.1781 - dice_coef: 0.8918 - val_loss: 0.1746 - val_dice_coef: 0.8821\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "14s - loss: 0.1714 - dice_coef: 0.8949 - val_loss: 0.1729 - val_dice_coef: 0.9043\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "15s - loss: 0.1798 - dice_coef: 0.8909 - val_loss: 0.1708 - val_dice_coef: 0.8943\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "14s - loss: 0.1812 - dice_coef: 0.8866 - val_loss: 0.1710 - val_dice_coef: 0.9056\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "15s - loss: 0.1830 - dice_coef: 0.8908 - val_loss: 0.1719 - val_dice_coef: 0.8909\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "15s - loss: 0.1788 - dice_coef: 0.8962 - val_loss: 0.1736 - val_dice_coef: 0.8861\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "14s - loss: 0.1772 - dice_coef: 0.8915 - val_loss: 0.1743 - val_dice_coef: 0.9073\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "15s - loss: 0.2010 - dice_coef: 0.8756 - val_loss: 0.1871 - val_dice_coef: 0.8658\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "14s - loss: 0.1912 - dice_coef: 0.8936 - val_loss: 0.1797 - val_dice_coef: 0.8771\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "15s - loss: 0.1931 - dice_coef: 0.8684 - val_loss: 0.1737 - val_dice_coef: 0.8938\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "14s - loss: 0.1958 - dice_coef: 0.8951 - val_loss: 0.1758 - val_dice_coef: 0.8822\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "15s - loss: 0.1859 - dice_coef: 0.8777 - val_loss: 0.1731 - val_dice_coef: 0.9078\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "15s - loss: 0.1771 - dice_coef: 0.8963 - val_loss: 0.1712 - val_dice_coef: 0.8898\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "14s - loss: 0.1984 - dice_coef: 0.8887 - val_loss: 0.1727 - val_dice_coef: 0.8847\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.17016 to 0.16764, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1886 - dice_coef: 0.8829 - val_loss: 0.1676 - val_dice_coef: 0.8990\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "14s - loss: 0.1756 - dice_coef: 0.8906 - val_loss: 0.1737 - val_dice_coef: 0.9097\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "15s - loss: 0.1840 - dice_coef: 0.8873 - val_loss: 0.1713 - val_dice_coef: 0.8897\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "14s - loss: 0.1715 - dice_coef: 0.9008 - val_loss: 0.1730 - val_dice_coef: 0.8867\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "15s - loss: 0.1848 - dice_coef: 0.8888 - val_loss: 0.1693 - val_dice_coef: 0.9025\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.16764 to 0.16752, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.2029 - dice_coef: 0.8824 - val_loss: 0.1675 - val_dice_coef: 0.8986\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "14s - loss: 0.1796 - dice_coef: 0.8897 - val_loss: 0.1709 - val_dice_coef: 0.9037\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "15s - loss: 0.1779 - dice_coef: 0.8940 - val_loss: 0.1692 - val_dice_coef: 0.8965\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "14s - loss: 0.1802 - dice_coef: 0.8927 - val_loss: 0.1721 - val_dice_coef: 0.9088\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "15s - loss: 0.1811 - dice_coef: 0.8902 - val_loss: 0.1700 - val_dice_coef: 0.8966\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "14s - loss: 0.1805 - dice_coef: 0.8932 - val_loss: 0.1677 - val_dice_coef: 0.9002\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "15s - loss: 0.1791 - dice_coef: 0.8919 - val_loss: 0.1679 - val_dice_coef: 0.9020\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "15s - loss: 0.1754 - dice_coef: 0.8951 - val_loss: 0.1689 - val_dice_coef: 0.8913\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.16752 to 0.16689, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1878 - dice_coef: 0.8840 - val_loss: 0.1669 - val_dice_coef: 0.8976\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00150: val_loss improved from 0.16689 to 0.16675, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1766 - dice_coef: 0.8910 - val_loss: 0.1668 - val_dice_coef: 0.8956\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "14s - loss: 0.1636 - dice_coef: 0.9000 - val_loss: 0.1692 - val_dice_coef: 0.8997\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "15s - loss: 0.1707 - dice_coef: 0.9000 - val_loss: 0.1693 - val_dice_coef: 0.9020\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.16675 to 0.16596, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1817 - dice_coef: 0.8893 - val_loss: 0.1660 - val_dice_coef: 0.8973\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "15s - loss: 0.1747 - dice_coef: 0.8904 - val_loss: 0.1674 - val_dice_coef: 0.9060\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "15s - loss: 0.1794 - dice_coef: 0.8924 - val_loss: 0.1696 - val_dice_coef: 0.9050\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "14s - loss: 0.1907 - dice_coef: 0.8904 - val_loss: 0.1775 - val_dice_coef: 0.8744\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "15s - loss: 0.1788 - dice_coef: 0.8888 - val_loss: 0.1712 - val_dice_coef: 0.8844\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "14s - loss: 0.1723 - dice_coef: 0.8974 - val_loss: 0.1686 - val_dice_coef: 0.9040\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "15s - loss: 0.1724 - dice_coef: 0.8947 - val_loss: 0.1690 - val_dice_coef: 0.9076\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "14s - loss: 0.1792 - dice_coef: 0.8876 - val_loss: 0.1690 - val_dice_coef: 0.9080\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "15s - loss: 0.1793 - dice_coef: 0.8942 - val_loss: 0.1697 - val_dice_coef: 0.8941\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "15s - loss: 0.1686 - dice_coef: 0.9024 - val_loss: 0.1701 - val_dice_coef: 0.8879\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "14s - loss: 0.1733 - dice_coef: 0.8939 - val_loss: 0.1665 - val_dice_coef: 0.9000\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "15s - loss: 0.1770 - dice_coef: 0.8910 - val_loss: 0.1707 - val_dice_coef: 0.9086\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "14s - loss: 0.1804 - dice_coef: 0.8940 - val_loss: 0.1672 - val_dice_coef: 0.8929\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "15s - loss: 0.1895 - dice_coef: 0.8815 - val_loss: 0.1693 - val_dice_coef: 0.8862\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "14s - loss: 0.1726 - dice_coef: 0.8950 - val_loss: 0.1714 - val_dice_coef: 0.8878\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "15s - loss: 0.1774 - dice_coef: 0.8927 - val_loss: 0.1695 - val_dice_coef: 0.9018\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "15s - loss: 0.1767 - dice_coef: 0.8938 - val_loss: 0.1667 - val_dice_coef: 0.8980\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "14s - loss: 0.1658 - dice_coef: 0.8965 - val_loss: 0.1683 - val_dice_coef: 0.9075\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "15s - loss: 0.1821 - dice_coef: 0.8875 - val_loss: 0.1688 - val_dice_coef: 0.9057\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "14s - loss: 0.1759 - dice_coef: 0.8936 - val_loss: 0.1706 - val_dice_coef: 0.9115\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "15s - loss: 0.1772 - dice_coef: 0.8917 - val_loss: 0.1690 - val_dice_coef: 0.9089\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "14s - loss: 0.1900 - dice_coef: 0.8854 - val_loss: 0.1663 - val_dice_coef: 0.8997\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.16596 to 0.16528, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1725 - dice_coef: 0.8957 - val_loss: 0.1653 - val_dice_coef: 0.8965\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "15s - loss: 0.1667 - dice_coef: 0.8963 - val_loss: 0.1673 - val_dice_coef: 0.8913\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "14s - loss: 0.1662 - dice_coef: 0.8997 - val_loss: 0.1666 - val_dice_coef: 0.8925\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.16528 to 0.16412, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1726 - dice_coef: 0.8931 - val_loss: 0.1641 - val_dice_coef: 0.8999\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "14s - loss: 0.1680 - dice_coef: 0.8953 - val_loss: 0.1651 - val_dice_coef: 0.9020\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "15s - loss: 0.1702 - dice_coef: 0.8982 - val_loss: 0.1681 - val_dice_coef: 0.8919\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "14s - loss: 0.1730 - dice_coef: 0.8922 - val_loss: 0.1695 - val_dice_coef: 0.9071\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "15s - loss: 0.1750 - dice_coef: 0.8941 - val_loss: 0.1654 - val_dice_coef: 0.9068\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "15s - loss: 0.1739 - dice_coef: 0.8931 - val_loss: 0.1648 - val_dice_coef: 0.9032\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "14s - loss: 0.1741 - dice_coef: 0.8952 - val_loss: 0.1646 - val_dice_coef: 0.8978\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.16412 to 0.16343, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1740 - dice_coef: 0.8934 - val_loss: 0.1634 - val_dice_coef: 0.8984\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "14s - loss: 0.1758 - dice_coef: 0.8930 - val_loss: 0.1655 - val_dice_coef: 0.8990\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "15s - loss: 0.1703 - dice_coef: 0.8973 - val_loss: 0.1654 - val_dice_coef: 0.9047\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "14s - loss: 0.1792 - dice_coef: 0.8858 - val_loss: 0.1988 - val_dice_coef: 0.9238\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "15s - loss: 0.1936 - dice_coef: 0.8803 - val_loss: 0.1801 - val_dice_coef: 0.8891\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "15s - loss: 0.1878 - dice_coef: 0.8980 - val_loss: 0.1735 - val_dice_coef: 0.8908\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "14s - loss: 0.1788 - dice_coef: 0.8886 - val_loss: 0.1666 - val_dice_coef: 0.9014\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "15s - loss: 0.1750 - dice_coef: 0.8930 - val_loss: 0.1653 - val_dice_coef: 0.9075\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss improved from 0.16343 to 0.16335, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "14s - loss: 0.1763 - dice_coef: 0.8931 - val_loss: 0.1633 - val_dice_coef: 0.8995\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "15s - loss: 0.1738 - dice_coef: 0.8912 - val_loss: 0.1642 - val_dice_coef: 0.8999\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "14s - loss: 0.1823 - dice_coef: 0.8931 - val_loss: 0.1686 - val_dice_coef: 0.8883\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "15s - loss: 0.1699 - dice_coef: 0.8922 - val_loss: 0.1658 - val_dice_coef: 0.8961\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "15s - loss: 0.1731 - dice_coef: 0.8930 - val_loss: 0.1667 - val_dice_coef: 0.9029\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "14s - loss: 0.1730 - dice_coef: 0.8948 - val_loss: 0.1638 - val_dice_coef: 0.9004\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.16335 to 0.16304, saving model to saved_models/epi_models/weightsNoDrop.hdf5\n",
      "15s - loss: 0.1677 - dice_coef: 0.8962 - val_loss: 0.1630 - val_dice_coef: 0.8963\n"
     ]
    }
   ],
   "source": [
    "model_epi.compile(optimizer=Adam(lr=1e-5),loss='categorical_crossentropy',metrics=[dice_coef])\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/epi_models/weightsNoDrop.hdf5',verbose=1,save_best_only=True)\n",
    "\n",
    "hist_epi = model_epi.fit_generator(train_outer_generator,steps_per_epoch=train_steps,epochs=epochs,verbose=2,callbacks=[checkpointer],\n",
    "                                 validation_data=(validation_images,validation_outer_masks),validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plots(hist_epi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
